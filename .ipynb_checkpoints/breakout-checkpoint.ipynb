{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_greyscale(img): # later on, let's turn these binary\n",
    "    return np.mean(img, axis=2).astype(np.uint8)\n",
    "\n",
    "def rgb_to_gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray.astype(np.uint8)\n",
    "\n",
    "def downsample(img):\n",
    "    return img[::2, ::2]\n",
    "\n",
    "def preprocess(img):\n",
    "    return rgb_to_gray(downsample(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (8, 8), strides=(4, 4), activation=\"relu\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (4, 4), strides=(2, 2), activation=\"relu\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"fr...)`\n"
     ]
    }
   ],
   "source": [
    "# We assume a theano backend here, so the \"channels\" are first.\n",
    "#ATARI_SHAPE = (4, 105, 80)\n",
    "\n",
    "# tf backend\n",
    "ATARI_SHAPE = (105, 80, 2)\n",
    "\n",
    "# With the functional API we need to define the inputs.\n",
    "frames_input = keras.layers.Input(ATARI_SHAPE, name='frames')\n",
    "#actions_input = keras.layers.Input((n_actions,), name='mask')\n",
    "\n",
    "# Assuming that the input frames are still encoded from 0 to 255. Transforming to [0, 1].\n",
    "normalized = keras.layers.Lambda(lambda x: x / 255.0)(frames_input)\n",
    "\n",
    "#still want to normalize these, although greyscaled already\n",
    "\n",
    "# \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "conv_1 = keras.layers.convolutional.Convolution2D(\n",
    "    16, 8, 8, subsample=(4, 4), activation='relu'\n",
    ")(normalized)\n",
    "# \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "conv_2 = keras.layers.convolutional.Convolution2D(\n",
    "    32, 4, 4, subsample=(2, 2), activation='relu'\n",
    ")(conv_1)\n",
    "# Flattening the second convolutional layer.\n",
    "conv_flattened = keras.layers.core.Flatten()(conv_2)\n",
    "\n",
    "# \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "hidden = keras.layers.Dense(256, activation='relu')(conv_flattened)\n",
    "\n",
    "# \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "output = keras.layers.Dense(4)(hidden) # number of actions\n",
    "\n",
    "#model = keras.models.Model(input=[frames_input, actions_input], output=filtered_output)\n",
    "atari_model = keras.models.Model(input=frames_input, output=output)\n",
    "optimizer = optimizer=keras.optimizers.RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "atari_model.compile(optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'atari_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8cdf62b34665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matari_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'atari_model' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutDeterministic-v4\")\n",
    "\n",
    "gamma = 0.9\n",
    "buffer = 100000\n",
    "batchSize = 32\n",
    "epsilon = 1\n",
    "\n",
    "rewards = []\n",
    "\n",
    "replay = []\n",
    "h = 0\n",
    "\n",
    "model = atari_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_old = env.reset()\n",
    "frame_new, reward, is_done, _ = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffa07042e48>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa070f3668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.step(env.action_space.sample())\n",
    "plt.imshow(preprocess(frame_new), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12308557  0.12879653  0.12815118  0.13466093]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffa073440b8>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa0744deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# STATE\n",
    "orig_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "# ACTION\n",
    "Qvals = model.predict(orig_state.reshape(1,105,80,2), batch_size=1)\n",
    "maxQ_ix = np.argmax(Qvals)\n",
    "\n",
    "print(Qvals)\n",
    "frame_old = frame_new\n",
    "\n",
    "# take optimal choice\n",
    "action = maxQ_ix \n",
    "\n",
    "# NEW STATE, REWARD\n",
    "frame_new, reward, is_done, _ = env.step(action)\n",
    "\n",
    "plt.imshow(preprocess(frame_new), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"breakout.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game # 0\n",
      "saving model...\n",
      "game # 1\n",
      "game # 2\n",
      "game # 3\n",
      "game # 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fde4e96827ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m#Get max_Q(S',a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mold_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mold_qval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mnewQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSU2GSGoyRFKTIZKaDJHU9H8/Byx9pO88nAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb20dc96208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    print(\"game #\", i)\n",
    "    # doing first two steps here to get enough for initial state\n",
    "    frame_old = env.reset()\n",
    "\n",
    "    frame_new, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "    while not is_done:\n",
    "        # STATE\n",
    "        orig_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "        # ACTION\n",
    "        Qvals = model.predict(orig_state.reshape(1,105,80,2), batch_size=1)\n",
    "        maxQ_ix = np.argmax(Qvals)\n",
    "\n",
    "        frame_old = frame_new\n",
    "        \n",
    "        if random.random()>epsilon:\n",
    "            action = maxQ_ix\n",
    "            # take optimal choice\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            # take random choice\n",
    "        if epsilon > .1: epsilon -= .9e-06\n",
    "\n",
    "        # NEW STATE, REWARD\n",
    "        frame_new, reward, is_done, _ = env.step(action) # totally exploratory\n",
    "\n",
    "        # new state \n",
    "        new_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "        reward = np.sign(reward)\n",
    "\n",
    "        #Experience replay storage\n",
    "        if (len(replay) < buffer): #if buffer not filled, add to it\n",
    "            replay.append((orig_state, action, reward, new_state))\n",
    "        else: \n",
    "            if (h < (buffer-1)):\n",
    "                h += 1\n",
    "            else:\n",
    "                h = 0\n",
    "\n",
    "            replay[h] = (orig_state, action, reward, new_state)\n",
    "\n",
    "            #randomly sample our experience replay memory\n",
    "            minibatch = random.sample(replay, batchSize)\n",
    "\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            for memory in minibatch:\n",
    "                #Get max_Q(S',a)\n",
    "                old_state, action, reward, new_state = memory\n",
    "                old_qval = model.predict(old_state.reshape(1,105,80,2), batch_size=1)\n",
    "\n",
    "                newQ = model.predict(new_state.reshape(1,105,80,2), batch_size=1)\n",
    "                maxQ = np.max(newQ)\n",
    "                y = np.zeros((1,4))\n",
    "                y[:] = old_qval[:]\n",
    "                update = (reward + (gamma * maxQ))\n",
    "\n",
    "                y[0][action] = update\n",
    "                X_train.append(old_state)\n",
    "                y_train.append(y)\n",
    "                \"\"\"\n",
    "                print(\"old qvals\", old_qval)\n",
    "                print(\"action\", action)\n",
    "                print(\"reward: \", reward)\n",
    "                print(\"new q vals \", newQ)\n",
    "                print(\"update\", update)\n",
    "                print(\"fitting with the following y:\", y, \"\\n\\n\")\n",
    "                \"\"\"\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train).reshape(batchSize, 4)\n",
    "\n",
    "            #print(\"Game #: %s\" % (i,))\n",
    "            model.fit(X_train, y_train, batch_size=batchSize, epochs=1, verbose=0)\n",
    "\n",
    "    #env.render()\n",
    "\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.imshow(preprocess(frame_old), cmap=\"gray\") \n",
    "        #env.close()\n",
    "        print(\"saving model...\")\n",
    "        model.save(\"breakout.h5\")\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    #env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"breakout.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_old = env.reset()\n",
    "\n",
    "frame_new, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "while not is_done:\n",
    "    # STATE\n",
    "    orig_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "    # ACTION\n",
    "    Qvals = model.predict(orig_state.reshape(1,105,80,2), batch_size=1)\n",
    "    maxQ_ix = np.argmax(Qvals)\n",
    "\n",
    "    frame_old = frame_new\n",
    "\n",
    "    # take optimal choice\n",
    "    action = maxQ_ix \n",
    "\n",
    "    # NEW STATE, REWARD\n",
    "    frame_new, reward, is_done, _ = env.step(action)\n",
    "    \n",
    "\n",
    "    env.render(mode='rgb_array')    \n",
    "#ax.imshow(preprocess(frame_old), cmap=\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (8, 8), strides=(4, 4), activation=\"relu\")`\n",
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (4, 4), strides=(2, 2), activation=\"relu\")`\n",
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"fr..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# We assume a theano backend here, so the \"channels\" are first.\n",
    "#ATARI_SHAPE = (4, 105, 80)\n",
    "\n",
    "# tf backend\n",
    "ATARI_SHAPE = (105, 80, 2)\n",
    "\n",
    "# With the functional API we need to define the inputs.\n",
    "frames_input = keras.layers.Input(ATARI_SHAPE, name='frames')\n",
    "#actions_input = keras.layers.Input((n_actions,), name='mask')\n",
    "\n",
    "# Assuming that the input frames are still encoded from 0 to 255. Transforming to [0, 1].\n",
    "normalized = keras.layers.Lambda(lambda x: x / 255.0)(frames_input)\n",
    "\n",
    "#still want to normalize these, although greyscaled already\n",
    "\n",
    "# \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "conv_1 = keras.layers.convolutional.Convolution2D(\n",
    "    16, 8, 8, subsample=(4, 4), activation='relu'\n",
    ")(normalized)\n",
    "# \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "conv_2 = keras.layers.convolutional.Convolution2D(\n",
    "    32, 4, 4, subsample=(2, 2), activation='relu'\n",
    ")(conv_1)\n",
    "# Flattening the second convolutional layer.\n",
    "conv_flattened = keras.layers.core.Flatten()(conv_2)\n",
    "\n",
    "# \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "hidden = keras.layers.Dense(256, activation='relu')(conv_flattened)\n",
    "\n",
    "# \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "output = keras.layers.Dense(4)(hidden) # number of actions\n",
    "\n",
    "#model = keras.models.Model(input=[frames_input, actions_input], output=filtered_output)\n",
    "atari_model = keras.models.Model(input=frames_input, output=output)\n",
    "optimizer = optimizer=keras.optimizers.RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "atari_model.compile(optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
