{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#N_STEPS = 5\n",
    "SEED = 1\n",
    "N_GAMES = 1000\n",
    "N_ACTIONS = 2\n",
    "N_INPUTS = 4\n",
    "\n",
    "states = []\n",
    "actions = []\n",
    "rewards = []\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ActorCritic()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "-0.3165  0.1104  0.3473 -0.5679\n",
      "-0.0794 -0.2747  1.7229  0.3133\n",
      " 0.0617  0.0912 -0.4923 -0.5562\n",
      "-0.0413  0.2262 -0.2084 -0.2201\n",
      " 0.2308  0.0411  0.9193  0.3575\n",
      "-0.3636 -0.3166 -0.4932 -0.2593\n",
      "-0.2372 -0.2273  0.5840  0.3355\n",
      "-0.3726  0.3583  0.0291 -0.2367\n",
      " 0.4792 -0.1949  0.2392 -0.4930\n",
      " 0.5584  0.0187  1.2138  0.4004\n",
      " 0.4938 -0.1633 -0.2778 -0.3069\n",
      " 0.2036  0.1608 -0.2685  0.1544\n",
      " 0.0372  0.0918 -0.5183 -0.4853\n",
      " 0.0976  0.1364 -0.3834 -0.0214\n",
      "-0.0770  0.3507 -0.1549 -0.4884\n",
      "-0.2180  0.1663 -0.0243 -0.2121\n",
      " 0.1494  0.4632 -0.7563  0.0139\n",
      " 0.2834  0.3296  0.5109  0.3168\n",
      "-0.3227  0.2681  0.7809  0.4069\n",
      "-0.1231 -0.0569  0.4945 -0.2541\n",
      " 0.4568  0.0952  0.4106  0.2142\n",
      "-0.3658  0.4328 -0.3125  0.1748\n",
      " 0.0720  0.8420  1.3125 -0.3830\n",
      " 0.3677  0.4929 -0.2872  0.0391\n",
      "-0.4611  0.1742  0.0857 -0.1591\n",
      " 0.4101  0.2922  0.4440  0.1545\n",
      "-0.2200  0.4908  0.2658  0.1718\n",
      "-0.1861  0.3742 -0.0755  0.2079\n",
      "-0.1560 -0.2155  1.2811 -0.1277\n",
      " 0.4211 -0.1254 -0.4485 -0.2714\n",
      "-0.1369 -0.2666 -0.3602 -0.1219\n",
      "-0.4053  0.3613 -0.4178 -0.1397\n",
      " 0.0094  0.1338  2.0728  0.1934\n",
      " 0.4038  0.7126 -0.2911 -0.1134\n",
      " 0.1990 -0.0828  0.0346 -0.3697\n",
      " 0.3516  0.1299  0.2586  0.1202\n",
      " 0.0001  0.2171  0.0469 -0.7822\n",
      "-0.3160  0.4825 -1.7191 -0.6167\n",
      "-0.2918  0.0775 -1.5106 -0.5660\n",
      " 0.4537  0.2635  0.2890  0.2999\n",
      "-0.2195  0.2865  0.0839 -0.5368\n",
      "-0.3991  0.0210 -0.7856 -0.4713\n",
      "-0.2519 -0.3214  1.9696  0.2500\n",
      "-0.3119  0.4503  0.0098  0.0376\n",
      " 0.4340  0.2686 -0.1020  0.0657\n",
      " 0.1165  0.4165 -0.3155 -0.3500\n",
      " 0.4217  0.1826  0.0069  0.2311\n",
      "-0.1776  0.1251 -0.2834 -0.3807\n",
      " 0.5658  0.3607  2.0272  0.4842\n",
      " 0.4626  0.6206  0.2097  0.0755\n",
      "-0.1229  0.4549  2.0866  0.3294\n",
      " 0.5575 -0.1475 -0.0670 -0.2102\n",
      "-0.2151 -0.0227  1.0827 -0.1598\n",
      "-0.1994 -0.1852 -0.5094  0.0596\n",
      " 0.4964  0.2224  0.1243  0.0563\n",
      " 0.1058 -0.3717  1.7848  0.5121\n",
      "-0.2363 -0.1843 -0.9226 -0.4307\n",
      " 0.2159 -0.2736  0.2598 -0.0701\n",
      " 0.0363  0.2776 -1.6324 -0.6057\n",
      "-0.3985 -0.4779  0.1238 -0.3170\n",
      "-0.0322  0.0188 -0.5833 -0.6402\n",
      "-0.1012  0.2766  0.3881 -0.3000\n",
      " 0.2815 -0.2743  0.1624 -0.1193\n",
      " 0.1212 -0.0430 -0.3534 -0.2217\n",
      "[torch.FloatTensor of size 64x4]\n",
      "\n",
      "Parameter containing:\n",
      "-0.1542\n",
      "-0.0968\n",
      "-0.1219\n",
      "-0.4010\n",
      "-0.0623\n",
      "-0.4304\n",
      "-0.9173\n",
      "-0.1377\n",
      "-0.0355\n",
      " 0.1460\n",
      "-0.3233\n",
      "-0.1328\n",
      "-0.1200\n",
      "-0.0545\n",
      "-0.3745\n",
      "-0.4117\n",
      "-0.1098\n",
      "-0.3839\n",
      "-0.3665\n",
      "-0.0969\n",
      "-0.5017\n",
      "-0.0950\n",
      "-0.2306\n",
      "-0.3071\n",
      "-0.4568\n",
      "-0.0362\n",
      "-0.1975\n",
      "-0.3616\n",
      " 0.0265\n",
      "-0.0491\n",
      "-0.2842\n",
      "-0.4327\n",
      " 0.0476\n",
      "-0.1099\n",
      "-0.1642\n",
      "-0.1665\n",
      "-0.0506\n",
      "-0.1642\n",
      " 0.0366\n",
      "-0.4223\n",
      "-0.1090\n",
      "-0.0634\n",
      " 0.2072\n",
      "-0.2478\n",
      "-0.6791\n",
      "-0.1347\n",
      "-0.3813\n",
      "-0.2236\n",
      " 0.0645\n",
      "-0.1141\n",
      " 0.0871\n",
      "-0.4011\n",
      "-0.0122\n",
      "-0.5856\n",
      "-0.4078\n",
      " 0.1243\n",
      "-0.1116\n",
      "-0.5217\n",
      "-0.1111\n",
      "-0.2440\n",
      "-0.0979\n",
      "-0.0387\n",
      "-0.2660\n",
      "-0.1436\n",
      "[torch.FloatTensor of size 64]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0437 -0.0755  0.0641  ...  -0.1010  0.0950  0.0390\n",
      "-0.0143 -0.0844 -0.2957  ...  -0.1777  0.0245 -0.1154\n",
      " 0.0475  0.0181 -0.0649  ...   0.1117 -0.0831 -0.0500\n",
      "          ...             ⋱             ...          \n",
      "-0.0130  0.0030  0.0452  ...  -0.0688  0.1115 -0.0108\n",
      " 0.0617  0.0085 -0.0852  ...  -0.2317  0.2410 -0.1644\n",
      " 0.1175  0.3087  0.0300  ...   0.1586  0.1113 -0.1166\n",
      "[torch.FloatTensor of size 128x64]\n",
      "\n",
      "Parameter containing:\n",
      "-0.0621\n",
      "-0.0790\n",
      "-0.0623\n",
      "-0.1657\n",
      "-0.0619\n",
      " 0.0621\n",
      " 0.0611\n",
      "-0.0934\n",
      " 0.2262\n",
      "-0.1251\n",
      " 0.0497\n",
      "-0.1052\n",
      " 0.1660\n",
      " 0.1175\n",
      "-0.2490\n",
      " 0.0348\n",
      " 0.3560\n",
      "-0.0452\n",
      " 0.1130\n",
      "-0.0244\n",
      " 0.2028\n",
      " 0.0426\n",
      "-0.0679\n",
      " 0.0579\n",
      " 0.1494\n",
      "-0.1322\n",
      "-0.0900\n",
      "-0.0386\n",
      "-0.1321\n",
      " 0.1985\n",
      " 0.3031\n",
      "-0.0774\n",
      "-0.0116\n",
      "-0.1368\n",
      "-0.0722\n",
      "-0.1471\n",
      "-0.2830\n",
      "-0.0311\n",
      "-0.0336\n",
      "-0.0952\n",
      "-0.1790\n",
      "-0.1516\n",
      " 0.0432\n",
      "-0.1335\n",
      "-0.0957\n",
      " 0.0329\n",
      "-0.0858\n",
      "-0.1212\n",
      "-0.0988\n",
      " 0.1407\n",
      " 0.2501\n",
      " 0.1413\n",
      "-0.2913\n",
      "-0.0404\n",
      "-0.0898\n",
      "-0.0873\n",
      "-0.0101\n",
      " 0.2568\n",
      "-0.1231\n",
      " 0.2386\n",
      "-0.1154\n",
      "-0.0509\n",
      "-0.0550\n",
      "-0.1682\n",
      "-0.0766\n",
      "-0.1403\n",
      "-0.1018\n",
      "-0.0314\n",
      " 0.1676\n",
      "-0.1078\n",
      " 0.3043\n",
      "-0.2792\n",
      "-0.5250\n",
      " 0.3087\n",
      "-0.1454\n",
      "-0.2982\n",
      "-0.0205\n",
      "-0.1334\n",
      "-0.2005\n",
      "-0.2725\n",
      " 0.0350\n",
      "-0.0474\n",
      "-0.0908\n",
      " 0.2813\n",
      "-0.1217\n",
      "-0.2966\n",
      "-0.0197\n",
      " 0.0110\n",
      "-0.0853\n",
      "-0.1096\n",
      " 0.2810\n",
      " 0.1387\n",
      " 0.0590\n",
      "-0.2880\n",
      " 0.1621\n",
      " 0.0180\n",
      " 0.3296\n",
      " 0.2428\n",
      " 0.2543\n",
      "-0.0492\n",
      " 0.1457\n",
      "-0.2553\n",
      "-0.0594\n",
      "-0.0472\n",
      "-0.2060\n",
      "-0.0978\n",
      "-0.2423\n",
      "-0.2981\n",
      "-0.1140\n",
      "-0.2593\n",
      "-0.1115\n",
      "-0.2164\n",
      "-0.0760\n",
      "-0.0415\n",
      "-0.1109\n",
      "-0.1084\n",
      "-0.1866\n",
      " 0.1951\n",
      " 0.0463\n",
      " 0.3983\n",
      "-0.0625\n",
      "-0.1116\n",
      "-0.1076\n",
      "-0.0824\n",
      "-0.0329\n",
      "-0.2960\n",
      "-0.0040\n",
      " 0.3405\n",
      "[torch.FloatTensor of size 128]\n",
      "\n",
      "Parameter containing:\n",
      "-0.0285 -0.2429  0.0822  ...  -0.0086 -0.1350 -0.2395\n",
      " 0.0230  0.0366  0.0862  ...   0.0515  0.0263  0.0374\n",
      " 0.0152  0.1762  0.0612  ...   0.3786  0.0580  0.1965\n",
      "          ...             ⋱             ...          \n",
      "-0.0461 -0.2400 -0.0016  ...  -0.0529 -0.2225 -0.2306\n",
      "-0.0294  0.2488  0.0275  ...  -0.0693 -0.1525 -0.1852\n",
      "-0.0847 -0.0332  0.0499  ...   0.0524 -0.1737 -0.0740\n",
      "[torch.FloatTensor of size 64x128]\n",
      "\n",
      "Parameter containing:\n",
      "-0.2068\n",
      " 0.0176\n",
      " 0.4875\n",
      "-0.2465\n",
      "-0.1608\n",
      "-0.0948\n",
      "-0.1245\n",
      "-0.0784\n",
      " 0.3574\n",
      "-0.1635\n",
      " 0.0023\n",
      "-0.0933\n",
      "-0.1657\n",
      "-0.1218\n",
      "-0.1366\n",
      "-0.1690\n",
      "-0.1593\n",
      " 0.1998\n",
      "-0.2113\n",
      " 0.1729\n",
      " 0.1543\n",
      "-0.1988\n",
      " 0.0553\n",
      " 0.3856\n",
      " 0.1973\n",
      " 0.6357\n",
      "-0.2363\n",
      "-0.2081\n",
      " 0.0710\n",
      "-0.1293\n",
      "-0.0290\n",
      " 0.2632\n",
      " 0.5742\n",
      " 0.0135\n",
      "-0.1419\n",
      " 0.3306\n",
      "-0.2514\n",
      "-0.1730\n",
      " 0.0315\n",
      " 0.5527\n",
      "-0.1933\n",
      "-0.0808\n",
      " 0.1625\n",
      "-0.0776\n",
      "-0.1892\n",
      "-0.2633\n",
      "-0.1340\n",
      " 0.5423\n",
      " 0.2103\n",
      "-0.1000\n",
      "-0.0168\n",
      "-0.1900\n",
      " 0.2341\n",
      " 0.0275\n",
      " 0.4353\n",
      "-0.0914\n",
      " 0.6422\n",
      "-0.1002\n",
      " 0.0553\n",
      "-0.2111\n",
      " 0.7432\n",
      "-0.2330\n",
      "-0.1147\n",
      "-0.1596\n",
      "[torch.FloatTensor of size 64]\n",
      "\n",
      "Parameter containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.1108  0.2362  0.1166  0.1471  0.1637  0.1216  0.0984 -0.0386  0.1957  0.0002\n",
      "-0.1689 -0.0403 -0.1897 -0.2956 -0.1711 -0.0642 -0.1383  0.1151 -0.2422  0.0238\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.0348  0.2396 -0.1987  0.1657 -0.0997  0.1355  0.2727  0.2942 -0.1095  0.1227\n",
      "-0.0745 -0.2234  0.2615 -0.2315  0.0290 -0.2722 -0.2528 -0.2625  0.0826 -0.0852\n",
      "\n",
      "Columns 20 to 29 \n",
      " 0.3039  0.1113  0.2377  0.1475  0.3029  0.1917  0.1062  0.1305 -0.3543  0.0684\n",
      "-0.1318 -0.2526 -0.3267 -0.1109 -0.1122 -0.2755 -0.1176 -0.2730  0.3080 -0.2560\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.0083  0.1529  0.2450  0.0943  0.1841  0.2433  0.2443  0.1751  0.0225  0.2745\n",
      "-0.0863 -0.3148 -0.2159 -0.2302 -0.1402 -0.3085 -0.2249 -0.1700 -0.0731 -0.1067\n",
      "\n",
      "Columns 40 to 49 \n",
      " 0.1715  0.0768  0.0464 -0.1184  0.1720  0.1774 -0.1112  0.3310  0.1742  0.0889\n",
      "-0.2045  0.0097 -0.1989 -0.0497 -0.0980 -0.2981  0.2150 -0.2759 -0.0712 -0.1235\n",
      "\n",
      "Columns 50 to 59 \n",
      "-0.0195  0.2314  0.2056 -0.0758  0.2306  0.0454  0.3393  0.2117 -0.0782  0.0770\n",
      "-0.1246 -0.2977 -0.0827 -0.0911 -0.1496 -0.1873 -0.1130 -0.1965 -0.0125 -0.2353\n",
      "\n",
      "Columns 60 to 63 \n",
      " 0.2216  0.0618  0.1708  0.1256\n",
      "-0.2216 -0.0573 -0.0929 -0.3105\n",
      "[torch.FloatTensor of size 2x64]\n",
      "\n",
      "Parameter containing:\n",
      " 0.2981\n",
      "-0.1434\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "Parameter containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.1542  0.0059 -0.1331 -0.0860 -0.1216 -0.1954 -0.0950  0.0922 -0.0104 -0.1338\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.0550 -0.1074 -0.0320 -0.1363 -0.1445 -0.1597 -0.1148 -0.0057 -0.1185  0.0015\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.0029 -0.1098  0.0038 -0.0393 -0.0036 -0.2325 -0.0733 -0.1391  0.0033 -0.1072\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.0728 -0.0069 -0.2561  0.0029 -0.1428 -0.0201 -0.0743 -0.1423  0.0002 -0.1143\n",
      "\n",
      "Columns 40 to 49 \n",
      "-0.1002  0.0125 -0.0032 -0.0463 -0.0575 -0.0600  0.2566 -0.2908 -0.0042 -0.1790\n",
      "\n",
      "Columns 50 to 59 \n",
      "-0.0515 -0.1078 -0.0037  0.0154 -0.1006 -0.1397 -0.2682 -0.0965  0.0226 -0.1548\n",
      "\n",
      "Columns 60 to 63 \n",
      "-0.3564 -0.1709 -0.0126 -0.0906\n",
      "[torch.FloatTensor of size 1x64]\n",
      "\n",
      "Parameter containing:\n",
      "-0.7832\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in model.parameters():\n",
    "    print(m)\n",
    "    \n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-f8d72bf760d7>:47: SyntaxWarning: name 'rewards' is used prior to global declaration\n",
      "  global rewards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.6068\n",
      "  7.9205\n",
      "  7.6224\n",
      "  7.4608\n",
      "  7.2973\n",
      "  7.0543\n",
      "  7.3635\n",
      "  7.0835\n",
      "  7.0164\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "1.00000e-02 *\n",
      "  1.7147\n",
      "  0.8240\n",
      " -0.4366\n",
      "  0.9157\n",
      " -0.3619\n",
      " -1.5582\n",
      " -2.8787\n",
      " -1.4416\n",
      " -2.8260\n",
      " -4.3563\n",
      " -6.3431\n",
      " -4.5636\n",
      " -3.1507\n",
      " -1.8324\n",
      " -1.0697\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  21\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.0258\n",
      "-0.0393\n",
      "-0.0621\n",
      "-0.0392\n",
      "-0.0624\n",
      "-0.0400\n",
      "-0.0634\n",
      "-0.0857\n",
      "-0.0655\n",
      "-0.0881\n",
      "-0.1121\n",
      "-0.0920\n",
      "-0.0736\n",
      "-0.0541\n",
      "-0.0368\n",
      "-0.0273\n",
      "-0.0335\n",
      "-0.0496\n",
      "-0.0287\n",
      "-0.0331\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  44\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.0809\n",
      "-0.0921\n",
      "-0.1213\n",
      "-0.0878\n",
      "-0.1142\n",
      "-0.1546\n",
      "-0.2045\n",
      "-0.2619\n",
      "-0.3211\n",
      "-0.3849\n",
      "-0.3123\n",
      "-0.3787\n",
      "-0.3092\n",
      "-0.3776\n",
      "-0.4494\n",
      "-0.3830\n",
      "-0.4602\n",
      "-0.3978\n",
      "-0.3359\n",
      "-0.4193\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.1469\n",
      "-0.1944\n",
      "-0.1491\n",
      "-0.1983\n",
      "-0.1517\n",
      "-0.2031\n",
      "-0.2773\n",
      "-0.3682\n",
      "-0.4708\n",
      "-0.5819\n",
      "-0.4937\n",
      "-0.4092\n",
      "-0.3328\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.2168\n",
      "-0.2871\n",
      "-0.3881\n",
      "-0.2931\n",
      "-0.3960\n",
      "-0.5228\n",
      "-0.6683\n",
      "-0.8253\n",
      "-0.9880\n",
      "-1.1563\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  27\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.2548\n",
      "-0.2825\n",
      "-0.2539\n",
      "-0.2774\n",
      "-0.2531\n",
      "-0.2730\n",
      "-0.2542\n",
      "-0.2678\n",
      "-0.3370\n",
      "-0.4504\n",
      "-0.5949\n",
      "-0.7540\n",
      "-0.9392\n",
      "-1.1382\n",
      "-1.3457\n",
      "-1.1547\n",
      "-1.3739\n",
      "-1.1940\n",
      "-1.0252\n",
      "-1.2535\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.3730\n",
      "-0.5061\n",
      "-0.6908\n",
      "-0.9253\n",
      "-1.1933\n",
      "-0.9640\n",
      "-1.2445\n",
      "-1.0218\n",
      "-0.8142\n",
      "-0.6454\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.4005\n",
      "-0.4061\n",
      "-0.4014\n",
      "-0.4033\n",
      "-0.4038\n",
      "-0.4625\n",
      "-0.4094\n",
      "-0.3953\n",
      "-0.4436\n",
      "-0.5910\n",
      "-0.8034\n",
      "-1.0660\n",
      "-1.3484\n",
      "-1.6697\n",
      "-2.0129\n",
      "-2.3706\n",
      "-2.7421\n",
      "-3.1247\n",
      "-3.5199\n",
      "-3.9285\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  23\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.4976\n",
      "-0.6158\n",
      "-0.8681\n",
      "-0.6245\n",
      "-0.5037\n",
      "-0.4724\n",
      "-0.5041\n",
      "-0.6382\n",
      "-0.5054\n",
      "-0.6430\n",
      "-0.9087\n",
      "-1.2483\n",
      "-1.6504\n",
      "-2.0997\n",
      "-1.6998\n",
      "-2.1661\n",
      "-1.7822\n",
      "-1.4190\n",
      "-1.8971\n",
      "-2.3974\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.7110\n",
      "-1.0035\n",
      "-1.3896\n",
      "-1.8574\n",
      "-2.3809\n",
      "-2.9504\n",
      "-3.5472\n",
      "-4.1655\n",
      "-4.8009\n",
      "-5.4548\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.8694\n",
      "-0.6842\n",
      "-0.6425\n",
      "-0.7114\n",
      "-0.8103\n",
      "-0.7232\n",
      "-0.6630\n",
      "-0.6528\n",
      "-0.6795\n",
      "-0.7677\n",
      "-0.8864\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  20\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.0691\n",
      "-1.5471\n",
      "-1.0561\n",
      "-0.8282\n",
      "-1.0417\n",
      "-1.5032\n",
      "-2.0990\n",
      "-1.4880\n",
      "-1.0284\n",
      "-0.8224\n",
      "-1.0219\n",
      "-1.4706\n",
      "-2.0631\n",
      "-2.7791\n",
      "-3.5824\n",
      "-4.4567\n",
      "-5.3701\n",
      "-6.3138\n",
      "-7.2832\n",
      "-8.2808\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.1798\n",
      "-1.7098\n",
      "-1.1651\n",
      "-1.6871\n",
      "-1.1537\n",
      "-1.6675\n",
      "-1.1451\n",
      "-0.9404\n",
      "-0.9208\n",
      "-1.0162\n",
      "-1.1487\n",
      "-1.3009\n",
      "-1.4639\n",
      "-1.6330\n",
      "-1.5127\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.5849\n",
      " -2.3035\n",
      " -3.2207\n",
      " -4.3026\n",
      " -5.5164\n",
      " -6.8050\n",
      " -8.1419\n",
      " -9.5154\n",
      "-10.9256\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  8\n",
      "\n",
      "Rewards [-7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.7806\n",
      " -2.6052\n",
      " -3.6916\n",
      " -4.9972\n",
      " -6.4559\n",
      " -7.9988\n",
      " -9.5978\n",
      "-11.2375\n",
      "[torch.FloatTensor of size 8x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0078\n",
      " -2.9215\n",
      " -4.1256\n",
      " -5.5809\n",
      " -7.2364\n",
      " -9.0039\n",
      "-10.8463\n",
      "-12.7352\n",
      "-14.6723\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  19\n",
      "\n",
      "Rewards [4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.4803\n",
      " -3.5879\n",
      " -2.4509\n",
      " -1.8784\n",
      " -2.4194\n",
      " -1.8616\n",
      " -1.6786\n",
      " -1.8302\n",
      " -2.3135\n",
      " -3.3292\n",
      " -4.6456\n",
      " -6.2039\n",
      " -7.9769\n",
      " -9.8937\n",
      "-11.9245\n",
      "-14.0133\n",
      "-16.1599\n",
      "-18.3698\n",
      "-20.6545\n",
      "[torch.FloatTensor of size 19x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.6988\n",
      " -3.9362\n",
      " -5.5524\n",
      " -7.4621\n",
      " -9.6406\n",
      "-11.9811\n",
      "-14.4210\n",
      "-16.9205\n",
      "-19.4868\n",
      "-22.1256\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1735\n",
      " -4.6573\n",
      " -6.5965\n",
      " -8.8639\n",
      "-11.4263\n",
      "-14.1417\n",
      "-16.9649\n",
      "-19.8592\n",
      "-22.8329\n",
      "-25.8926\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1852\n",
      " -4.7003\n",
      " -6.7058\n",
      " -9.1141\n",
      "-11.8531\n",
      "-14.7972\n",
      "-17.8695\n",
      "-21.0261\n",
      "-24.2699\n",
      "-27.6085\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.6381\n",
      " -2.7181\n",
      " -3.5738\n",
      " -5.2558\n",
      " -7.4666\n",
      "-10.0543\n",
      "-13.0066\n",
      "-16.1794\n",
      "-19.4931\n",
      "-22.8890\n",
      "-26.3778\n",
      "-29.9703\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.9112\n",
      " -5.7582\n",
      " -8.1537\n",
      "-10.9444\n",
      "-14.0898\n",
      "-17.4182\n",
      "-20.8925\n",
      "-24.4572\n",
      "-28.1229\n",
      "-31.9041\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  17\n",
      "\n",
      "Rewards [3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-4.1764\n",
      "-3.1369\n",
      "-2.7096\n",
      "-2.8394\n",
      "-3.1477\n",
      "-2.8277\n",
      "-3.1491\n",
      "-3.5456\n",
      "-4.0138\n",
      "-3.6190\n",
      "-3.2401\n",
      "-2.9211\n",
      "-2.7139\n",
      "-2.6614\n",
      "-3.1486\n",
      "-2.6599\n",
      "-2.9405\n",
      "[torch.FloatTensor of size 17x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.3904\n",
      " -3.3285\n",
      " -4.4751\n",
      " -6.5885\n",
      " -9.3958\n",
      "-12.6677\n",
      "-16.2795\n",
      "-20.0469\n",
      "-23.9325\n",
      "-27.9115\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4145\n",
      " -3.3937\n",
      " -4.4106\n",
      " -6.3815\n",
      " -8.9678\n",
      "-12.0326\n",
      "-15.4863\n",
      "-19.1295\n",
      "-22.9162\n",
      "-26.7978\n",
      "-30.7855\n",
      "-34.8874\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  30\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2221\n",
      " -3.5862\n",
      " -3.2647\n",
      " -3.2384\n",
      " -3.7386\n",
      " -4.9146\n",
      " -6.8620\n",
      " -4.6596\n",
      " -6.4620\n",
      " -8.7612\n",
      "-11.3958\n",
      "-14.2173\n",
      "-17.3190\n",
      "-20.6457\n",
      "-24.1064\n",
      "-20.6674\n",
      "-24.3016\n",
      "-28.0445\n",
      "-31.9027\n",
      "-35.8855\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.3194\n",
      " -6.0876\n",
      " -8.4202\n",
      "-11.2682\n",
      "-14.4748\n",
      "-11.3842\n",
      "-14.6961\n",
      "-18.2729\n",
      "-21.9720\n",
      "-25.7683\n",
      "-29.6677\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.3731\n",
      " -6.1593\n",
      " -8.5586\n",
      "-11.4633\n",
      " -8.7364\n",
      "-11.7619\n",
      "-15.1517\n",
      "-18.6942\n",
      "-22.3744\n",
      "-19.5706\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  33\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.0249\n",
      " -4.3092\n",
      " -3.5366\n",
      " -3.4072\n",
      " -3.7679\n",
      " -3.4304\n",
      " -3.4607\n",
      " -4.0046\n",
      " -5.3201\n",
      " -7.2701\n",
      " -9.6001\n",
      "-12.2124\n",
      "-15.1407\n",
      "-18.2671\n",
      "-21.5449\n",
      "-18.3873\n",
      "-21.8311\n",
      "-25.3662\n",
      "-28.9986\n",
      "-32.7356\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  18\n",
      "\n",
      "Rewards [3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4183\n",
      " -3.5817\n",
      " -4.3709\n",
      " -5.9944\n",
      " -4.3266\n",
      " -5.9329\n",
      " -4.2917\n",
      " -5.8852\n",
      " -4.2650\n",
      " -5.8493\n",
      " -7.9819\n",
      "-10.5833\n",
      "-13.5777\n",
      "-16.7795\n",
      "-20.1263\n",
      "-23.5761\n",
      "-27.1211\n",
      "-30.7672\n",
      "[torch.FloatTensor of size 18x1]\n",
      "\n",
      "Training. Score was  24\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4625\n",
      " -3.6233\n",
      " -4.4828\n",
      " -3.6239\n",
      " -4.4962\n",
      " -3.6223\n",
      " -4.5023\n",
      " -6.1801\n",
      " -4.5137\n",
      " -6.2068\n",
      " -8.4680\n",
      "-11.1516\n",
      " -8.6125\n",
      "-11.4086\n",
      "-14.5446\n",
      "-11.8628\n",
      "-15.0990\n",
      "-12.5386\n",
      "-15.8780\n",
      "-13.4530\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.1505\n",
      " -5.6728\n",
      " -4.1098\n",
      " -5.6158\n",
      " -7.5953\n",
      "-10.0127\n",
      "-12.7541\n",
      "-15.7047\n",
      "-18.7901\n",
      "-21.9663\n",
      "-25.2353\n",
      "-22.7525\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  36\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.3390\n",
      " -3.5862\n",
      " -4.5201\n",
      " -3.6559\n",
      " -4.7515\n",
      " -6.7114\n",
      " -9.2179\n",
      " -7.1180\n",
      " -5.4306\n",
      " -4.1945\n",
      " -5.8349\n",
      " -4.4629\n",
      " -3.6861\n",
      " -4.7823\n",
      " -3.8728\n",
      " -3.3853\n",
      " -4.0808\n",
      " -5.5803\n",
      " -7.9346\n",
      "-10.8578\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  17\n",
      "\n",
      "Rewards [3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.8292\n",
      "-3.2042\n",
      "-3.0910\n",
      "-3.1664\n",
      "-3.1185\n",
      "-3.5409\n",
      "-3.1731\n",
      "-3.1130\n",
      "-3.2552\n",
      "-3.7327\n",
      "-3.3692\n",
      "-3.1723\n",
      "-3.2592\n",
      "-3.7980\n",
      "-4.8668\n",
      "-3.6587\n",
      "-4.4955\n",
      "[torch.FloatTensor of size 17x1]\n",
      "\n",
      "Training. Score was  24\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.5526\n",
      "-3.0573\n",
      "-3.4742\n",
      "-4.5846\n",
      "-3.4006\n",
      "-3.0473\n",
      "-3.2289\n",
      "-3.0535\n",
      "-3.2853\n",
      "-4.0439\n",
      "-3.2308\n",
      "-3.8980\n",
      "-3.1922\n",
      "-3.1796\n",
      "-3.1869\n",
      "-3.6032\n",
      "-3.2081\n",
      "-3.3871\n",
      "-3.8485\n",
      "-3.5234\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  19\n",
      "\n",
      "Rewards [4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.6565\n",
      "-3.1612\n",
      "-3.1342\n",
      "-3.5649\n",
      "-4.0882\n",
      "-3.6212\n",
      "-3.2229\n",
      "-3.0999\n",
      "-3.3171\n",
      "-3.1233\n",
      "-3.2976\n",
      "-3.9493\n",
      "-5.1940\n",
      "-3.7784\n",
      "-3.2545\n",
      "-3.3791\n",
      "-3.2952\n",
      "-3.5157\n",
      "-3.3648\n",
      "[torch.FloatTensor of size 19x1]\n",
      "\n",
      "Training. Score was  21\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.2946\n",
      "-3.7910\n",
      "-5.1016\n",
      "-3.8306\n",
      "-5.1738\n",
      "-3.8779\n",
      "-3.3239\n",
      "-3.2137\n",
      "-3.5507\n",
      "-4.0394\n",
      "-3.5540\n",
      "-4.0643\n",
      "-3.5899\n",
      "-3.2236\n",
      "-3.6531\n",
      "-4.2164\n",
      "-3.7512\n",
      "-4.3482\n",
      "-3.8940\n",
      "-4.5313\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.9034\n",
      "-3.3839\n",
      "-3.3757\n",
      "-3.7984\n",
      "-4.3516\n",
      "-4.9747\n",
      "-5.6567\n",
      "-6.3765\n",
      "-5.8214\n",
      "-5.2904\n",
      "-4.7814\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.9274\n",
      "-3.5430\n",
      "-3.5814\n",
      "-4.0565\n",
      "-3.5697\n",
      "-4.0562\n",
      "-4.6847\n",
      "-5.3794\n",
      "-6.1327\n",
      "-6.9314\n",
      "-7.7556\n",
      "-8.6041\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  16\n",
      "\n",
      "Rewards [2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.9612\n",
      "-3.7483\n",
      "-3.9826\n",
      "-4.6536\n",
      "-4.0165\n",
      "-3.7475\n",
      "-3.8979\n",
      "-4.7679\n",
      "-3.8705\n",
      "-3.8011\n",
      "-4.2299\n",
      "-4.9656\n",
      "-5.7750\n",
      "-6.6444\n",
      "-7.5673\n",
      "-8.5188\n",
      "[torch.FloatTensor of size 16x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.2322\n",
      " -5.2703\n",
      " -4.2595\n",
      " -4.0015\n",
      " -4.2062\n",
      " -4.8682\n",
      " -5.6527\n",
      " -6.5087\n",
      " -7.4186\n",
      " -8.3862\n",
      " -9.3913\n",
      "-10.4310\n",
      "-11.5102\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4846\n",
      " -4.2652\n",
      " -4.5372\n",
      " -5.3091\n",
      " -6.2296\n",
      " -7.2256\n",
      " -8.2756\n",
      " -9.3873\n",
      " -8.4897\n",
      " -9.6653\n",
      "-10.8769\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.7058\n",
      " -5.7644\n",
      " -4.7219\n",
      " -4.5533\n",
      " -4.9206\n",
      " -5.7989\n",
      " -6.8448\n",
      " -7.9749\n",
      " -9.1584\n",
      "-10.4080\n",
      "-11.7097\n",
      "-13.0565\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.0033\n",
      " -5.0104\n",
      " -5.6253\n",
      " -6.7787\n",
      " -8.0700\n",
      " -9.4217\n",
      "-10.8587\n",
      "-12.3595\n",
      "-13.9038\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  14\n",
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.2286\n",
      " -5.9830\n",
      " -5.2287\n",
      " -5.4721\n",
      " -6.2834\n",
      " -7.6305\n",
      " -6.3636\n",
      " -5.5416\n",
      " -6.4989\n",
      " -7.9201\n",
      " -9.4525\n",
      "-11.0510\n",
      "-12.7472\n",
      "-14.4966\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.5946\n",
      " -5.8781\n",
      " -6.7690\n",
      " -8.2499\n",
      " -9.8842\n",
      "-11.6103\n",
      "-13.4005\n",
      "-15.2725\n",
      "-17.2096\n",
      "-19.2135\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.9862\n",
      " -6.6257\n",
      " -7.9799\n",
      " -9.8217\n",
      "-11.7825\n",
      "-13.8253\n",
      "-15.9654\n",
      "-18.1790\n",
      "-20.4559\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.4533\n",
      " -6.8988\n",
      " -8.2018\n",
      " -6.8829\n",
      " -6.4439\n",
      " -7.1209\n",
      " -8.5159\n",
      "-10.5187\n",
      "-12.6658\n",
      "-14.9178\n",
      "-17.2530\n",
      "-19.6823\n",
      "-22.1921\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.7093\n",
      " -7.4211\n",
      " -8.8784\n",
      "-11.0103\n",
      "-13.3622\n",
      "-15.8029\n",
      "-18.3149\n",
      "-20.9350\n",
      "-23.6549\n",
      "-26.4752\n",
      "-29.3923\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.0381\n",
      " -8.0130\n",
      " -9.7918\n",
      "-12.2185\n",
      "-14.8588\n",
      "-17.5929\n",
      "-20.4079\n",
      "-23.3348\n",
      "-26.3694\n",
      "-29.5136\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.3029\n",
      " -8.6369\n",
      "-10.7998\n",
      "-13.5483\n",
      "-10.9515\n",
      "-13.7604\n",
      "-16.7342\n",
      "-19.7939\n",
      "-22.9583\n",
      "-26.2320\n",
      "-29.6080\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.4018\n",
      " -8.8118\n",
      "-11.1102\n",
      "-13.9797\n",
      "-17.0244\n",
      "-20.1603\n",
      "-23.3969\n",
      "-26.7462\n",
      "-30.2110\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.5295\n",
      " -7.2422\n",
      " -7.5606\n",
      " -7.2407\n",
      " -7.5840\n",
      " -9.2104\n",
      "-11.6985\n",
      "-14.7061\n",
      "-17.8736\n",
      "-21.1310\n",
      "-24.4971\n",
      "-27.9764\n",
      "-31.5712\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.3474\n",
      " -8.8616\n",
      "-11.2995\n",
      "-14.3254\n",
      "-17.5207\n",
      "-20.8184\n",
      "-24.2181\n",
      "-27.7305\n",
      "-31.3569\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.3107\n",
      " -8.9666\n",
      "-11.4865\n",
      "-14.5450\n",
      "-17.7757\n",
      "-21.1021\n",
      "-24.5337\n",
      "-28.0765\n",
      "-31.7278\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.9613\n",
      " -8.3518\n",
      "-10.5777\n",
      "-13.3992\n",
      "-16.4422\n",
      "-19.5788\n",
      "-22.8025\n",
      "-26.1445\n",
      "-29.5972\n",
      "-33.1751\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.6090\n",
      " -7.7727\n",
      " -9.7873\n",
      "-12.4505\n",
      "-15.3517\n",
      "-18.3436\n",
      "-21.4160\n",
      "-24.6057\n",
      "-27.8994\n",
      "-31.3153\n",
      "-34.8484\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  14\n",
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.7766\n",
      " -6.3378\n",
      " -6.8669\n",
      " -8.5899\n",
      " -6.9968\n",
      " -6.3608\n",
      " -7.1142\n",
      " -8.9588\n",
      "-11.5342\n",
      "-14.4847\n",
      "-17.5425\n",
      "-20.7091\n",
      "-23.9817\n",
      "-27.3461\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.1278\n",
      " -7.4355\n",
      " -9.4525\n",
      "-12.0026\n",
      "-14.7221\n",
      "-17.5336\n",
      "-20.4227\n",
      "-23.4156\n",
      "-26.5067\n",
      "-29.7054\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.8661\n",
      " -5.8250\n",
      " -5.8989\n",
      " -7.3222\n",
      " -9.4671\n",
      "-12.0566\n",
      "-14.7790\n",
      "-17.5916\n",
      "-20.4891\n",
      "-23.4760\n",
      "-26.5508\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.5254\n",
      " -6.8635\n",
      " -8.8556\n",
      "-11.2639\n",
      " -9.0008\n",
      "-11.4694\n",
      "-14.0522\n",
      "-16.7263\n",
      "-19.4825\n",
      "-22.3199\n",
      "-25.2385\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.1100\n",
      " -5.2591\n",
      " -5.1343\n",
      " -6.3363\n",
      " -8.1976\n",
      "-10.4677\n",
      "-12.8793\n",
      "-15.3759\n",
      "-17.9452\n",
      "-20.5941\n",
      "-23.3212\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.8690\n",
      " -5.9027\n",
      " -7.5476\n",
      " -9.6208\n",
      "-11.8291\n",
      "-14.1266\n",
      "-16.4888\n",
      "-18.9304\n",
      "-21.4492\n",
      "-24.0498\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.5587\n",
      " -5.5732\n",
      " -4.5718\n",
      " -5.6014\n",
      " -4.5906\n",
      " -4.8671\n",
      " -4.5968\n",
      " -5.6465\n",
      " -7.3193\n",
      " -9.4159\n",
      "-11.6519\n",
      "-13.9712\n",
      "-16.3552\n",
      "-18.8119\n",
      "-21.3408\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4355\n",
      " -5.4437\n",
      " -7.0517\n",
      " -9.0650\n",
      "-11.2201\n",
      "-13.4538\n",
      "-15.7488\n",
      "-18.1185\n",
      "-20.5602\n",
      "-23.0811\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.2633\n",
      " -5.3282\n",
      " -7.0074\n",
      " -9.0904\n",
      "-11.3181\n",
      "-13.6156\n",
      "-15.9745\n",
      "-18.4044\n",
      "-20.9047\n",
      "-23.4828\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4121\n",
      " -4.3877\n",
      " -5.1817\n",
      " -4.3918\n",
      " -4.2809\n",
      " -5.4594\n",
      " -7.1746\n",
      " -9.2672\n",
      "-11.4827\n",
      " -9.3507\n",
      "-11.6319\n",
      "-13.9887\n",
      "-16.4115\n",
      "-18.9013\n",
      "-21.4627\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.2621\n",
      " -4.3477\n",
      " -4.3062\n",
      " -5.7024\n",
      " -7.7103\n",
      "-10.0048\n",
      "-12.4347\n",
      "-10.3627\n",
      "-12.8589\n",
      "-15.4313\n",
      "-13.5140\n",
      "-16.1691\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.1419\n",
      " -5.2434\n",
      " -4.1165\n",
      " -5.1540\n",
      " -6.8826\n",
      " -9.1064\n",
      "-11.4848\n",
      "-13.9360\n",
      "-16.4490\n",
      "-19.0358\n",
      "-16.9135\n",
      "-19.6230\n",
      "-22.4044\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.0789\n",
      " -4.2145\n",
      " -5.1566\n",
      " -4.2567\n",
      " -5.3048\n",
      " -7.1728\n",
      " -5.5398\n",
      " -7.5556\n",
      " -9.8275\n",
      " -8.1008\n",
      "-10.4550\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  24\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.2093\n",
      " -5.6415\n",
      " -4.2382\n",
      " -5.7193\n",
      " -4.2828\n",
      " -5.8257\n",
      " -4.3579\n",
      " -4.2504\n",
      " -4.4292\n",
      " -6.0632\n",
      " -8.3080\n",
      "-10.8608\n",
      " -8.6298\n",
      "-11.2587\n",
      " -9.0921\n",
      " -7.1561\n",
      " -9.6495\n",
      "-12.4287\n",
      "-15.2879\n",
      "-18.2130\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  48\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-12.0709\n",
      " -9.6853\n",
      " -7.4649\n",
      " -5.6382\n",
      " -4.3304\n",
      " -4.2955\n",
      " -4.5001\n",
      " -6.2189\n",
      " -4.7358\n",
      " -4.2120\n",
      " -4.9779\n",
      " -4.2302\n",
      " -5.2526\n",
      " -7.2653\n",
      " -5.5836\n",
      " -7.7029\n",
      "-10.3026\n",
      "-13.1631\n",
      "-16.0848\n",
      "-19.0709\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  44\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -9.3667\n",
      " -6.8977\n",
      " -4.8834\n",
      " -6.8511\n",
      " -9.2827\n",
      " -6.8573\n",
      " -4.9395\n",
      " -6.8901\n",
      " -4.9921\n",
      " -6.9514\n",
      " -9.4909\n",
      " -7.0886\n",
      " -9.6851\n",
      "-12.4665\n",
      "-10.0104\n",
      "-12.8512\n",
      "-15.7731\n",
      "-18.7551\n",
      "-21.7897\n",
      "-19.6524\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  51\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-4.0163\n",
      "-5.2484\n",
      "-4.0612\n",
      "-5.3967\n",
      "-7.6465\n",
      "-5.6259\n",
      "-7.9755\n",
      "-5.9443\n",
      "-8.4034\n",
      "-6.3845\n",
      "-4.8418\n",
      "-6.9013\n",
      "-5.2932\n",
      "-4.4684\n",
      "-5.7659\n",
      "-8.0960\n",
      "-6.3873\n",
      "-5.0533\n",
      "-7.0537\n",
      "-9.6718\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.6826\n",
      " -3.8662\n",
      " -4.8165\n",
      " -6.3939\n",
      " -8.3700\n",
      "-10.5136\n",
      "-12.7251\n",
      "-15.0515\n",
      "-17.4557\n",
      "-15.6109\n",
      "-18.1526\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  36\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.2231\n",
      " -4.6329\n",
      " -5.5637\n",
      " -4.5293\n",
      " -5.2791\n",
      " -6.5966\n",
      " -5.0590\n",
      " -4.5972\n",
      " -4.9570\n",
      " -6.0649\n",
      " -7.5839\n",
      " -9.2358\n",
      "-11.0674\n",
      "-12.9994\n",
      "-15.0747\n",
      "-17.2568\n",
      "-19.5273\n",
      "-21.9097\n",
      "-24.3907\n",
      "-27.0061\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  43\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.3891\n",
      " -4.2174\n",
      " -4.3561\n",
      " -4.3707\n",
      " -5.8681\n",
      " -4.5734\n",
      " -4.4280\n",
      " -4.9052\n",
      " -4.4937\n",
      " -4.8316\n",
      " -5.9603\n",
      " -7.5083\n",
      " -9.1865\n",
      "-11.0603\n",
      "-13.0287\n",
      "-15.1580\n",
      "-17.3738\n",
      "-19.6978\n",
      "-22.1146\n",
      "-24.6549\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2262\n",
      " -4.4692\n",
      " -3.1854\n",
      " -3.4021\n",
      " -4.5365\n",
      " -6.4119\n",
      " -8.6028\n",
      "-10.9052\n",
      "-13.3203\n",
      "-15.8072\n",
      "-18.3629\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0528\n",
      " -3.3034\n",
      " -4.5424\n",
      " -6.4559\n",
      " -4.7267\n",
      " -6.7921\n",
      " -9.1253\n",
      "-11.5651\n",
      " -9.7437\n",
      " -8.0185\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0397\n",
      " -3.3088\n",
      " -3.0511\n",
      " -3.2731\n",
      " -4.3703\n",
      " -6.1250\n",
      " -4.3462\n",
      " -6.1695\n",
      " -8.3834\n",
      "-10.7302\n",
      "-13.1751\n",
      "-15.7084\n",
      "-18.3158\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1046\n",
      " -3.1685\n",
      " -4.2889\n",
      " -6.1697\n",
      " -8.4891\n",
      "-10.9659\n",
      "-13.5380\n",
      "-16.2054\n",
      "-18.9496\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1054\n",
      " -3.3314\n",
      " -4.5766\n",
      " -6.5879\n",
      " -9.0073\n",
      "-11.6091\n",
      "-14.2977\n",
      "-17.0962\n",
      "-19.9781\n",
      "-22.9500\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0326\n",
      " -3.6216\n",
      " -5.2950\n",
      " -7.7687\n",
      "-10.5990\n",
      "-13.5440\n",
      "-16.5994\n",
      "-19.7437\n",
      "-22.9771\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  14\n",
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1831\n",
      " -4.5125\n",
      " -3.2003\n",
      " -4.5991\n",
      " -3.2235\n",
      " -3.6843\n",
      " -5.2846\n",
      " -7.6955\n",
      "-10.5925\n",
      "-13.6489\n",
      "-16.8134\n",
      "-20.1008\n",
      "-23.4878\n",
      "-26.9822\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2616\n",
      " -4.0429\n",
      " -5.8779\n",
      " -8.4723\n",
      "-11.5339\n",
      "-14.7387\n",
      "-18.0538\n",
      "-21.5042\n",
      "-25.0622\n",
      "-28.7366\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1878\n",
      " -3.9196\n",
      " -5.9213\n",
      " -8.8077\n",
      "-12.1477\n",
      "-15.6194\n",
      "-19.2091\n",
      "-22.9165\n",
      "-26.7317\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2750\n",
      " -4.0457\n",
      " -6.0662\n",
      " -8.9516\n",
      "-12.3397\n",
      "-15.8730\n",
      "-19.5319\n",
      "-23.3200\n",
      "-27.2217\n",
      "-31.2459\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.3215\n",
      " -4.4150\n",
      " -6.6501\n",
      " -9.6547\n",
      "-13.1273\n",
      "-16.7121\n",
      "-20.4303\n",
      "-24.2803\n",
      "-28.2479\n",
      "-32.3420\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2930\n",
      " -4.3358\n",
      " -3.2931\n",
      " -4.2931\n",
      " -6.4361\n",
      " -9.4153\n",
      " -6.4641\n",
      " -9.5603\n",
      "-13.0971\n",
      "-16.7629\n",
      "-20.5644\n",
      "-24.4876\n",
      "-28.5238\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2446\n",
      " -4.2418\n",
      " -6.3438\n",
      " -9.2060\n",
      "-12.5395\n",
      "-16.0161\n",
      "-19.6100\n",
      "-23.3408\n",
      "-27.1880\n",
      "-31.1604\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1557\n",
      " -3.9926\n",
      " -3.1621\n",
      " -3.9709\n",
      " -5.9553\n",
      " -8.7777\n",
      "-12.0618\n",
      "-15.4911\n",
      "-19.0295\n",
      "-22.6990\n",
      "-26.4771\n",
      "-30.3725\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  14\n",
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0668\n",
      " -4.4835\n",
      " -3.0929\n",
      " -4.5650\n",
      " -3.1386\n",
      " -3.6359\n",
      " -5.3897\n",
      " -7.9515\n",
      "-10.9909\n",
      "-14.2232\n",
      "-17.5555\n",
      "-21.0015\n",
      "-24.5637\n",
      "-28.2386\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8975\n",
      " -3.8255\n",
      " -5.7837\n",
      " -8.4629\n",
      "-11.5005\n",
      "-14.6415\n",
      "-17.8923\n",
      "-21.2498\n",
      "-24.7047\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8064\n",
      " -3.9135\n",
      " -6.0007\n",
      " -8.7217\n",
      "-11.7176\n",
      "-14.8120\n",
      "-17.9989\n",
      "-21.2870\n",
      "-24.6694\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8425\n",
      " -3.7165\n",
      " -5.4748\n",
      " -7.8085\n",
      "-10.5226\n",
      "-13.3704\n",
      "-16.3172\n",
      "-19.3594\n",
      "-22.5097\n",
      "-25.7645\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8122\n",
      " -3.7241\n",
      " -5.5929\n",
      " -8.0666\n",
      "-10.9065\n",
      "-13.8548\n",
      "-16.8929\n",
      "-20.0280\n",
      "-23.2643\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8499\n",
      " -3.7999\n",
      " -5.7458\n",
      " -8.4111\n",
      "-11.3966\n",
      "-14.4786\n",
      "-17.6555\n",
      "-20.9322\n",
      "-24.3011\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.9634\n",
      " -4.0188\n",
      " -6.0180\n",
      " -4.0553\n",
      " -6.1089\n",
      " -8.8435\n",
      "-11.8887\n",
      "-15.0355\n",
      "-18.2857\n",
      "-21.6389\n",
      "-25.0882\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1287\n",
      " -4.1939\n",
      " -6.1385\n",
      " -8.7638\n",
      "-11.7455\n",
      "-14.8900\n",
      "-18.1110\n",
      "-21.4594\n",
      "-24.9170\n",
      "-28.4859\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1890\n",
      " -4.4334\n",
      " -3.1836\n",
      " -4.4420\n",
      " -6.6651\n",
      " -4.4842\n",
      " -3.1802\n",
      " -4.5552\n",
      " -6.8860\n",
      " -9.8853\n",
      "-13.1788\n",
      "-16.5699\n",
      "-20.0668\n",
      "-23.6721\n",
      "-27.3802\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2316\n",
      " -4.4036\n",
      " -6.5136\n",
      " -9.2674\n",
      "-12.3862\n",
      "-15.6374\n",
      "-18.9855\n",
      "-22.4451\n",
      "-26.0205\n",
      "-29.7110\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2124\n",
      " -4.6230\n",
      " -3.2168\n",
      " -4.6720\n",
      " -7.0339\n",
      "-10.0302\n",
      "-13.3021\n",
      "-16.6720\n",
      "-20.1376\n",
      "-23.7071\n",
      "-27.3838\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1893\n",
      " -3.6760\n",
      " -3.1950\n",
      " -4.5425\n",
      " -3.1899\n",
      " -3.6542\n",
      " -3.1974\n",
      " -4.5685\n",
      " -6.8138\n",
      " -9.6436\n",
      "-12.7717\n",
      "-15.9907\n",
      "-19.3123\n",
      "-22.7325\n",
      "-26.2585\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0213\n",
      " -3.8886\n",
      " -3.0254\n",
      " -4.0973\n",
      " -6.1184\n",
      " -4.1002\n",
      " -6.1571\n",
      " -8.8425\n",
      "-11.8719\n",
      "-15.0032\n",
      "-18.2337\n",
      "-21.5526\n",
      "-24.9756\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  16\n",
      "\n",
      "Rewards [2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.9995\n",
      " -3.6548\n",
      " -5.9789\n",
      " -3.7461\n",
      " -6.1419\n",
      " -3.8813\n",
      " -3.0066\n",
      " -4.0317\n",
      " -5.9354\n",
      " -8.4001\n",
      "-11.1991\n",
      "-14.1662\n",
      "-17.2179\n",
      "-20.3703\n",
      "-23.6256\n",
      "-26.9905\n",
      "[torch.FloatTensor of size 16x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.9877\n",
      " -4.3141\n",
      " -6.4780\n",
      " -9.1166\n",
      " -6.5481\n",
      " -9.2948\n",
      "-12.2984\n",
      "-15.3816\n",
      "-18.5615\n",
      "-21.8298\n",
      "-25.1948\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8941\n",
      " -4.2163\n",
      " -6.3436\n",
      " -8.9478\n",
      "-11.8274\n",
      "-14.8092\n",
      "-17.8741\n",
      "-21.0390\n",
      "-24.3039\n",
      "-27.6714\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8715\n",
      " -4.3593\n",
      " -6.6225\n",
      " -9.3223\n",
      "-12.2525\n",
      "-15.2590\n",
      "-18.3611\n",
      "-21.5494\n",
      "-24.8337\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8572\n",
      " -4.1843\n",
      " -6.2524\n",
      " -4.0665\n",
      " -6.1560\n",
      " -8.6914\n",
      "-11.4907\n",
      "-14.4005\n",
      "-17.3912\n",
      "-20.4789\n",
      "-23.6639\n",
      "-26.9504\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.6706\n",
      " -3.9144\n",
      " -6.0609\n",
      " -8.6730\n",
      "-11.5417\n",
      "-14.4965\n",
      "-17.5426\n",
      "-20.6737\n",
      "-23.8972\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.6617\n",
      " -4.0443\n",
      " -6.2186\n",
      " -8.8313\n",
      "-11.6821\n",
      "-14.6179\n",
      "-17.6381\n",
      "-20.7495\n",
      "-23.9523\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  9\n",
      "\n",
      "Rewards [-5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.7323\n",
      " -4.2772\n",
      " -6.5577\n",
      " -9.2470\n",
      "-12.1566\n",
      "-15.1466\n",
      "-18.2284\n",
      "-21.3956\n",
      "-24.6577\n",
      "[torch.FloatTensor of size 9x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.7504\n",
      " -3.0149\n",
      " -2.7736\n",
      " -4.3747\n",
      " -6.7268\n",
      " -9.5235\n",
      "-12.5516\n",
      "-15.6635\n",
      "-18.8659\n",
      "-22.1540\n",
      "-25.5389\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8340\n",
      " -4.4625\n",
      " -6.9609\n",
      " -4.5827\n",
      " -7.1629\n",
      "-10.1911\n",
      "-13.4324\n",
      "-10.6922\n",
      "-14.0386\n",
      "-17.4683\n",
      "-20.9803\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  11\n",
      "\n",
      "Rewards [-2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.9532\n",
      " -4.4696\n",
      " -6.8243\n",
      " -9.6475\n",
      "-12.7376\n",
      "-15.9798\n",
      "-19.3010\n",
      "-22.7270\n",
      "-19.8424\n",
      "-23.4586\n",
      "-27.1750\n",
      "[torch.FloatTensor of size 11x1]\n",
      "\n",
      "Training. Score was  14\n",
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.9279\n",
      " -3.4447\n",
      " -2.9494\n",
      " -4.6036\n",
      " -2.9572\n",
      " -4.6408\n",
      " -7.2791\n",
      "-10.4005\n",
      " -7.4480\n",
      "-10.6819\n",
      "-14.1893\n",
      "-17.7783\n",
      "-21.4699\n",
      "-25.2553\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  20\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1035\n",
      " -3.5383\n",
      " -3.0563\n",
      " -4.7075\n",
      " -7.3177\n",
      " -4.6057\n",
      " -7.2251\n",
      "-10.3496\n",
      " -7.2340\n",
      " -4.6225\n",
      " -2.9843\n",
      " -4.7202\n",
      " -7.4937\n",
      "-10.8004\n",
      " -7.7392\n",
      "-11.1687\n",
      "-14.8746\n",
      "-18.6583\n",
      "-22.5451\n",
      "-26.5287\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2173\n",
      " -3.2709\n",
      " -3.2236\n",
      " -5.2797\n",
      " -3.2156\n",
      " -5.2870\n",
      " -8.2363\n",
      " -5.3410\n",
      " -8.3536\n",
      "-11.8233\n",
      "-15.5384\n",
      "-19.3434\n",
      "-23.2467\n",
      "-27.2613\n",
      "-31.3894\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  45\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0500\n",
      " -4.2075\n",
      " -6.7945\n",
      " -9.7213\n",
      " -7.0704\n",
      " -4.6628\n",
      " -3.2284\n",
      " -3.5505\n",
      " -5.7387\n",
      " -3.3839\n",
      " -5.4489\n",
      " -8.2111\n",
      "-11.4095\n",
      "-14.8882\n",
      "-18.4912\n",
      "-22.1957\n",
      "-26.0235\n",
      "-22.7883\n",
      "-26.8281\n",
      "-23.8479\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.2016\n",
      " -5.5155\n",
      " -3.3369\n",
      " -5.7466\n",
      " -8.9941\n",
      " -6.0493\n",
      " -3.7657\n",
      " -6.4419\n",
      " -9.8968\n",
      "-13.7435\n",
      "-17.7018\n",
      "-14.6332\n",
      "-18.7354\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0554\n",
      " -4.0442\n",
      " -3.1079\n",
      " -4.2798\n",
      " -3.2122\n",
      " -3.9995\n",
      " -3.3651\n",
      " -3.8005\n",
      " -5.8225\n",
      " -3.6587\n",
      " -5.4787\n",
      " -3.5963\n",
      " -4.1166\n",
      " -3.5573\n",
      " -4.5215\n",
      " -6.8866\n",
      " -9.8054\n",
      "-12.9070\n",
      "-10.7350\n",
      " -8.6515\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  54\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.5092\n",
      "-10.3119\n",
      " -7.6649\n",
      " -5.1449\n",
      " -3.4046\n",
      " -5.3266\n",
      " -8.1808\n",
      " -5.6622\n",
      " -8.5919\n",
      " -6.1507\n",
      " -4.0786\n",
      " -3.1752\n",
      " -4.4925\n",
      " -7.2321\n",
      " -5.0730\n",
      " -7.9244\n",
      " -5.7468\n",
      " -8.7544\n",
      "-11.9516\n",
      "-15.1932\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.9121\n",
      " -3.4315\n",
      " -2.8687\n",
      " -3.5898\n",
      " -6.1110\n",
      " -3.8787\n",
      " -6.4709\n",
      " -9.4376\n",
      "-12.4900\n",
      "-15.6523\n",
      "-18.8678\n",
      "-16.6951\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  23\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1400\n",
      " -3.1326\n",
      " -3.1385\n",
      " -5.1872\n",
      " -3.1792\n",
      " -3.1367\n",
      " -3.2313\n",
      " -3.1010\n",
      " -5.1838\n",
      " -8.2328\n",
      "-11.6753\n",
      "-15.3994\n",
      "-19.2446\n",
      "-23.1836\n",
      "-19.8175\n",
      "-16.5319\n",
      "-13.3245\n",
      "-10.2103\n",
      "-14.4331\n",
      "-11.4128\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.3858\n",
      " -9.6774\n",
      " -6.4803\n",
      " -3.9755\n",
      " -3.0479\n",
      " -4.0529\n",
      " -3.0331\n",
      " -4.2107\n",
      " -6.7183\n",
      " -9.5935\n",
      " -6.9486\n",
      " -9.9181\n",
      " -7.3685\n",
      "-10.4506\n",
      " -7.9867\n",
      "-11.1855\n",
      " -8.8461\n",
      " -6.7488\n",
      " -5.0176\n",
      " -3.8521\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  10\n",
      "\n",
      "Rewards [-3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0814\n",
      " -3.0545\n",
      " -5.3394\n",
      " -8.2806\n",
      " -5.7828\n",
      " -8.8106\n",
      "-11.9822\n",
      "-15.2594\n",
      "-18.5886\n",
      "-16.3767\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "Training. Score was  55\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.5849\n",
      " -5.4490\n",
      " -3.4152\n",
      " -5.0787\n",
      " -3.3099\n",
      " -4.7783\n",
      " -7.0805\n",
      " -4.5640\n",
      " -6.8119\n",
      " -9.3057\n",
      "-12.0681\n",
      "-14.9353\n",
      "-17.8635\n",
      "-15.1841\n",
      "-12.5227\n",
      "-15.6337\n",
      "-18.7882\n",
      "-16.3681\n",
      "-19.6948\n",
      "-23.1355\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  23\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8774\n",
      " -2.9850\n",
      " -5.3183\n",
      " -3.0217\n",
      " -2.8105\n",
      " -4.6062\n",
      " -7.4014\n",
      "-10.4145\n",
      " -7.6303\n",
      "-10.7311\n",
      " -8.0567\n",
      " -5.5337\n",
      " -3.4692\n",
      " -6.0392\n",
      " -9.1967\n",
      " -6.7158\n",
      " -9.9936\n",
      "-13.3349\n",
      "-11.0468\n",
      "-14.4925\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.6534\n",
      " -3.2686\n",
      " -2.6179\n",
      " -4.3302\n",
      " -2.5938\n",
      " -4.1864\n",
      " -2.5945\n",
      " -3.7458\n",
      " -6.4364\n",
      " -9.5359\n",
      " -6.9192\n",
      "-10.1265\n",
      "-13.4149\n",
      "-16.7925\n",
      "-20.2525\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  34\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.6176\n",
      " -2.7302\n",
      " -2.6016\n",
      " -4.7195\n",
      " -7.6770\n",
      "-11.0099\n",
      "-14.5590\n",
      "-11.2691\n",
      "-14.9450\n",
      "-11.7859\n",
      " -8.7266\n",
      " -5.8700\n",
      " -3.6287\n",
      " -2.4871\n",
      " -4.1315\n",
      " -7.3330\n",
      "-11.1511\n",
      " -8.2861\n",
      " -5.6309\n",
      " -9.4020\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  21\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.1825\n",
      " -2.3436\n",
      " -2.9073\n",
      " -2.3319\n",
      " -4.0404\n",
      " -2.3099\n",
      " -3.0368\n",
      " -5.7567\n",
      " -3.2188\n",
      " -6.0234\n",
      " -9.2511\n",
      "-12.5563\n",
      " -9.8916\n",
      " -7.2249\n",
      " -4.8886\n",
      " -3.0896\n",
      " -5.6361\n",
      " -8.9030\n",
      "-12.4333\n",
      "-10.0601\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  26\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-12.2861\n",
      "-15.7829\n",
      "-13.1617\n",
      "-10.6178\n",
      " -8.0735\n",
      " -5.8275\n",
      " -3.9993\n",
      " -3.0408\n",
      " -4.0296\n",
      " -3.4344\n",
      " -3.6489\n",
      " -5.2526\n",
      " -7.2179\n",
      " -4.7630\n",
      " -3.6875\n",
      " -4.4030\n",
      " -4.1149\n",
      " -4.2697\n",
      " -4.8618\n",
      " -7.5579\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.2065\n",
      " -4.2138\n",
      " -7.1383\n",
      "-10.4511\n",
      " -7.5428\n",
      " -4.8723\n",
      " -2.8354\n",
      " -5.3804\n",
      " -8.7190\n",
      " -6.0215\n",
      " -3.7229\n",
      " -6.7896\n",
      " -4.3597\n",
      " -7.7124\n",
      "-11.4051\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  23\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0258\n",
      " -5.7991\n",
      " -3.1829\n",
      " -6.0272\n",
      " -3.4263\n",
      " -2.1898\n",
      " -3.6889\n",
      " -2.2513\n",
      " -4.0282\n",
      " -2.4028\n",
      " -4.4312\n",
      " -7.5331\n",
      " -4.9939\n",
      " -2.9719\n",
      " -5.6062\n",
      " -8.8922\n",
      " -6.4072\n",
      " -9.8183\n",
      "-13.5194\n",
      "-17.2894\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0698\n",
      " -3.9955\n",
      " -2.1398\n",
      " -2.2447\n",
      " -2.2594\n",
      " -4.4245\n",
      " -7.4036\n",
      "-10.7253\n",
      " -7.8580\n",
      "-11.3046\n",
      "-14.8123\n",
      "-18.4031\n",
      "-22.0761\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  62\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8378\n",
      " -1.9543\n",
      " -2.9740\n",
      " -1.9377\n",
      " -3.1301\n",
      " -1.9392\n",
      " -2.8188\n",
      " -5.4635\n",
      " -2.7538\n",
      " -1.9567\n",
      " -3.5697\n",
      " -6.3062\n",
      " -3.7369\n",
      " -6.5971\n",
      " -9.9113\n",
      "-13.4015\n",
      "-16.9436\n",
      "-14.2291\n",
      "-11.5890\n",
      "-15.3251\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.9429\n",
      " -3.6755\n",
      " -1.9555\n",
      " -3.8034\n",
      " -6.7346\n",
      "-10.0838\n",
      "-13.6102\n",
      "-17.1974\n",
      "-14.3268\n",
      "-11.5225\n",
      " -8.7684\n",
      " -6.1392\n",
      " -9.9079\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  33\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8070\n",
      " -5.0332\n",
      " -2.6331\n",
      " -4.7870\n",
      " -2.5253\n",
      " -4.5968\n",
      " -7.5190\n",
      " -4.4647\n",
      " -2.4212\n",
      " -4.4003\n",
      " -7.3831\n",
      "-10.6991\n",
      "-14.1651\n",
      "-17.7339\n",
      "-14.5968\n",
      "-18.3226\n",
      "-15.3448\n",
      "-12.4425\n",
      "-16.3487\n",
      "-20.3421\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  17\n",
      "\n",
      "Rewards [3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0224\n",
      " -3.4232\n",
      " -6.9146\n",
      " -3.8944\n",
      " -2.1434\n",
      " -4.3784\n",
      " -7.9940\n",
      " -5.0384\n",
      " -2.7139\n",
      " -5.7402\n",
      " -9.5746\n",
      "-13.6628\n",
      "-10.7411\n",
      " -7.9076\n",
      " -5.5290\n",
      " -9.1896\n",
      " -6.8272\n",
      "[torch.FloatTensor of size 17x1]\n",
      "\n",
      "Training. Score was  16\n",
      "\n",
      "Rewards [2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0400\n",
      " -3.8894\n",
      " -7.4039\n",
      "-11.3893\n",
      " -8.0243\n",
      "-12.1454\n",
      " -8.9093\n",
      " -6.0019\n",
      " -3.5634\n",
      " -6.9269\n",
      " -4.4473\n",
      " -2.8840\n",
      " -5.3697\n",
      " -8.9889\n",
      "-13.2688\n",
      "-17.6514\n",
      "[torch.FloatTensor of size 16x1]\n",
      "\n",
      "Training. Score was  18\n",
      "\n",
      "Rewards [3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0789\n",
      " -3.0117\n",
      " -6.5087\n",
      "-10.5067\n",
      " -7.1123\n",
      " -4.0628\n",
      " -7.8074\n",
      " -4.8087\n",
      " -2.6147\n",
      " -5.5888\n",
      " -3.1431\n",
      " -6.4592\n",
      "-10.5038\n",
      " -7.5597\n",
      "-11.7622\n",
      " -8.8511\n",
      " -6.4221\n",
      "-10.2970\n",
      "[torch.FloatTensor of size 18x1]\n",
      "\n",
      "Training. Score was  40\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.3437\n",
      " -2.0976\n",
      " -4.0728\n",
      " -7.7353\n",
      " -4.0047\n",
      " -2.0979\n",
      " -2.9214\n",
      " -2.0676\n",
      " -3.0045\n",
      " -5.8945\n",
      " -9.5709\n",
      " -6.1892\n",
      "-10.0038\n",
      " -6.6673\n",
      "-10.6256\n",
      " -7.3332\n",
      "-11.4503\n",
      "-15.6781\n",
      "-19.9930\n",
      "-24.3979\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  12\n",
      "\n",
      "Rewards [-1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.9500\n",
      " -4.0049\n",
      " -7.5427\n",
      "-11.5352\n",
      " -8.0727\n",
      " -4.8897\n",
      " -2.5558\n",
      " -5.5001\n",
      " -9.5293\n",
      "-13.8155\n",
      "-18.1872\n",
      "-22.6490\n",
      "[torch.FloatTensor of size 12x1]\n",
      "\n",
      "Training. Score was  14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0613\n",
      " -3.7365\n",
      " -2.0579\n",
      " -3.7537\n",
      " -7.1005\n",
      "-10.9819\n",
      " -7.3085\n",
      "-11.3293\n",
      "-15.5292\n",
      "-19.8278\n",
      "-16.3669\n",
      "-20.8535\n",
      "-25.4413\n",
      "-30.1526\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.9927\n",
      " -3.9271\n",
      " -2.0106\n",
      " -4.0754\n",
      " -2.0363\n",
      " -3.2745\n",
      " -6.4267\n",
      "-10.2051\n",
      "-14.2740\n",
      "-18.4484\n",
      "-22.7540\n",
      "-19.1846\n",
      "-23.6965\n",
      "-28.3339\n",
      "-33.1089\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  40\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.2513\n",
      " -4.8573\n",
      " -8.7786\n",
      "-13.2462\n",
      " -9.6339\n",
      " -6.4526\n",
      "-10.6500\n",
      " -7.5313\n",
      "-11.9112\n",
      " -8.8349\n",
      " -6.1633\n",
      " -3.9573\n",
      " -4.0234\n",
      " -5.9505\n",
      " -4.0200\n",
      " -6.0031\n",
      " -9.8178\n",
      " -7.3543\n",
      " -5.2259\n",
      " -8.7612\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-12.1468\n",
      " -8.2678\n",
      "-12.6340\n",
      " -8.8923\n",
      " -5.4213\n",
      " -2.5533\n",
      " -6.0743\n",
      "-10.3887\n",
      "-15.0064\n",
      "-11.6066\n",
      " -8.2884\n",
      " -5.4106\n",
      " -3.1213\n",
      " -2.9306\n",
      " -3.9760\n",
      " -7.7499\n",
      " -5.1447\n",
      " -9.1157\n",
      "-13.7437\n",
      "-10.7986\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  27\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.7997\n",
      " -1.8763\n",
      " -3.9219\n",
      " -1.8744\n",
      " -2.6116\n",
      " -1.8766\n",
      " -4.1795\n",
      " -7.8182\n",
      " -4.4039\n",
      " -8.1375\n",
      " -4.7402\n",
      " -8.5905\n",
      " -5.1911\n",
      " -2.5524\n",
      " -5.7107\n",
      " -9.8489\n",
      "-14.2031\n",
      "-18.6641\n",
      "-23.2309\n",
      "-27.9054\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  45\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.5552\n",
      " -3.5210\n",
      " -7.0227\n",
      "-11.0590\n",
      " -7.4887\n",
      " -4.2064\n",
      " -8.1397\n",
      " -4.8219\n",
      " -2.3667\n",
      " -1.6538\n",
      " -2.6196\n",
      " -1.6713\n",
      " -3.3501\n",
      " -7.1648\n",
      " -4.0071\n",
      " -2.0698\n",
      " -4.9257\n",
      " -9.2693\n",
      "-13.7209\n",
      "-18.2712\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  34\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.6365\n",
      " -2.6142\n",
      " -1.8245\n",
      " -2.4612\n",
      " -5.1996\n",
      " -8.6342\n",
      " -5.1112\n",
      " -2.3326\n",
      " -5.1138\n",
      " -2.3483\n",
      " -5.1941\n",
      " -8.8278\n",
      "-12.7608\n",
      " -9.2189\n",
      "-13.2893\n",
      "-17.4212\n",
      "-14.1413\n",
      "-10.9057\n",
      "-15.2445\n",
      "-19.6845\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  37\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.5907\n",
      " -1.6223\n",
      " -1.4622\n",
      " -1.7585\n",
      " -4.3629\n",
      " -1.9711\n",
      " -4.7523\n",
      " -2.2557\n",
      " -1.3721\n",
      " -2.0786\n",
      " -1.3974\n",
      " -2.8215\n",
      " -6.0870\n",
      " -3.2042\n",
      " -6.6832\n",
      "-10.7178\n",
      "-14.8838\n",
      "-19.1040\n",
      "-16.1246\n",
      "-20.5057\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  53\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.5184\n",
      " -6.4194\n",
      " -4.8602\n",
      " -5.2000\n",
      " -6.7212\n",
      " -8.8199\n",
      "-11.0998\n",
      " -8.3681\n",
      " -6.1990\n",
      " -5.8064\n",
      " -6.1522\n",
      " -7.6942\n",
      " -6.1864\n",
      " -7.4740\n",
      " -6.4366\n",
      " -7.3228\n",
      " -9.0048\n",
      " -7.2754\n",
      " -8.7605\n",
      " -7.3767\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.1130\n",
      " -9.8875\n",
      "-13.8513\n",
      "-10.6734\n",
      " -7.5678\n",
      " -4.5800\n",
      " -8.5778\n",
      " -5.6137\n",
      " -3.0787\n",
      " -1.5286\n",
      " -1.1494\n",
      " -1.9330\n",
      " -1.2239\n",
      " -2.5626\n",
      " -1.4231\n",
      " -3.3705\n",
      " -1.7889\n",
      " -1.4424\n",
      " -2.3488\n",
      " -5.6921\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  49\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-10.0518\n",
      " -7.0711\n",
      " -4.2194\n",
      " -1.9809\n",
      " -0.9711\n",
      " -1.0521\n",
      " -1.1256\n",
      " -0.9474\n",
      " -1.4517\n",
      " -4.0647\n",
      " -1.9221\n",
      " -1.0568\n",
      " -2.5152\n",
      " -1.2777\n",
      " -3.3314\n",
      " -1.6495\n",
      " -1.1996\n",
      " -2.2012\n",
      " -5.5995\n",
      " -9.7320\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  34\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.3517\n",
      "-0.8335\n",
      "-1.6448\n",
      "-0.8662\n",
      "-1.3172\n",
      "-0.9008\n",
      "-2.3185\n",
      "-0.9856\n",
      "-2.7097\n",
      "-6.0904\n",
      "-9.8851\n",
      "-7.0048\n",
      "-4.1897\n",
      "-2.0505\n",
      "-1.1359\n",
      "-1.3388\n",
      "-1.3874\n",
      "-3.5309\n",
      "-7.3989\n",
      "-4.7260\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  17\n",
      "\n",
      "Rewards [3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.9487\n",
      " -2.2726\n",
      " -1.0046\n",
      " -2.6950\n",
      " -1.1334\n",
      " -3.1952\n",
      " -6.5198\n",
      " -3.9401\n",
      " -1.8127\n",
      " -4.7085\n",
      " -8.1997\n",
      "-12.2108\n",
      " -9.5470\n",
      " -7.1770\n",
      " -5.0358\n",
      " -8.5820\n",
      "-12.6460\n",
      "[torch.FloatTensor of size 17x1]\n",
      "\n",
      "Training. Score was  22\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.9071\n",
      " -1.0420\n",
      " -2.7479\n",
      " -1.0212\n",
      " -1.0499\n",
      " -0.9759\n",
      " -2.4016\n",
      " -5.4395\n",
      " -2.4865\n",
      " -5.5836\n",
      " -2.6996\n",
      " -5.8784\n",
      " -3.0423\n",
      " -6.3274\n",
      "-10.0730\n",
      "-13.9081\n",
      "-17.8973\n",
      "-15.2627\n",
      "-19.4335\n",
      "-23.6806\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.8735\n",
      " -2.2068\n",
      " -0.8750\n",
      " -1.2224\n",
      " -3.7540\n",
      " -7.0711\n",
      "-10.7452\n",
      " -7.6280\n",
      "-11.4482\n",
      " -8.4878\n",
      "-12.4449\n",
      "-16.4889\n",
      "-13.9138\n",
      "-11.3946\n",
      "-15.6427\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  19\n",
      "\n",
      "Rewards [4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.8302\n",
      " -2.0558\n",
      " -0.8282\n",
      " -1.4876\n",
      " -4.3668\n",
      " -1.6920\n",
      " -4.7456\n",
      " -2.0259\n",
      " -5.2493\n",
      " -9.0173\n",
      " -6.0462\n",
      " -9.9712\n",
      " -7.0842\n",
      " -4.6079\n",
      " -2.3522\n",
      " -5.6851\n",
      " -9.4719\n",
      "-13.7219\n",
      "-11.1975\n",
      "[torch.FloatTensor of size 19x1]\n",
      "\n",
      "Training. Score was  55\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.5798\n",
      "-1.7295\n",
      "-4.0713\n",
      "-1.9999\n",
      "-1.5914\n",
      "-2.3498\n",
      "-1.6415\n",
      "-2.2782\n",
      "-1.7269\n",
      "-2.2216\n",
      "-1.8759\n",
      "-3.8453\n",
      "-7.0713\n",
      "-4.6060\n",
      "-2.7150\n",
      "-2.2559\n",
      "-3.4642\n",
      "-6.5155\n",
      "-4.3727\n",
      "-7.7788\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  21\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0773\n",
      " -0.9385\n",
      " -1.7227\n",
      " -3.9287\n",
      " -6.7943\n",
      " -3.8659\n",
      " -1.5886\n",
      " -0.9714\n",
      " -2.5030\n",
      " -5.9850\n",
      " -9.8536\n",
      " -6.6296\n",
      " -3.6828\n",
      " -7.3884\n",
      "-11.5471\n",
      "-15.9161\n",
      "-13.0413\n",
      "-10.2018\n",
      "-14.7643\n",
      "-12.1446\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  59\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.6762\n",
      " -2.3434\n",
      " -3.8861\n",
      " -6.5691\n",
      " -9.4047\n",
      " -6.2862\n",
      " -9.1928\n",
      " -6.1214\n",
      " -9.1037\n",
      "-12.5009\n",
      " -9.2451\n",
      "-12.8328\n",
      "-16.7178\n",
      "-13.5567\n",
      "-17.6039\n",
      "-21.8085\n",
      "-18.9795\n",
      "-23.4674\n",
      "-20.8290\n",
      "-18.2813\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  61\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.8192\n",
      " -1.8236\n",
      " -1.5365\n",
      " -3.0482\n",
      " -1.5037\n",
      " -3.0242\n",
      " -1.6989\n",
      " -2.3935\n",
      " -4.1670\n",
      " -2.1780\n",
      " -3.8215\n",
      " -2.0709\n",
      " -2.4334\n",
      " -5.5729\n",
      " -9.4832\n",
      "-13.8847\n",
      "-10.8154\n",
      "-15.4503\n",
      "-12.5081\n",
      " -9.9733\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  48\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.9211\n",
      " -2.4627\n",
      " -0.9900\n",
      " -1.5721\n",
      " -1.1101\n",
      " -3.7594\n",
      " -7.8221\n",
      " -4.7771\n",
      " -8.9587\n",
      "-13.7663\n",
      "-10.5431\n",
      " -7.6780\n",
      " -5.0419\n",
      " -2.7064\n",
      " -2.0092\n",
      " -3.8719\n",
      " -2.4250\n",
      " -5.2650\n",
      " -9.4027\n",
      " -6.9460\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.7744\n",
      " -3.0678\n",
      " -1.2646\n",
      " -3.4681\n",
      " -1.5332\n",
      " -3.9851\n",
      " -1.8862\n",
      " -0.9718\n",
      " -2.2746\n",
      " -1.1200\n",
      " -2.7089\n",
      " -1.3572\n",
      " -1.2125\n",
      " -1.6062\n",
      " -3.9117\n",
      " -7.6185\n",
      " -4.8568\n",
      " -8.7353\n",
      "-12.7790\n",
      "-10.1942\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  15\n",
      "\n",
      "Rewards [1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.8039\n",
      " -2.0144\n",
      " -0.8027\n",
      " -1.6338\n",
      " -5.1740\n",
      " -1.7539\n",
      " -5.4183\n",
      " -9.7625\n",
      "-14.4479\n",
      "-19.2454\n",
      "-15.7532\n",
      "-12.2896\n",
      "-17.3483\n",
      "-22.5500\n",
      "-27.8603\n",
      "[torch.FloatTensor of size 15x1]\n",
      "\n",
      "Training. Score was  26\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-13.9279\n",
      "-10.1195\n",
      " -6.5719\n",
      " -3.3035\n",
      " -1.2164\n",
      " -4.1150\n",
      " -1.6191\n",
      " -5.0209\n",
      " -2.2479\n",
      " -6.0864\n",
      " -3.1487\n",
      " -7.2893\n",
      "-11.8843\n",
      " -8.8674\n",
      " -6.0730\n",
      " -3.4778\n",
      " -7.6087\n",
      " -5.0329\n",
      " -9.2990\n",
      " -6.8099\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  25\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.6315\n",
      " -0.7997\n",
      " -2.1446\n",
      " -4.9357\n",
      " -2.2511\n",
      " -5.1542\n",
      " -8.7972\n",
      " -5.5999\n",
      " -2.8966\n",
      " -1.1272\n",
      " -3.3118\n",
      " -6.7967\n",
      "-10.8042\n",
      " -7.7882\n",
      " -4.9018\n",
      " -8.9426\n",
      " -6.0849\n",
      " -3.6337\n",
      " -7.4676\n",
      "-11.7797\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.5767\n",
      " -3.1477\n",
      " -1.0065\n",
      " -3.7908\n",
      " -1.2930\n",
      " -4.5365\n",
      " -8.8258\n",
      " -5.6033\n",
      "-10.0190\n",
      "-15.0487\n",
      "-11.7369\n",
      " -8.7547\n",
      " -6.0049\n",
      " -3.4362\n",
      " -2.2957\n",
      " -4.8872\n",
      " -2.9915\n",
      " -6.4684\n",
      "-10.8927\n",
      " -8.3764\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  60\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.7714\n",
      "-4.4856\n",
      "-8.1791\n",
      "-4.8997\n",
      "-8.7856\n",
      "-5.5390\n",
      "-9.6287\n",
      "-6.4830\n",
      "-3.5975\n",
      "-1.7783\n",
      "-1.2681\n",
      "-2.2809\n",
      "-1.4191\n",
      "-2.9411\n",
      "-6.6483\n",
      "-3.9674\n",
      "-2.2092\n",
      "-5.1290\n",
      "-9.4118\n",
      "-6.6753\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-10.8096\n",
      "-15.2785\n",
      "-11.5720\n",
      " -7.8954\n",
      " -4.5852\n",
      " -1.7035\n",
      " -5.4098\n",
      " -2.3771\n",
      " -0.9336\n",
      " -3.1624\n",
      " -7.2522\n",
      " -4.2592\n",
      " -8.4634\n",
      "-13.2432\n",
      "-10.1010\n",
      " -7.3772\n",
      "-11.9226\n",
      " -9.2995\n",
      " -6.8484\n",
      " -4.5273\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  60\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.6705\n",
      " -5.0087\n",
      " -1.6525\n",
      " -5.0716\n",
      " -1.7444\n",
      " -5.3297\n",
      " -1.9743\n",
      " -5.7815\n",
      "-10.1311\n",
      " -6.6422\n",
      "-11.1726\n",
      " -7.8245\n",
      "-12.5549\n",
      " -9.3836\n",
      "-14.2993\n",
      "-11.3449\n",
      " -8.5686\n",
      " -6.0993\n",
      " -3.8251\n",
      " -8.0066\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  35\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.9165\n",
      " -4.5943\n",
      " -2.4875\n",
      " -5.7542\n",
      " -3.3867\n",
      " -2.5878\n",
      " -4.4435\n",
      " -3.0610\n",
      " -3.3431\n",
      " -4.7422\n",
      " -3.4474\n",
      " -4.1919\n",
      " -3.6903\n",
      " -4.9980\n",
      " -8.5987\n",
      " -6.2251\n",
      " -9.9771\n",
      " -7.7124\n",
      "-11.6277\n",
      "-15.9955\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  64\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1545\n",
      " -1.0813\n",
      " -0.9291\n",
      " -1.0663\n",
      " -0.9506\n",
      " -3.2053\n",
      " -1.0502\n",
      " -3.5598\n",
      " -7.2693\n",
      " -4.2484\n",
      " -8.0759\n",
      "-12.3822\n",
      " -9.3461\n",
      " -6.6261\n",
      "-10.7779\n",
      " -8.1883\n",
      " -5.7782\n",
      " -9.8384\n",
      "-14.4124\n",
      "-11.9602\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  140\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.7667\n",
      " -9.9569\n",
      " -9.0359\n",
      "-10.2764\n",
      " -9.2969\n",
      " -9.0640\n",
      " -9.4376\n",
      "-10.6870\n",
      " -9.6364\n",
      " -9.3223\n",
      " -9.7035\n",
      "-10.8657\n",
      " -9.8363\n",
      " -9.6025\n",
      "-10.7989\n",
      " -9.7680\n",
      "-11.2687\n",
      "-13.5359\n",
      "-16.8306\n",
      "-14.7290\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  52\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.6178\n",
      "-11.5544\n",
      "-15.0109\n",
      "-11.8396\n",
      " -8.9244\n",
      "-12.3051\n",
      " -9.4577\n",
      " -6.7038\n",
      " -4.4220\n",
      " -2.8132\n",
      " -4.7416\n",
      " -7.8250\n",
      "-11.5506\n",
      "-15.6410\n",
      "-12.8351\n",
      "-10.1735\n",
      " -7.6443\n",
      " -5.3244\n",
      " -9.0906\n",
      " -6.7615\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  55\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.1063\n",
      " -1.7734\n",
      " -1.1002\n",
      " -2.7924\n",
      " -6.2375\n",
      " -3.7203\n",
      " -1.8102\n",
      " -1.1922\n",
      " -2.2688\n",
      " -5.5096\n",
      " -9.4294\n",
      " -6.8936\n",
      " -4.5493\n",
      " -2.5840\n",
      " -5.8170\n",
      " -9.7068\n",
      " -7.4334\n",
      "-11.5201\n",
      " -9.3368\n",
      " -7.2786\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  50\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.5849\n",
      " -2.0511\n",
      " -5.6216\n",
      " -9.5804\n",
      " -7.0529\n",
      " -4.6843\n",
      " -2.5080\n",
      " -6.0315\n",
      " -9.9997\n",
      " -7.8030\n",
      " -5.7193\n",
      " -3.7485\n",
      " -2.7748\n",
      " -3.3575\n",
      " -3.4711\n",
      " -3.4273\n",
      " -4.4428\n",
      " -7.8732\n",
      "-11.7344\n",
      " -9.7733\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  53\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.8432\n",
      " -5.5853\n",
      " -4.3100\n",
      " -6.6523\n",
      " -5.0384\n",
      " -4.7718\n",
      " -5.8626\n",
      " -5.1551\n",
      " -6.8948\n",
      "-10.1995\n",
      " -8.2524\n",
      " -6.8027\n",
      " -6.3586\n",
      " -7.9397\n",
      " -7.0396\n",
      " -7.2795\n",
      " -8.2833\n",
      " -7.6288\n",
      " -8.8724\n",
      " -8.1666\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  63\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.5167\n",
      " -2.9745\n",
      " -1.8486\n",
      " -1.7609\n",
      " -2.0362\n",
      " -1.8635\n",
      " -2.3623\n",
      " -1.9535\n",
      " -2.3811\n",
      " -2.0573\n",
      " -2.6523\n",
      " -5.3289\n",
      " -8.9832\n",
      "-12.9910\n",
      "-10.1850\n",
      " -7.4324\n",
      "-11.5914\n",
      " -8.9604\n",
      " -6.5703\n",
      " -4.7559\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  111\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.8587\n",
      " -7.2021\n",
      " -7.4033\n",
      " -7.3908\n",
      " -8.3516\n",
      " -7.5950\n",
      " -8.7094\n",
      " -8.0408\n",
      " -9.6101\n",
      " -8.7999\n",
      " -8.9071\n",
      " -9.6855\n",
      " -9.3467\n",
      "-10.1242\n",
      "-11.2959\n",
      "-12.5557\n",
      "-11.3928\n",
      "-10.6548\n",
      "-11.6609\n",
      "-13.6451\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  18\n",
      "\n",
      "Rewards [3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.4647\n",
      " -2.1692\n",
      " -5.1765\n",
      " -2.3769\n",
      " -5.5662\n",
      " -9.3927\n",
      " -6.2936\n",
      "-10.2630\n",
      " -7.2985\n",
      " -4.3705\n",
      " -2.1448\n",
      " -5.4392\n",
      " -9.6294\n",
      " -6.8531\n",
      " -4.2140\n",
      " -8.3856\n",
      " -5.7634\n",
      "-10.1324\n",
      "[torch.FloatTensor of size 18x1]\n",
      "\n",
      "Training. Score was  28\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.3555\n",
      " -1.7319\n",
      " -0.4974\n",
      " -2.4502\n",
      " -5.8209\n",
      " -3.5209\n",
      " -1.5134\n",
      " -0.8078\n",
      " -1.6037\n",
      " -1.0270\n",
      " -2.9731\n",
      " -6.3064\n",
      " -4.1877\n",
      " -7.6441\n",
      "-11.4162\n",
      " -9.4530\n",
      " -7.5868\n",
      " -5.8721\n",
      " -4.2769\n",
      " -7.5736\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  20\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.2739\n",
      " -0.4340\n",
      " -0.2678\n",
      " -0.5181\n",
      " -0.2626\n",
      " -0.6355\n",
      " -3.2032\n",
      " -0.9313\n",
      " -3.8643\n",
      " -1.4779\n",
      " -4.7051\n",
      " -2.3806\n",
      " -5.7408\n",
      " -3.5109\n",
      " -6.9910\n",
      "-10.8687\n",
      " -8.7286\n",
      " -6.8160\n",
      "-10.5899\n",
      " -8.8554\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  127\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.6278\n",
      " -9.3577\n",
      " -6.7507\n",
      " -4.5668\n",
      " -3.0606\n",
      " -4.6805\n",
      " -3.0084\n",
      " -5.0451\n",
      " -3.0876\n",
      " -1.7851\n",
      " -1.2453\n",
      " -1.7902\n",
      " -1.0099\n",
      " -1.9262\n",
      " -4.6385\n",
      " -8.7100\n",
      " -5.9307\n",
      "-10.3238\n",
      "-14.8475\n",
      "-12.4376\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  17\n",
      "\n",
      "Rewards [3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.2326\n",
      " -1.2649\n",
      " -3.8133\n",
      " -7.2300\n",
      "-11.0704\n",
      " -7.7219\n",
      " -4.5078\n",
      " -8.3716\n",
      "-12.4929\n",
      " -9.4418\n",
      "-13.7358\n",
      "-10.8781\n",
      " -7.9872\n",
      "-12.5196\n",
      " -9.8023\n",
      " -7.1237\n",
      " -4.6912\n",
      "[torch.FloatTensor of size 17x1]\n",
      "\n",
      "Training. Score was  93\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.9529\n",
      " -6.1800\n",
      " -4.4583\n",
      " -3.0599\n",
      " -2.2319\n",
      " -2.2667\n",
      " -3.0905\n",
      " -2.0678\n",
      " -2.8828\n",
      " -5.0263\n",
      " -7.7521\n",
      "-11.2645\n",
      " -8.6408\n",
      " -6.3251\n",
      " -4.2173\n",
      " -7.5071\n",
      " -5.4348\n",
      " -9.3109\n",
      " -7.3272\n",
      " -5.4728\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  69\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.1486\n",
      " -3.6327\n",
      " -1.5862\n",
      " -0.7798\n",
      " -2.0428\n",
      " -1.0027\n",
      " -2.5785\n",
      " -6.0727\n",
      "-10.2521\n",
      " -7.4038\n",
      " -4.7558\n",
      " -8.8901\n",
      " -6.1979\n",
      " -3.9783\n",
      " -2.6792\n",
      " -2.4169\n",
      " -3.4746\n",
      " -6.7201\n",
      "-11.0295\n",
      "-15.6299\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training, score of  200\n",
      "Training. Score was  13\n",
      "\n",
      "Rewards [-0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.2433\n",
      " -1.1179\n",
      " -4.4230\n",
      " -8.1123\n",
      " -5.6643\n",
      " -9.5395\n",
      " -7.2328\n",
      " -5.0266\n",
      " -8.8891\n",
      " -6.8232\n",
      "-10.8287\n",
      " -8.9463\n",
      " -7.1476\n",
      "[torch.FloatTensor of size 13x1]\n",
      "\n",
      "Training. Score was  103\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-15.5943\n",
      "-16.5528\n",
      "-17.8324\n",
      "-19.1062\n",
      "-20.4556\n",
      "-22.0131\n",
      "-20.4703\n",
      "-19.2660\n",
      "-20.5134\n",
      "-22.0249\n",
      "-20.5342\n",
      "-22.0538\n",
      "-24.0143\n",
      "-26.5519\n",
      "-29.7022\n",
      "-33.0720\n",
      "-31.1629\n",
      "-29.2986\n",
      "-27.4819\n",
      "-25.7718\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  40\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-4.4828\n",
      "-8.6123\n",
      "-5.6995\n",
      "-3.2497\n",
      "-1.9511\n",
      "-4.2494\n",
      "-8.3342\n",
      "-5.5792\n",
      "-3.5350\n",
      "-2.5951\n",
      "-4.6759\n",
      "-8.5968\n",
      "-6.1435\n",
      "-4.3739\n",
      "-3.6533\n",
      "-5.6626\n",
      "-4.4889\n",
      "-7.0863\n",
      "-5.5709\n",
      "-8.7992\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  100\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0921\n",
      " -4.0085\n",
      " -2.1946\n",
      " -2.3521\n",
      " -2.2255\n",
      " -4.3583\n",
      " -2.3268\n",
      " -2.2758\n",
      " -3.6544\n",
      " -5.9243\n",
      " -3.7245\n",
      " -6.3053\n",
      " -9.8930\n",
      " -7.2233\n",
      "-11.0989\n",
      "-15.3065\n",
      "-13.0052\n",
      "-10.7751\n",
      " -8.6418\n",
      "-13.0488\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  189\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -9.9459\n",
      " -8.7386\n",
      " -7.9612\n",
      " -8.2132\n",
      " -8.9144\n",
      "-10.2633\n",
      " -8.9273\n",
      "-10.0826\n",
      " -8.9965\n",
      " -9.9610\n",
      " -9.0771\n",
      " -9.4580\n",
      " -9.2831\n",
      " -9.7756\n",
      " -9.7403\n",
      " -9.9262\n",
      "-10.4195\n",
      "-12.1201\n",
      "-11.3089\n",
      "-13.3224\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  38\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.0437\n",
      " -7.8766\n",
      " -4.5270\n",
      " -8.6828\n",
      " -5.4566\n",
      " -2.7280\n",
      " -6.5958\n",
      "-11.1952\n",
      " -8.3467\n",
      " -5.6801\n",
      " -3.1813\n",
      " -7.4483\n",
      " -5.0875\n",
      " -2.7879\n",
      " -7.0066\n",
      " -4.7972\n",
      " -2.5971\n",
      " -6.7532\n",
      "-11.2128\n",
      " -9.1779\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  120\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-15.6105\n",
      "-19.0794\n",
      "-17.0303\n",
      "-15.1931\n",
      "-13.4350\n",
      "-11.7750\n",
      "-14.7683\n",
      "-13.0380\n",
      "-11.5017\n",
      "-10.5281\n",
      "-10.0579\n",
      " -9.8265\n",
      "-10.0516\n",
      "-11.0200\n",
      " -9.7521\n",
      " -9.9182\n",
      " -9.6675\n",
      "-10.1873\n",
      "-11.3941\n",
      "-13.5937\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  72\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4753\n",
      " -3.7417\n",
      " -3.3348\n",
      " -3.6998\n",
      " -4.5215\n",
      " -6.4196\n",
      " -4.7228\n",
      " -3.4765\n",
      " -4.9199\n",
      " -7.3161\n",
      " -5.3289\n",
      " -3.6913\n",
      " -5.9668\n",
      " -4.1392\n",
      " -6.7702\n",
      "-10.0197\n",
      "-13.5530\n",
      "-11.6763\n",
      " -9.8077\n",
      " -8.0167\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  43\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.9852\n",
      " -1.4311\n",
      " -1.2021\n",
      " -1.6610\n",
      " -1.3979\n",
      " -2.2787\n",
      " -1.6763\n",
      " -1.7663\n",
      " -2.9119\n",
      " -1.8511\n",
      " -2.9081\n",
      " -5.1294\n",
      " -8.1422\n",
      " -5.5734\n",
      " -9.0023\n",
      "-13.1519\n",
      "-17.7960\n",
      "-15.4522\n",
      "-20.4382\n",
      "-18.5117\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  14\n",
      "\n",
      "Rewards [0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.1226\n",
      " -0.2720\n",
      " -2.8183\n",
      " -0.3606\n",
      " -3.2619\n",
      " -7.0173\n",
      "-11.2406\n",
      "-15.7214\n",
      "-13.1558\n",
      "-10.6088\n",
      "-15.3649\n",
      "-13.1314\n",
      "-11.0553\n",
      " -9.1702\n",
      "[torch.FloatTensor of size 14x1]\n",
      "\n",
      "Training. Score was  82\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.4679\n",
      " -5.5562\n",
      " -4.1262\n",
      " -3.7784\n",
      " -4.2464\n",
      " -3.5414\n",
      " -4.5177\n",
      " -3.3540\n",
      " -3.2065\n",
      " -3.6974\n",
      " -2.8377\n",
      " -3.6684\n",
      " -6.5890\n",
      " -4.4384\n",
      " -2.7185\n",
      " -5.6530\n",
      " -9.4615\n",
      "-13.7900\n",
      "-18.5057\n",
      "-16.6218\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  101\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -9.0836\n",
      " -7.4988\n",
      " -7.1989\n",
      " -7.3341\n",
      " -7.5666\n",
      " -8.0979\n",
      " -7.7400\n",
      " -8.2072\n",
      " -9.0213\n",
      " -8.2764\n",
      " -7.7460\n",
      " -7.5521\n",
      " -7.8944\n",
      " -9.3058\n",
      "-11.7809\n",
      "-15.0863\n",
      "-19.0539\n",
      "-16.7807\n",
      "-21.1834\n",
      "-19.0718\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  32\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.4313\n",
      " -1.4571\n",
      " -5.3484\n",
      " -2.5020\n",
      " -0.2827\n",
      " -0.1046\n",
      " -0.6457\n",
      " -0.1184\n",
      " -1.3060\n",
      " -0.2008\n",
      " -2.1024\n",
      " -0.3497\n",
      " -3.0558\n",
      " -7.0925\n",
      " -4.4363\n",
      " -8.5848\n",
      "-12.9626\n",
      "-17.8661\n",
      "-15.5752\n",
      "-13.5727\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.4814\n",
      " -4.4933\n",
      " -6.8929\n",
      " -5.4187\n",
      " -8.4088\n",
      " -6.6448\n",
      " -5.8580\n",
      " -8.0672\n",
      " -6.7994\n",
      " -6.3184\n",
      " -6.3540\n",
      " -6.5231\n",
      " -6.7918\n",
      " -7.6107\n",
      " -9.9197\n",
      "-13.3102\n",
      "-11.5503\n",
      "-10.0573\n",
      " -9.0934\n",
      "-11.5520\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  58\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.6272\n",
      " -2.8289\n",
      " -0.4121\n",
      " -0.0872\n",
      " -1.1226\n",
      " -0.1521\n",
      " -2.0985\n",
      " -6.1902\n",
      " -3.3914\n",
      " -0.9039\n",
      " -4.6959\n",
      " -9.0283\n",
      " -6.4244\n",
      " -3.6335\n",
      " -8.1057\n",
      "-12.6287\n",
      "-10.2716\n",
      "-14.9672\n",
      "-12.7924\n",
      "-17.6887\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  23\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.6738\n",
      " -4.7872\n",
      " -9.1743\n",
      " -6.2536\n",
      " -3.3190\n",
      " -0.5743\n",
      " -4.6839\n",
      " -1.8046\n",
      " -6.2119\n",
      "-10.8432\n",
      " -8.2903\n",
      " -5.7106\n",
      " -3.0320\n",
      " -7.6807\n",
      " -5.0908\n",
      " -2.6645\n",
      " -7.0046\n",
      "-11.7511\n",
      " -9.3652\n",
      " -6.7364\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  125\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.5997\n",
      " -8.0061\n",
      " -7.5087\n",
      " -8.3666\n",
      " -9.5999\n",
      "-11.5473\n",
      "-10.3678\n",
      "-12.5329\n",
      "-11.3038\n",
      "-10.5439\n",
      " -9.9865\n",
      "-11.3409\n",
      "-10.7716\n",
      "-12.2025\n",
      "-11.6286\n",
      "-11.1147\n",
      "-12.4638\n",
      "-14.1725\n",
      "-16.8852\n",
      "-15.7002\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  109\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.7405\n",
      " -1.4849\n",
      " -4.0884\n",
      " -1.8153\n",
      " -4.6767\n",
      " -2.3287\n",
      " -5.5153\n",
      " -3.1194\n",
      " -1.2534\n",
      " -4.0529\n",
      " -7.7033\n",
      " -5.4897\n",
      " -9.2791\n",
      " -7.2436\n",
      " -5.0933\n",
      " -2.9345\n",
      " -1.3633\n",
      " -4.4991\n",
      " -8.6935\n",
      "-12.7797\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  141\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.0249\n",
      "-10.1859\n",
      " -8.4301\n",
      " -6.8421\n",
      " -9.8996\n",
      " -8.3570\n",
      " -7.0178\n",
      " -6.1735\n",
      " -6.1088\n",
      " -6.3860\n",
      " -7.1032\n",
      " -6.5826\n",
      " -6.8961\n",
      " -6.8060\n",
      " -7.1201\n",
      " -7.0650\n",
      " -7.9450\n",
      " -7.4363\n",
      " -7.3957\n",
      " -7.8550\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  110\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-6.2987\n",
      "-6.7462\n",
      "-6.2849\n",
      "-6.7064\n",
      "-6.2417\n",
      "-6.6985\n",
      "-6.1724\n",
      "-5.8806\n",
      "-6.0983\n",
      "-6.7331\n",
      "-6.0697\n",
      "-5.6119\n",
      "-5.8486\n",
      "-5.5526\n",
      "-5.7512\n",
      "-5.5648\n",
      "-5.6784\n",
      "-5.5868\n",
      "-6.0279\n",
      "-6.9753\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  102\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.3407\n",
      " -1.7067\n",
      " -2.3599\n",
      " -3.9258\n",
      " -2.5227\n",
      " -4.2297\n",
      " -2.7689\n",
      " -4.6627\n",
      " -3.1735\n",
      " -2.2701\n",
      " -3.5558\n",
      " -2.5839\n",
      " -3.9987\n",
      " -6.3617\n",
      " -4.6946\n",
      " -7.3393\n",
      "-10.5911\n",
      "-14.4052\n",
      "-18.5822\n",
      "-17.0352\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  54\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.1167\n",
      " -3.4414\n",
      " -1.6084\n",
      " -4.3483\n",
      " -8.2194\n",
      " -5.6672\n",
      " -3.3235\n",
      " -7.0406\n",
      " -4.6233\n",
      " -2.8006\n",
      " -1.9308\n",
      " -1.3634\n",
      " -2.4419\n",
      " -4.6190\n",
      " -8.2289\n",
      "-12.2868\n",
      "-10.0453\n",
      "-14.2200\n",
      "-12.2432\n",
      "-10.0798\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  25\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.6289\n",
      "  0.1086\n",
      " -0.8174\n",
      "  0.0886\n",
      " -1.0531\n",
      " -3.7345\n",
      " -1.5439\n",
      " -0.1731\n",
      " -2.0484\n",
      " -5.4738\n",
      " -3.0176\n",
      " -6.7629\n",
      " -4.4108\n",
      " -8.3403\n",
      " -6.1661\n",
      " -3.9104\n",
      " -8.0040\n",
      " -5.8617\n",
      "-10.0850\n",
      " -8.1465\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  91\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "  0.1033\n",
      "  0.0645\n",
      "  0.0680\n",
      "  0.0904\n",
      " -0.1442\n",
      " -4.5865\n",
      " -1.4206\n",
      " -6.6455\n",
      " -3.5672\n",
      " -0.6799\n",
      "  0.0586\n",
      " -2.6346\n",
      " -0.2785\n",
      "  0.0154\n",
      " -0.1547\n",
      " -0.1420\n",
      " -3.4741\n",
      " -8.7985\n",
      " -6.0222\n",
      "-11.6282\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  164\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.7864\n",
      " -2.9877\n",
      " -3.8298\n",
      " -4.9662\n",
      " -7.2671\n",
      " -5.3572\n",
      " -4.0981\n",
      " -3.2165\n",
      " -2.8812\n",
      " -3.3293\n",
      " -4.5151\n",
      " -6.6350\n",
      " -4.9982\n",
      " -7.3332\n",
      " -5.6376\n",
      " -8.1681\n",
      "-11.0449\n",
      " -9.3229\n",
      " -7.6837\n",
      "-10.5942\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  35\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.4302\n",
      " -3.6760\n",
      " -1.5078\n",
      " -5.1574\n",
      " -2.5978\n",
      " -1.0401\n",
      " -0.2669\n",
      " -1.7413\n",
      " -5.0962\n",
      " -2.6731\n",
      " -1.4263\n",
      " -3.8833\n",
      " -2.1589\n",
      " -5.2070\n",
      " -9.6017\n",
      "-14.1909\n",
      "-11.8650\n",
      " -9.3804\n",
      "-14.2212\n",
      "-19.0327\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  147\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.0171\n",
      "-4.1537\n",
      "-7.5422\n",
      "-3.6652\n",
      "-1.4978\n",
      "-1.1756\n",
      "-1.5544\n",
      "-1.0999\n",
      "-1.9315\n",
      "-1.1001\n",
      "-2.5353\n",
      "-5.3013\n",
      "-3.7051\n",
      "-2.3950\n",
      "-1.2102\n",
      "-3.5961\n",
      "-7.2485\n",
      "-5.6920\n",
      "-4.0707\n",
      "-8.1079\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  141\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-4.1712\n",
      "-7.2183\n",
      "-4.8094\n",
      "-2.9449\n",
      "-1.2987\n",
      "-0.5342\n",
      "-1.8133\n",
      "-0.6447\n",
      "-2.6683\n",
      "-6.2278\n",
      "-4.2944\n",
      "-2.5108\n",
      "-1.1298\n",
      "-0.4801\n",
      "-0.6762\n",
      "-1.3899\n",
      "-0.5737\n",
      "-1.9109\n",
      "-5.5674\n",
      "-3.7252\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  118\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.4385\n",
      "-1.3770\n",
      "-2.7233\n",
      "-1.4194\n",
      "-1.6071\n",
      "-1.4686\n",
      "-1.6601\n",
      "-1.5210\n",
      "-2.7683\n",
      "-5.5205\n",
      "-3.1628\n",
      "-1.9115\n",
      "-3.9880\n",
      "-7.7541\n",
      "-5.3850\n",
      "-9.7715\n",
      "-7.5898\n",
      "-5.4211\n",
      "-3.9576\n",
      "-2.8143\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  125\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.5447\n",
      " -1.4462\n",
      " -1.4462\n",
      " -2.5465\n",
      " -1.4924\n",
      " -2.3400\n",
      " -1.6991\n",
      " -2.1376\n",
      " -3.4910\n",
      " -2.1125\n",
      " -2.4120\n",
      " -2.2101\n",
      " -2.9909\n",
      " -2.4431\n",
      " -3.7116\n",
      " -2.8026\n",
      " -4.7551\n",
      " -9.1674\n",
      " -6.5870\n",
      "-11.5374\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  47\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.6544\n",
      " -3.9311\n",
      " -1.1907\n",
      " -0.5901\n",
      " -1.9472\n",
      " -6.6746\n",
      " -3.1487\n",
      " -8.2641\n",
      " -4.6973\n",
      " -2.0088\n",
      " -6.1470\n",
      "-11.7186\n",
      " -8.1478\n",
      "-13.9094\n",
      "-10.4334\n",
      "-16.3955\n",
      "-13.0112\n",
      " -9.8470\n",
      " -6.5971\n",
      "-12.3581\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  125\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-14.0001\n",
      "-11.4640\n",
      " -9.8184\n",
      "-13.0169\n",
      "-17.5383\n",
      "-15.0341\n",
      "-12.7073\n",
      "-11.0831\n",
      "-10.5309\n",
      "-12.1968\n",
      "-11.3718\n",
      "-13.7152\n",
      "-12.2395\n",
      "-11.7868\n",
      "-11.6223\n",
      "-12.4496\n",
      "-12.1362\n",
      "-13.1275\n",
      "-15.7306\n",
      "-19.9083\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  154\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.1732\n",
      " -4.9832\n",
      " -6.5936\n",
      " -5.0799\n",
      " -4.8217\n",
      " -6.7584\n",
      " -5.4305\n",
      " -5.2238\n",
      " -6.1273\n",
      " -8.7502\n",
      " -7.0557\n",
      "-10.3744\n",
      " -8.3817\n",
      " -7.1989\n",
      " -6.7010\n",
      " -7.1863\n",
      " -7.4750\n",
      " -7.4321\n",
      " -8.2025\n",
      " -8.0857\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  156\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.3556\n",
      " -7.4946\n",
      " -7.2505\n",
      " -7.7153\n",
      " -7.4545\n",
      " -7.9382\n",
      " -8.7878\n",
      " -8.1806\n",
      " -7.8686\n",
      " -8.4068\n",
      " -8.1018\n",
      " -9.0007\n",
      "-11.6241\n",
      " -9.7306\n",
      " -8.8453\n",
      "-10.6171\n",
      " -9.4878\n",
      " -9.4060\n",
      " -9.9873\n",
      " -9.8450\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  183\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.6765\n",
      " -6.1323\n",
      " -7.0347\n",
      " -6.3241\n",
      " -7.2754\n",
      " -6.4957\n",
      " -7.5405\n",
      " -6.6538\n",
      " -6.2796\n",
      " -6.7038\n",
      " -6.4409\n",
      " -7.0322\n",
      " -9.1551\n",
      "-13.0644\n",
      "-17.9174\n",
      "-14.9753\n",
      "-12.4516\n",
      "-10.2475\n",
      " -8.9246\n",
      "-12.2479\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  112\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-7.3783\n",
      "-5.4062\n",
      "-4.2530\n",
      "-4.3064\n",
      "-4.8052\n",
      "-6.0057\n",
      "-4.9824\n",
      "-4.7939\n",
      "-5.1838\n",
      "-5.1048\n",
      "-5.4192\n",
      "-5.6099\n",
      "-5.6778\n",
      "-6.1652\n",
      "-5.9417\n",
      "-6.3548\n",
      "-6.3016\n",
      "-6.6217\n",
      "-6.8675\n",
      "-6.9064\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  101\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.4073\n",
      " -3.7570\n",
      " -2.5731\n",
      " -4.1653\n",
      " -7.6486\n",
      "-12.8369\n",
      " -9.3327\n",
      " -6.4033\n",
      " -4.6127\n",
      " -3.5332\n",
      " -5.6579\n",
      " -4.3269\n",
      " -3.6719\n",
      " -5.3170\n",
      " -4.3337\n",
      " -4.0214\n",
      " -5.1186\n",
      " -7.6085\n",
      "-11.7971\n",
      " -9.6154\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  106\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.6663\n",
      " -4.6657\n",
      " -3.4684\n",
      " -2.9233\n",
      " -3.1160\n",
      " -3.3153\n",
      " -3.3308\n",
      " -3.7787\n",
      " -3.5871\n",
      " -4.2939\n",
      " -3.8632\n",
      " -4.9477\n",
      " -7.2575\n",
      " -5.8955\n",
      " -4.9045\n",
      " -4.7665\n",
      " -5.6627\n",
      " -7.8768\n",
      "-11.5872\n",
      "-16.7914\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  52\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.1594\n",
      " -0.5446\n",
      " -0.0922\n",
      " -0.2787\n",
      " -0.1706\n",
      " -2.6483\n",
      " -8.2804\n",
      " -4.3789\n",
      " -1.4248\n",
      " -6.1651\n",
      "-12.2140\n",
      " -8.4478\n",
      " -4.7888\n",
      "-10.7396\n",
      " -7.1549\n",
      "-13.3125\n",
      " -9.8105\n",
      " -6.3276\n",
      " -3.4797\n",
      " -8.7236\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  124\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.2079\n",
      " -3.1997\n",
      " -1.8207\n",
      " -1.2909\n",
      " -1.3470\n",
      " -1.3198\n",
      " -1.3538\n",
      " -2.6325\n",
      " -5.6967\n",
      "-10.4362\n",
      " -6.8009\n",
      " -3.9367\n",
      " -8.1362\n",
      " -5.1533\n",
      " -9.9025\n",
      " -7.0541\n",
      " -4.8641\n",
      " -9.1567\n",
      " -6.7392\n",
      " -5.2061\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  53\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.3259\n",
      " -6.5556\n",
      " -2.6500\n",
      "  0.0312\n",
      "  0.1264\n",
      " -0.2613\n",
      "  0.1227\n",
      " -1.2728\n",
      " -6.7082\n",
      "-12.5990\n",
      " -9.2536\n",
      " -6.1110\n",
      " -2.8793\n",
      " -8.6401\n",
      " -5.6469\n",
      " -2.1987\n",
      " -8.2949\n",
      "-14.3375\n",
      "-11.6970\n",
      "-17.9597\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  163\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.2422\n",
      "-3.9354\n",
      "-3.4239\n",
      "-4.2590\n",
      "-3.6509\n",
      "-4.3455\n",
      "-3.8948\n",
      "-4.5475\n",
      "-4.2216\n",
      "-4.7331\n",
      "-4.5878\n",
      "-4.9142\n",
      "-5.0241\n",
      "-5.0928\n",
      "-6.4067\n",
      "-8.3771\n",
      "-6.6066\n",
      "-5.5831\n",
      "-6.7180\n",
      "-5.9418\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  174\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-10.8773\n",
      "-14.6000\n",
      "-12.3038\n",
      "-10.4828\n",
      " -9.4482\n",
      " -9.1446\n",
      " -9.9136\n",
      " -9.3423\n",
      "-11.2130\n",
      " -9.6071\n",
      "-10.3807\n",
      "-12.1073\n",
      "-10.6574\n",
      "-10.1013\n",
      "-10.7600\n",
      "-12.4660\n",
      "-10.9612\n",
      "-12.6790\n",
      "-15.5767\n",
      "-13.1478\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  161\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.5127\n",
      " -4.1840\n",
      " -5.8919\n",
      " -4.1071\n",
      " -6.3542\n",
      "-10.1344\n",
      " -7.6480\n",
      " -5.3845\n",
      " -3.4041\n",
      " -2.2362\n",
      " -2.2883\n",
      " -2.8866\n",
      " -4.4977\n",
      " -1.8195\n",
      " -2.8768\n",
      " -0.9568\n",
      " -1.5334\n",
      " -0.8714\n",
      " -3.6203\n",
      " -1.7722\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  180\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.1064\n",
      " -6.2645\n",
      " -3.3465\n",
      " -8.0477\n",
      " -5.2168\n",
      " -2.4026\n",
      " -0.6346\n",
      " -4.0882\n",
      " -1.3464\n",
      " -6.1413\n",
      " -3.1416\n",
      " -8.4514\n",
      "-14.3988\n",
      "-11.4955\n",
      " -8.7977\n",
      " -6.1366\n",
      " -3.4703\n",
      " -1.2464\n",
      " -6.1194\n",
      "-11.8386\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  181\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.3386\n",
      "-10.5143\n",
      " -8.1853\n",
      "-11.5750\n",
      " -9.2358\n",
      "-12.8702\n",
      "-10.4882\n",
      "-14.4313\n",
      "-12.0059\n",
      " -9.9833\n",
      " -8.4391\n",
      " -7.9779\n",
      " -9.1831\n",
      "-12.2200\n",
      "-16.1736\n",
      "-21.3160\n",
      "-18.4825\n",
      "-16.2259\n",
      "-14.1981\n",
      "-12.4763\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  184\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.2959\n",
      "-2.3480\n",
      "-3.5572\n",
      "-6.0506\n",
      "-2.8616\n",
      "-5.0926\n",
      "-2.5607\n",
      "-4.2319\n",
      "-2.4537\n",
      "-3.5336\n",
      "-2.6854\n",
      "-2.9789\n",
      "-3.1746\n",
      "-2.9938\n",
      "-4.0508\n",
      "-3.3147\n",
      "-5.0953\n",
      "-8.9896\n",
      "-7.1067\n",
      "-5.6029\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  59\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.8240\n",
      " -8.9892\n",
      " -5.5215\n",
      " -2.1879\n",
      " -7.5231\n",
      " -4.3453\n",
      " -1.5191\n",
      "  0.0950\n",
      " -3.5789\n",
      " -9.1361\n",
      " -6.5699\n",
      " -4.0102\n",
      " -1.3302\n",
      " -6.8846\n",
      " -4.4134\n",
      " -1.4708\n",
      "  0.0873\n",
      " -4.2704\n",
      "-10.0933\n",
      " -7.5960\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  199\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-11.4082\n",
      "-14.3945\n",
      "-18.7317\n",
      "-16.2604\n",
      "-13.9781\n",
      "-18.1007\n",
      "-15.6384\n",
      "-13.6339\n",
      "-17.2945\n",
      "-15.0406\n",
      "-13.0350\n",
      "-16.2530\n",
      "-14.1765\n",
      "-17.5607\n",
      "-21.9746\n",
      "-19.1502\n",
      "-16.6254\n",
      "-14.5640\n",
      "-17.5948\n",
      "-15.3470\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  96\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.2409\n",
      " -0.5338\n",
      " -0.2357\n",
      " -0.8138\n",
      " -0.2389\n",
      " -1.2249\n",
      " -0.2755\n",
      " -0.1642\n",
      " -0.3204\n",
      " -0.1176\n",
      " -0.4210\n",
      " -3.1231\n",
      " -7.4254\n",
      "-12.4405\n",
      " -9.4892\n",
      "-15.0907\n",
      "-12.2202\n",
      "-18.4328\n",
      "-15.9300\n",
      "-13.1998\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  149\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.6541\n",
      "-2.3964\n",
      "-5.3631\n",
      "-3.4976\n",
      "-2.0152\n",
      "-1.5525\n",
      "-2.0744\n",
      "-3.7515\n",
      "-6.2439\n",
      "-2.8799\n",
      "-1.5530\n",
      "-2.7872\n",
      "-1.9206\n",
      "-3.9977\n",
      "-2.6738\n",
      "-5.9433\n",
      "-4.2943\n",
      "-3.0254\n",
      "-2.6819\n",
      "-4.6731\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  119\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.0920\n",
      "-0.5421\n",
      "-1.5212\n",
      "-3.7024\n",
      "-1.0395\n",
      "-0.1766\n",
      "-0.4694\n",
      "-0.0994\n",
      "-1.2006\n",
      "-0.2251\n",
      "-2.1643\n",
      "-0.9547\n",
      "-0.0773\n",
      " 0.0878\n",
      " 0.0827\n",
      " 0.0560\n",
      "-1.8771\n",
      "-0.6889\n",
      " 0.0497\n",
      "-2.9134\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  109\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.1479\n",
      " -2.2078\n",
      " -0.3712\n",
      " -0.1368\n",
      " -0.5517\n",
      " -3.2988\n",
      " -0.8638\n",
      " -0.1593\n",
      " -0.3139\n",
      " -1.9237\n",
      " -6.9755\n",
      "-12.6685\n",
      "-18.8702\n",
      "-15.9909\n",
      "-13.2336\n",
      "-10.5560\n",
      " -7.8539\n",
      " -5.1824\n",
      " -2.6708\n",
      " -8.8980\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  107\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.4862\n",
      "-1.0755\n",
      "-3.4078\n",
      "-0.9779\n",
      "-3.2224\n",
      "-6.4818\n",
      "-3.1424\n",
      "-0.7655\n",
      "-0.0168\n",
      "-0.1986\n",
      " 0.0424\n",
      "-0.6417\n",
      "-3.1078\n",
      "-1.6557\n",
      "-0.4508\n",
      " 0.0919\n",
      "-1.4279\n",
      "-5.7628\n",
      "-3.9335\n",
      "-2.3762\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  109\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.8008\n",
      " -1.7349\n",
      " -4.0195\n",
      " -7.6895\n",
      "-12.1689\n",
      " -8.6352\n",
      " -5.6294\n",
      " -9.5992\n",
      " -6.6971\n",
      " -3.8234\n",
      " -7.6804\n",
      " -4.8053\n",
      " -8.7891\n",
      "-13.4238\n",
      "-10.3901\n",
      "-15.4370\n",
      "-12.3748\n",
      "-17.8702\n",
      "-14.9923\n",
      "-12.5489\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  153\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.1977\n",
      " -3.5296\n",
      " -1.1636\n",
      " -4.2549\n",
      " -1.5856\n",
      " -5.2616\n",
      " -2.3329\n",
      " -1.1340\n",
      " -3.1628\n",
      " -1.4485\n",
      " -4.2508\n",
      " -2.0728\n",
      " -5.6146\n",
      "-10.6484\n",
      " -7.7010\n",
      "-12.9980\n",
      "-10.1995\n",
      " -7.5563\n",
      " -5.3318\n",
      "-10.0505\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  138\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-12.9963\n",
      " -9.3215\n",
      " -6.2505\n",
      "-10.0423\n",
      " -7.0879\n",
      "-11.1003\n",
      " -8.2260\n",
      "-12.5641\n",
      " -9.6669\n",
      "-14.4021\n",
      "-11.4717\n",
      " -8.9991\n",
      " -6.5149\n",
      " -4.2663\n",
      " -7.9634\n",
      " -5.5436\n",
      " -9.5100\n",
      " -7.0943\n",
      " -4.8931\n",
      " -8.5640\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  153\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " 1.5993e-01\n",
      " 1.7068e-01\n",
      "-9.5903e-01\n",
      " 1.6629e-01\n",
      "-1.6378e+00\n",
      "-6.3435e+00\n",
      "-1.1420e+01\n",
      "-8.3527e+00\n",
      "-5.0994e+00\n",
      "-2.0221e+00\n",
      "-1.0246e-01\n",
      "-3.6845e+00\n",
      "-9.9865e-01\n",
      " 3.2986e-04\n",
      "-2.4193e+00\n",
      "-7.4336e+00\n",
      "-1.3266e+01\n",
      "-1.0335e+01\n",
      "-7.5230e+00\n",
      "-1.3426e+01\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  68\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " 0.0434\n",
      "-0.1594\n",
      " 0.0507\n",
      "-0.0700\n",
      " 0.0232\n",
      "-1.0656\n",
      "-4.2558\n",
      "-8.5709\n",
      "-6.7063\n",
      "-4.8175\n",
      "-2.9775\n",
      "-1.1893\n",
      " 0.0090\n",
      "-3.2109\n",
      "-1.2026\n",
      " 0.0463\n",
      "-3.2918\n",
      "-1.3371\n",
      " 0.0125\n",
      "-3.6526\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  110\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8279\n",
      " -1.0967\n",
      " -3.5326\n",
      " -1.5527\n",
      " -0.7660\n",
      " -1.8060\n",
      " -0.8364\n",
      " -0.8907\n",
      " -2.0535\n",
      " -0.9695\n",
      " -2.7990\n",
      " -1.2895\n",
      " -0.5341\n",
      " -0.5289\n",
      " -0.5886\n",
      " -3.0466\n",
      " -6.5147\n",
      "-12.2312\n",
      "-10.5664\n",
      " -9.0617\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  147\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0283\n",
      " -5.9766\n",
      " -9.9465\n",
      " -7.1473\n",
      " -5.0162\n",
      " -3.2118\n",
      " -6.1541\n",
      "-10.1353\n",
      " -7.9411\n",
      " -5.9327\n",
      "-10.0660\n",
      "-15.1435\n",
      "-13.0873\n",
      "-10.9827\n",
      " -8.9530\n",
      " -6.6750\n",
      " -4.2823\n",
      " -2.3690\n",
      " -6.6163\n",
      "-11.6666\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  126\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.4951\n",
      " -0.2321\n",
      "  0.0832\n",
      " -0.7402\n",
      " -4.8235\n",
      " -1.6229\n",
      " -0.1071\n",
      "  0.0654\n",
      " -0.1340\n",
      " -1.3767\n",
      " -0.2005\n",
      " -2.3926\n",
      " -0.4571\n",
      " -4.2462\n",
      " -1.8064\n",
      " -6.7884\n",
      "-12.3130\n",
      "-10.5040\n",
      "-16.4249\n",
      "-15.1137\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  84\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.8477\n",
      " -0.8109\n",
      " -3.3819\n",
      " -1.1166\n",
      " -0.2890\n",
      " -0.4300\n",
      " -3.0198\n",
      " -0.8887\n",
      " -0.4650\n",
      " -1.4595\n",
      " -4.7284\n",
      " -9.1370\n",
      " -6.5973\n",
      " -4.4883\n",
      " -8.7209\n",
      "-13.8701\n",
      "-11.8134\n",
      "-17.3984\n",
      "-15.6538\n",
      "-21.7494\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  165\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -9.0342\n",
      " -6.7441\n",
      " -4.4124\n",
      " -3.1747\n",
      " -4.8909\n",
      " -7.9656\n",
      "-11.5003\n",
      " -9.1658\n",
      " -7.0485\n",
      " -4.9293\n",
      " -8.0658\n",
      "-11.4668\n",
      " -9.4967\n",
      " -7.4997\n",
      " -5.5116\n",
      " -8.7058\n",
      " -6.6597\n",
      " -5.0492\n",
      " -4.5993\n",
      " -5.6459\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  114\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-10.2736\n",
      " -7.9650\n",
      "-11.9108\n",
      " -9.5165\n",
      " -7.4582\n",
      " -5.3386\n",
      " -8.7569\n",
      " -6.6752\n",
      "-10.1593\n",
      " -8.1526\n",
      "-11.7710\n",
      " -9.8402\n",
      " -7.8872\n",
      "-11.4517\n",
      " -9.5258\n",
      " -7.6121\n",
      "-11.0941\n",
      " -9.2078\n",
      "-12.7995\n",
      "-16.8701\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  71\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.5184\n",
      " -5.7926\n",
      " -3.2414\n",
      " -7.8963\n",
      "-13.1047\n",
      "-10.8585\n",
      " -8.4849\n",
      " -5.5468\n",
      "-11.3896\n",
      " -8.5839\n",
      " -5.6365\n",
      " -2.6031\n",
      " -8.5290\n",
      " -5.3846\n",
      " -2.3849\n",
      " -8.2229\n",
      " -4.9511\n",
      " -2.2854\n",
      " -7.6425\n",
      "-14.2796\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  136\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.1987\n",
      "  0.1303\n",
      "  0.1348\n",
      "  0.1301\n",
      "  0.1278\n",
      "  0.1304\n",
      " -0.0673\n",
      "  0.1303\n",
      "  0.0873\n",
      "  0.1318\n",
      " -0.0023\n",
      " -2.2090\n",
      " -6.1994\n",
      " -4.1234\n",
      " -1.9354\n",
      " -6.2033\n",
      " -4.2210\n",
      " -8.9954\n",
      " -7.1077\n",
      "-12.5082\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  142\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.8974\n",
      " -0.6542\n",
      " -2.0106\n",
      " -4.9895\n",
      " -2.2786\n",
      " -0.8244\n",
      " -2.5910\n",
      " -6.0188\n",
      " -3.4781\n",
      " -7.1863\n",
      " -4.7805\n",
      " -8.8176\n",
      " -6.5253\n",
      " -4.4012\n",
      " -2.8046\n",
      " -6.0870\n",
      " -4.2577\n",
      " -3.0283\n",
      " -5.9020\n",
      "-10.0853\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  155\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.4005\n",
      " -1.2126\n",
      " -0.5180\n",
      " -1.0587\n",
      " -0.5399\n",
      " -1.5133\n",
      " -4.5119\n",
      " -2.1059\n",
      " -5.4508\n",
      " -2.9823\n",
      " -1.3652\n",
      " -3.8804\n",
      " -7.7862\n",
      "-12.5166\n",
      "-10.0991\n",
      " -7.7497\n",
      " -5.6819\n",
      " -9.9513\n",
      " -7.8655\n",
      " -6.1658\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  130\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-5.8394\n",
      "-4.1047\n",
      "-6.9845\n",
      "-5.2050\n",
      "-3.8179\n",
      "-6.3238\n",
      "-4.7839\n",
      "-3.6968\n",
      "-3.5945\n",
      "-4.2788\n",
      "-6.6467\n",
      "-5.1813\n",
      "-4.2093\n",
      "-6.0916\n",
      "-8.9529\n",
      "-7.5081\n",
      "-6.1273\n",
      "-8.8880\n",
      "-7.4615\n",
      "-6.2769\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  192\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.6492\n",
      " -4.7606\n",
      " -4.7650\n",
      " -5.9407\n",
      " -8.3905\n",
      " -6.6684\n",
      " -5.3442\n",
      " -5.0563\n",
      " -5.5573\n",
      " -5.0544\n",
      " -5.5897\n",
      " -5.0131\n",
      " -5.5517\n",
      " -7.3573\n",
      " -5.8415\n",
      " -7.7571\n",
      "-10.3077\n",
      " -8.5881\n",
      " -7.0265\n",
      " -9.3900\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  177\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.7075\n",
      " -5.9461\n",
      " -4.3271\n",
      " -3.4434\n",
      " -4.8947\n",
      " -7.5550\n",
      " -5.8585\n",
      " -4.5968\n",
      " -6.8139\n",
      "-10.1039\n",
      " -8.2505\n",
      " -6.8449\n",
      " -5.7034\n",
      " -5.0705\n",
      " -6.5369\n",
      " -9.1283\n",
      " -7.7676\n",
      "-10.6227\n",
      " -9.3507\n",
      "-12.4631\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  169\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.7318\n",
      " -7.1194\n",
      " -5.3329\n",
      " -7.8939\n",
      " -6.1470\n",
      " -4.7295\n",
      " -6.9047\n",
      " -5.4047\n",
      " -7.8017\n",
      "-11.1008\n",
      " -9.1828\n",
      " -7.7513\n",
      " -6.4337\n",
      " -8.9419\n",
      " -7.5537\n",
      " -6.4003\n",
      " -8.6582\n",
      " -7.3869\n",
      " -6.4291\n",
      " -6.4717\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  153\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.1021\n",
      " -0.3896\n",
      " -0.5255\n",
      " -0.4440\n",
      " -1.2211\n",
      " -0.4897\n",
      " -0.7336\n",
      " -2.2820\n",
      " -1.0721\n",
      " -0.6723\n",
      " -0.9236\n",
      " -0.8440\n",
      " -2.1723\n",
      " -5.2777\n",
      " -3.5624\n",
      " -7.3444\n",
      " -5.7241\n",
      "-10.0491\n",
      " -8.6337\n",
      " -7.1329\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  160\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.1493\n",
      " -0.0797\n",
      " -2.1608\n",
      " -6.5987\n",
      " -4.1346\n",
      " -2.0607\n",
      " -0.3465\n",
      "  0.0987\n",
      " -1.0193\n",
      " -4.9709\n",
      " -9.8407\n",
      " -7.7205\n",
      "-12.8560\n",
      "-11.0176\n",
      " -8.7221\n",
      " -5.9840\n",
      " -3.2079\n",
      " -8.9721\n",
      " -6.0076\n",
      "-12.2392\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  163\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.8490\n",
      "-5.4059\n",
      "-8.8807\n",
      "-5.8255\n",
      "-4.1150\n",
      "-3.2969\n",
      "-3.4093\n",
      "-3.4342\n",
      "-3.6936\n",
      "-5.9739\n",
      "-9.2415\n",
      "-7.2391\n",
      "-5.5038\n",
      "-8.7511\n",
      "-6.9603\n",
      "-5.8803\n",
      "-5.3689\n",
      "-5.2055\n",
      "-6.0446\n",
      "-5.6398\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  186\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.5052\n",
      " -5.4616\n",
      " -4.4332\n",
      " -5.3280\n",
      " -7.8720\n",
      " -5.2138\n",
      " -4.1725\n",
      " -5.3177\n",
      " -8.0506\n",
      " -5.9379\n",
      " -4.2174\n",
      " -6.8261\n",
      " -4.8501\n",
      " -3.3629\n",
      " -3.0161\n",
      " -3.7121\n",
      " -7.5210\n",
      " -5.0269\n",
      "-10.2497\n",
      "-16.7082\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  127\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-0.3491\n",
      "-0.2312\n",
      "-0.9524\n",
      "-0.0582\n",
      "-2.3584\n",
      "-0.2770\n",
      "-0.0178\n",
      "-1.1050\n",
      "-0.0372\n",
      "-2.7864\n",
      "-8.8516\n",
      "-5.5747\n",
      "-2.5238\n",
      "-8.6188\n",
      "-5.4597\n",
      "-2.4904\n",
      "-8.5086\n",
      "-5.5718\n",
      "-2.7095\n",
      "-8.5279\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  163\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.5441\n",
      " -0.0104\n",
      " -1.1360\n",
      " -5.5363\n",
      "-11.6246\n",
      " -8.2551\n",
      " -4.9867\n",
      " -2.0675\n",
      " -0.0316\n",
      " -4.2938\n",
      " -1.3187\n",
      " -7.2169\n",
      " -4.1136\n",
      " -0.9960\n",
      " -7.1916\n",
      " -3.9835\n",
      "-10.5884\n",
      " -7.4946\n",
      " -4.1885\n",
      "-10.9093\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  130\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "  0.1471\n",
      " -1.5682\n",
      "  0.1200\n",
      "  0.1545\n",
      "  0.1695\n",
      "  0.1495\n",
      "  0.1669\n",
      " -0.0528\n",
      " -2.0088\n",
      " -0.3175\n",
      " -3.4075\n",
      " -7.8004\n",
      " -5.9658\n",
      "-10.8917\n",
      " -9.4574\n",
      " -8.0165\n",
      " -6.4954\n",
      " -4.7744\n",
      " -9.9168\n",
      " -8.4997\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  153\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.6608\n",
      " -2.2422\n",
      " -1.6614\n",
      " -2.6118\n",
      " -4.9022\n",
      " -3.2257\n",
      " -6.1868\n",
      " -9.9575\n",
      " -8.0948\n",
      " -5.9125\n",
      " -3.7765\n",
      " -7.5709\n",
      " -5.1528\n",
      " -9.4179\n",
      "-13.8104\n",
      "-19.0418\n",
      "-17.1246\n",
      "-15.2878\n",
      "-13.4112\n",
      "-11.3227\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  162\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.0546\n",
      " -5.3114\n",
      " -3.5505\n",
      " -1.8525\n",
      " -0.6355\n",
      " -0.1408\n",
      "  0.1066\n",
      " -0.7722\n",
      " -0.0762\n",
      " -2.1335\n",
      " -0.8064\n",
      "  0.0807\n",
      " -2.0938\n",
      " -0.4288\n",
      " -4.2847\n",
      " -9.6707\n",
      " -7.6299\n",
      " -5.0289\n",
      "-10.9876\n",
      " -8.6482\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  104\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.1950\n",
      " -3.2480\n",
      " -6.3353\n",
      " -3.8215\n",
      " -7.4287\n",
      " -4.8232\n",
      " -2.4413\n",
      " -1.3994\n",
      " -3.3512\n",
      " -7.3433\n",
      " -5.0266\n",
      " -2.7647\n",
      " -0.8620\n",
      " -0.4836\n",
      " -1.8355\n",
      " -5.7696\n",
      " -3.4985\n",
      " -9.1075\n",
      " -6.4989\n",
      "-13.3645\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  136\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.1342\n",
      "  0.1336\n",
      "  0.1735\n",
      "  0.1253\n",
      " -1.9024\n",
      " -7.6351\n",
      " -2.5828\n",
      "  0.0750\n",
      "  0.1670\n",
      "  0.0725\n",
      "  0.1634\n",
      "  0.0906\n",
      "  0.1610\n",
      "  0.0280\n",
      " -0.9092\n",
      " -4.4450\n",
      " -9.3211\n",
      "-14.9301\n",
      "-14.3797\n",
      "-13.9167\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  121\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-8.5657\n",
      "-3.9720\n",
      "-0.1156\n",
      " 0.1660\n",
      " 0.1516\n",
      "-0.2208\n",
      "-1.4391\n",
      "-5.0433\n",
      "-9.5485\n",
      "-8.0181\n",
      "-6.4688\n",
      "-4.8806\n",
      "-3.3984\n",
      "-2.4071\n",
      "-1.0062\n",
      "-4.2756\n",
      "-9.1671\n",
      "-7.7226\n",
      "-6.1817\n",
      "-4.4592\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  163\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "  0.0924\n",
      "  0.1640\n",
      "  0.0934\n",
      "  0.1572\n",
      "  0.0450\n",
      "  0.1513\n",
      "  0.0803\n",
      " -2.2498\n",
      "  0.0964\n",
      "  0.1463\n",
      " -0.1826\n",
      "  0.0956\n",
      " -0.5601\n",
      " -0.1020\n",
      " -1.8193\n",
      " -6.0616\n",
      "-11.4577\n",
      "-10.4359\n",
      " -9.4173\n",
      " -8.3337\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  34\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "  0.0844\n",
      "  0.1309\n",
      "  0.0029\n",
      "  0.1261\n",
      " -0.0012\n",
      "  0.1190\n",
      " -0.2303\n",
      "  0.1145\n",
      " -0.0390\n",
      " -2.1799\n",
      " -0.3289\n",
      "  0.0626\n",
      " -0.8410\n",
      " -4.6174\n",
      " -9.4542\n",
      "-14.8305\n",
      "-20.6749\n",
      "-19.4600\n",
      "-18.2938\n",
      "-17.1726\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  60\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.0720\n",
      " -0.9658\n",
      " -0.2673\n",
      " -2.3124\n",
      " -1.0588\n",
      " -4.5026\n",
      " -2.8563\n",
      " -1.7393\n",
      " -5.1087\n",
      "-10.0962\n",
      " -8.3828\n",
      " -6.9569\n",
      " -5.2617\n",
      " -3.0021\n",
      " -7.9595\n",
      " -5.6716\n",
      " -3.1903\n",
      " -8.4571\n",
      "-14.3383\n",
      "-11.9570\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  194\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.1815\n",
      " -3.3750\n",
      " -9.6476\n",
      "-17.0251\n",
      "-11.8120\n",
      " -6.6326\n",
      " -2.4638\n",
      " -0.3314\n",
      "  0.0262\n",
      " -0.1195\n",
      " -0.9746\n",
      " -0.2559\n",
      " -1.8416\n",
      " -6.0950\n",
      " -4.4144\n",
      "-10.1654\n",
      " -8.7855\n",
      " -7.4672\n",
      " -6.3061\n",
      "-12.4409\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  198\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-18.8993\n",
      "-19.5245\n",
      "-19.4388\n",
      "-20.0208\n",
      "-20.8898\n",
      "-22.5002\n",
      "-21.5167\n",
      "-21.1594\n",
      "-21.1001\n",
      "-21.6739\n",
      "-22.5281\n",
      "-22.2290\n",
      "-23.0758\n",
      "-22.7873\n",
      "-23.6268\n",
      "-25.1743\n",
      "-24.2567\n",
      "-25.9615\n",
      "-24.9065\n",
      "-24.5929\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  148\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.8459\n",
      " -4.5993\n",
      " -4.6886\n",
      " -6.7911\n",
      "-10.8289\n",
      " -7.3504\n",
      " -5.0750\n",
      " -4.6133\n",
      " -5.2946\n",
      " -8.4008\n",
      "-13.1146\n",
      "-19.2253\n",
      "-15.5943\n",
      "-12.2059\n",
      "-18.6899\n",
      "-15.3687\n",
      "-12.4526\n",
      "-19.1573\n",
      "-16.1193\n",
      "-13.5860\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  187\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-19.2077\n",
      "-20.2865\n",
      "-21.9557\n",
      "-20.7739\n",
      "-20.1307\n",
      "-21.1555\n",
      "-20.5928\n",
      "-20.5662\n",
      "-22.7327\n",
      "-21.3186\n",
      "-21.3929\n",
      "-22.4431\n",
      "-21.9256\n",
      "-22.5006\n",
      "-22.5844\n",
      "-22.9685\n",
      "-23.5846\n",
      "-24.1846\n",
      "-24.1818\n",
      "-24.7506\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  196\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-17.3203\n",
      "-17.4458\n",
      "-18.1423\n",
      "-19.0747\n",
      "-18.6289\n",
      "-18.3743\n",
      "-19.0313\n",
      "-19.2251\n",
      "-19.4657\n",
      "-20.2441\n",
      "-19.9637\n",
      "-20.3975\n",
      "-20.6355\n",
      "-22.6267\n",
      "-21.7788\n",
      "-21.4750\n",
      "-21.8242\n",
      "-22.2407\n",
      "-22.4395\n",
      "-23.2180\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  197\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-14.8871\n",
      "-14.3322\n",
      "-15.4588\n",
      "-15.0043\n",
      "-16.0250\n",
      "-15.7097\n",
      "-17.1896\n",
      "-16.3804\n",
      "-17.0961\n",
      "-18.6463\n",
      "-17.8849\n",
      "-17.8014\n",
      "-19.0406\n",
      "-18.4535\n",
      "-19.7250\n",
      "-19.1168\n",
      "-20.4443\n",
      "-19.7934\n",
      "-21.2177\n",
      "-20.5026\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  169\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-13.5784\n",
      "-13.0953\n",
      "-14.6451\n",
      "-18.0968\n",
      "-15.8949\n",
      "-14.2718\n",
      "-17.2617\n",
      "-15.5072\n",
      "-14.4958\n",
      "-15.0826\n",
      "-15.7420\n",
      "-16.8653\n",
      "-16.1475\n",
      "-17.1872\n",
      "-16.5927\n",
      "-17.5404\n",
      "-19.4138\n",
      "-18.1064\n",
      "-17.5770\n",
      "-18.5416\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  170\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-10.9784\n",
      "-13.1835\n",
      "-11.7687\n",
      "-11.5373\n",
      "-12.2382\n",
      "-12.8398\n",
      "-12.4339\n",
      "-12.9229\n",
      "-12.6356\n",
      "-13.1437\n",
      "-14.0148\n",
      "-13.5016\n",
      "-13.3519\n",
      "-15.3158\n",
      "-14.2330\n",
      "-13.9951\n",
      "-14.3723\n",
      "-15.1567\n",
      "-14.8053\n",
      "-15.0984\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  191\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -9.7494\n",
      " -8.7377\n",
      " -8.1707\n",
      " -9.3054\n",
      " -8.6603\n",
      " -9.1371\n",
      "-10.8675\n",
      " -9.5382\n",
      " -9.4287\n",
      " -9.8739\n",
      " -9.8261\n",
      "-10.8009\n",
      "-10.2836\n",
      "-10.4779\n",
      "-10.6817\n",
      "-10.8658\n",
      "-12.6710\n",
      "-11.4411\n",
      "-11.3795\n",
      "-11.9453\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  185\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-7.6016\n",
      "-6.1672\n",
      "-5.1676\n",
      "-7.2132\n",
      "-6.0552\n",
      "-5.1338\n",
      "-5.0528\n",
      "-5.9541\n",
      "-5.4104\n",
      "-6.4058\n",
      "-5.8004\n",
      "-6.3660\n",
      "-6.2067\n",
      "-6.7317\n",
      "-6.5967\n",
      "-7.1387\n",
      "-8.6840\n",
      "-7.7302\n",
      "-7.4926\n",
      "-8.2444\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  184\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.7743\n",
      "-2.0742\n",
      "-3.1066\n",
      "-2.3417\n",
      "-3.4415\n",
      "-2.6092\n",
      "-3.3683\n",
      "-2.8838\n",
      "-3.9080\n",
      "-3.3388\n",
      "-4.5773\n",
      "-3.8602\n",
      "-5.4223\n",
      "-4.4746\n",
      "-6.5790\n",
      "-5.1914\n",
      "-4.7084\n",
      "-4.9979\n",
      "-5.1011\n",
      "-6.4258\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  147\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.7904\n",
      "-0.3643\n",
      "-2.3446\n",
      "-0.6648\n",
      "-3.1248\n",
      "-1.1805\n",
      "-4.2454\n",
      "-2.0016\n",
      "-0.6725\n",
      "-3.0502\n",
      "-1.2934\n",
      "-4.4881\n",
      "-2.3269\n",
      "-6.3290\n",
      "-4.0151\n",
      "-2.2217\n",
      "-5.9471\n",
      "-3.8562\n",
      "-8.2572\n",
      "-6.0793\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  128\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.5504\n",
      " -4.0140\n",
      " -8.6388\n",
      " -5.9172\n",
      " -3.6352\n",
      " -1.9311\n",
      " -0.5616\n",
      " -0.1692\n",
      " -1.2522\n",
      " -0.4039\n",
      " -2.0245\n",
      " -4.8610\n",
      " -3.0168\n",
      " -6.3320\n",
      "-11.2131\n",
      " -8.5805\n",
      " -6.0626\n",
      "-10.8898\n",
      " -8.3751\n",
      " -6.0101\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  190\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.1875\n",
      "-0.6733\n",
      "-2.5619\n",
      "-0.9998\n",
      "-0.4216\n",
      "-1.2508\n",
      "-3.9134\n",
      "-7.8151\n",
      "-5.1239\n",
      "-2.7957\n",
      "-1.4098\n",
      "-1.0287\n",
      "-2.4303\n",
      "-4.3710\n",
      "-7.3965\n",
      "-5.0691\n",
      "-3.3373\n",
      "-1.9387\n",
      "-1.5187\n",
      "-2.4721\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  152\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-1.1202\n",
      "-2.3178\n",
      "-5.3079\n",
      "-2.8698\n",
      "-1.4000\n",
      "-2.0866\n",
      "-3.9143\n",
      "-2.4197\n",
      "-4.5781\n",
      "-2.8760\n",
      "-1.9307\n",
      "-2.0798\n",
      "-3.5833\n",
      "-2.0686\n",
      "-3.2558\n",
      "-2.1505\n",
      "-2.9435\n",
      "-2.2528\n",
      "-3.4421\n",
      "-2.6360\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  159\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.0354\n",
      "  0.0777\n",
      "  0.1771\n",
      " -0.1190\n",
      "  0.1588\n",
      " -0.7175\n",
      " -4.9747\n",
      "-10.5328\n",
      " -7.4839\n",
      " -4.2636\n",
      " -1.4965\n",
      " -0.0816\n",
      " -2.9176\n",
      " -0.7493\n",
      " -4.7771\n",
      "-10.5280\n",
      " -7.3211\n",
      "-13.3245\n",
      "-10.3517\n",
      " -7.2665\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  175\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.1593\n",
      "-0.0607\n",
      "-1.5794\n",
      "-0.0614\n",
      "-0.9764\n",
      "-0.1441\n",
      "-2.0188\n",
      "-5.5772\n",
      "-3.3811\n",
      "-1.3267\n",
      "-0.2764\n",
      "-2.4671\n",
      "-0.8259\n",
      "-3.9941\n",
      "-8.4239\n",
      "-6.2768\n",
      "-4.1198\n",
      "-2.3692\n",
      "-6.2735\n",
      "-4.2412\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  147\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -4.9346\n",
      " -9.0031\n",
      " -6.5367\n",
      "-11.0289\n",
      " -8.4199\n",
      " -6.2481\n",
      " -4.4264\n",
      " -3.3118\n",
      " -2.5491\n",
      " -2.2366\n",
      " -3.0948\n",
      " -4.5613\n",
      " -6.6925\n",
      " -5.1040\n",
      " -7.3346\n",
      " -5.6856\n",
      " -4.6279\n",
      " -3.8058\n",
      " -4.9302\n",
      " -4.0619\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  171\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-7.0484\n",
      "-5.2196\n",
      "-3.8899\n",
      "-5.9531\n",
      "-9.2358\n",
      "-7.1089\n",
      "-5.5166\n",
      "-8.3846\n",
      "-6.5029\n",
      "-5.2517\n",
      "-4.1283\n",
      "-4.0024\n",
      "-4.6513\n",
      "-4.2610\n",
      "-4.9223\n",
      "-4.5663\n",
      "-5.2166\n",
      "-4.8928\n",
      "-5.5765\n",
      "-5.2202\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  125\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-11.7891\n",
      " -9.1693\n",
      "-13.0156\n",
      "-10.2457\n",
      "-14.3105\n",
      "-11.4448\n",
      " -9.2716\n",
      "-12.4382\n",
      "-16.7670\n",
      "-13.7984\n",
      "-11.2892\n",
      " -9.6553\n",
      " -8.5967\n",
      " -7.6355\n",
      " -8.9808\n",
      "-10.5039\n",
      "-12.7436\n",
      "-10.8996\n",
      "-13.1699\n",
      "-11.3248\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  145\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.9025\n",
      " -7.2907\n",
      " -9.5643\n",
      "-13.4495\n",
      "-10.7764\n",
      " -8.6415\n",
      "-12.0147\n",
      " -9.6180\n",
      "-13.5402\n",
      "-11.0671\n",
      " -9.4756\n",
      "-12.6389\n",
      "-10.5523\n",
      "-14.4920\n",
      "-12.2071\n",
      "-10.7786\n",
      " -9.8448\n",
      "-11.8904\n",
      "-10.8886\n",
      "-10.0365\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  152\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.3296\n",
      " -6.4892\n",
      " -8.3552\n",
      " -7.0759\n",
      " -9.2086\n",
      " -7.7617\n",
      " -6.8051\n",
      " -7.1918\n",
      " -7.1606\n",
      " -7.3095\n",
      " -8.3873\n",
      "-10.5299\n",
      "-13.7086\n",
      "-11.5853\n",
      "-15.0898\n",
      "-13.1030\n",
      "-11.2034\n",
      "-14.7344\n",
      "-12.9477\n",
      "-11.3175\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  139\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-10.7935\n",
      "-15.2998\n",
      "-12.9376\n",
      "-17.5665\n",
      "-15.4020\n",
      "-13.0437\n",
      "-11.0703\n",
      " -9.7883\n",
      " -9.0481\n",
      " -8.5674\n",
      " -9.8550\n",
      "-11.9402\n",
      "-15.5009\n",
      "-13.2718\n",
      "-12.0326\n",
      "-11.0762\n",
      "-13.0379\n",
      "-11.9035\n",
      "-11.3807\n",
      "-12.7308\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  123\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -7.9281\n",
      " -6.9057\n",
      " -7.9751\n",
      "-10.0815\n",
      " -8.2192\n",
      " -7.3770\n",
      " -8.3918\n",
      " -7.5944\n",
      " -7.3325\n",
      " -7.7841\n",
      " -8.7899\n",
      " -8.0135\n",
      " -7.7757\n",
      " -8.2180\n",
      " -7.9905\n",
      " -8.4142\n",
      " -9.4827\n",
      "-11.0237\n",
      " -9.9251\n",
      "-11.6986\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  163\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -8.9030\n",
      " -6.9611\n",
      " -5.7674\n",
      " -5.1982\n",
      " -6.2099\n",
      " -5.5233\n",
      " -6.6982\n",
      " -5.9832\n",
      " -5.6686\n",
      " -6.0382\n",
      " -7.5111\n",
      " -6.3697\n",
      " -8.0311\n",
      " -6.8751\n",
      " -6.4217\n",
      " -7.3219\n",
      " -6.6748\n",
      " -7.0902\n",
      " -8.2398\n",
      "-10.0644\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  140\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.7407\n",
      "-3.5605\n",
      "-4.3499\n",
      "-4.1769\n",
      "-4.7846\n",
      "-4.6487\n",
      "-5.0926\n",
      "-5.7469\n",
      "-6.5921\n",
      "-6.0688\n",
      "-6.9134\n",
      "-8.7408\n",
      "-7.3817\n",
      "-9.3257\n",
      "-7.9273\n",
      "-7.1383\n",
      "-6.8311\n",
      "-6.5802\n",
      "-7.1172\n",
      "-6.8463\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  126\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.7158\n",
      "-2.7930\n",
      "-3.1634\n",
      "-3.8126\n",
      "-4.5553\n",
      "-4.1118\n",
      "-3.7005\n",
      "-4.3545\n",
      "-5.0299\n",
      "-4.5859\n",
      "-5.1864\n",
      "-4.8000\n",
      "-5.3295\n",
      "-6.1874\n",
      "-5.5205\n",
      "-5.1813\n",
      "-5.1137\n",
      "-5.3422\n",
      "-5.5812\n",
      "-5.5728\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  154\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.9793\n",
      "-3.4270\n",
      "-3.0473\n",
      "-3.7007\n",
      "-3.3597\n",
      "-3.9424\n",
      "-3.6285\n",
      "-4.1697\n",
      "-5.1930\n",
      "-4.4379\n",
      "-5.6345\n",
      "-4.8122\n",
      "-4.4738\n",
      "-5.1731\n",
      "-4.7783\n",
      "-4.7568\n",
      "-5.0665\n",
      "-5.0642\n",
      "-5.3097\n",
      "-5.3788\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  142\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.2090\n",
      " -2.2233\n",
      " -2.8000\n",
      " -2.3211\n",
      " -2.8166\n",
      " -3.7894\n",
      " -2.9056\n",
      " -2.7848\n",
      " -2.9590\n",
      " -3.2619\n",
      " -3.0604\n",
      " -3.5163\n",
      " -3.2999\n",
      " -4.6688\n",
      " -7.1947\n",
      " -5.7872\n",
      " -4.7128\n",
      " -7.0473\n",
      "-10.6318\n",
      " -9.0049\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  155\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-3.8219\n",
      "-3.5342\n",
      "-3.6154\n",
      "-3.8774\n",
      "-4.1770\n",
      "-4.6030\n",
      "-6.0178\n",
      "-4.8793\n",
      "-4.5681\n",
      "-5.1386\n",
      "-4.7903\n",
      "-4.8955\n",
      "-5.0046\n",
      "-5.1878\n",
      "-5.2480\n",
      "-5.5173\n",
      "-5.5059\n",
      "-6.0912\n",
      "-5.7463\n",
      "-6.1380\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  123\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.7781\n",
      " -0.3337\n",
      " -0.0106\n",
      " -0.8091\n",
      " -0.0629\n",
      " -0.1959\n",
      " -1.4702\n",
      " -0.1498\n",
      " -0.3866\n",
      " -2.6745\n",
      " -6.9493\n",
      " -4.3509\n",
      " -9.2003\n",
      " -6.7810\n",
      " -4.1296\n",
      " -2.1625\n",
      " -0.9231\n",
      " -3.5646\n",
      " -8.5681\n",
      "-13.9530\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  118\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.0922\n",
      " -0.6927\n",
      " -3.0138\n",
      " -1.3953\n",
      " -0.6242\n",
      " -0.9964\n",
      " -0.8893\n",
      " -0.9576\n",
      " -1.8117\n",
      " -1.0546\n",
      " -1.7887\n",
      " -1.2526\n",
      " -2.4013\n",
      " -5.1133\n",
      " -9.6316\n",
      " -7.1170\n",
      "-12.2856\n",
      "-10.0262\n",
      " -7.6364\n",
      " -5.4768\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  121\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.8645\n",
      " -5.4853\n",
      " -8.3843\n",
      " -6.1921\n",
      " -9.5813\n",
      " -7.1212\n",
      " -5.6515\n",
      " -4.8288\n",
      " -6.3699\n",
      " -9.0789\n",
      " -7.2587\n",
      "-10.3665\n",
      " -8.2934\n",
      " -6.9703\n",
      " -9.4658\n",
      "-13.5254\n",
      "-19.0964\n",
      "-16.3091\n",
      "-13.6846\n",
      "-11.6414\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  120\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -2.3955\n",
      " -5.1377\n",
      " -3.1124\n",
      " -2.0868\n",
      " -3.8268\n",
      " -2.5704\n",
      " -2.0382\n",
      " -3.1508\n",
      " -5.7817\n",
      "-10.4731\n",
      " -7.6498\n",
      " -5.2867\n",
      " -9.8692\n",
      " -7.1622\n",
      " -5.1941\n",
      " -4.1192\n",
      " -6.7026\n",
      "-11.7271\n",
      " -8.9210\n",
      "-14.6733\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  135\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.8033\n",
      " -9.6327\n",
      " -7.9397\n",
      "-11.2896\n",
      " -9.5279\n",
      " -8.2286\n",
      " -7.5415\n",
      " -9.5931\n",
      " -8.5439\n",
      " -8.1361\n",
      " -9.8008\n",
      " -9.0305\n",
      " -8.7511\n",
      " -8.7085\n",
      " -9.1837\n",
      " -9.3018\n",
      " -9.5787\n",
      "-10.1319\n",
      "-10.1512\n",
      "-10.9555\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  186\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.4514\n",
      " -6.3520\n",
      " -7.0427\n",
      " -6.9215\n",
      " -7.2200\n",
      " -7.5339\n",
      " -7.8107\n",
      " -8.1242\n",
      " -8.6052\n",
      " -8.6291\n",
      " -9.0378\n",
      " -9.7363\n",
      " -9.4682\n",
      " -9.5825\n",
      " -9.9113\n",
      "-10.6877\n",
      "-10.3420\n",
      "-11.2305\n",
      "-10.8327\n",
      "-11.0022\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  192\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.7848\n",
      " -7.4918\n",
      " -7.3461\n",
      " -7.4499\n",
      " -7.8465\n",
      " -7.8710\n",
      " -8.0616\n",
      " -9.1491\n",
      " -8.5227\n",
      " -9.7499\n",
      "-12.3974\n",
      "-10.7091\n",
      " -9.7140\n",
      "-11.8190\n",
      "-10.5515\n",
      "-13.1742\n",
      "-11.6633\n",
      "-14.8248\n",
      "-19.3725\n",
      "-17.3991\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  128\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-6.9136\n",
      "-6.3273\n",
      "-6.1560\n",
      "-7.2170\n",
      "-9.9792\n",
      "-7.9644\n",
      "-6.9289\n",
      "-7.0816\n",
      "-7.3716\n",
      "-7.4189\n",
      "-8.0201\n",
      "-7.8137\n",
      "-8.2976\n",
      "-9.0362\n",
      "-8.6258\n",
      "-9.3553\n",
      "-8.9603\n",
      "-9.6816\n",
      "-9.2982\n",
      "-9.4967\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  182\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.3539\n",
      " -0.9782\n",
      " -1.5503\n",
      " -3.4741\n",
      " -7.5760\n",
      " -4.4410\n",
      " -8.9989\n",
      " -5.7187\n",
      " -3.3035\n",
      " -7.1598\n",
      " -4.4514\n",
      " -9.0763\n",
      " -6.0311\n",
      "-11.3342\n",
      " -8.2218\n",
      " -5.6879\n",
      "-10.7155\n",
      " -7.7138\n",
      "-13.5481\n",
      "-10.6141\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  160\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.9568\n",
      " -3.5152\n",
      " -4.0930\n",
      " -4.7854\n",
      " -6.0511\n",
      " -5.0619\n",
      " -4.4588\n",
      " -4.5288\n",
      " -4.6306\n",
      " -5.1254\n",
      " -4.8849\n",
      " -5.9385\n",
      " -5.2452\n",
      " -7.1354\n",
      " -5.8243\n",
      " -8.5696\n",
      "-12.6542\n",
      "-10.7434\n",
      " -9.0590\n",
      " -7.6233\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  167\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.3641\n",
      " -2.6525\n",
      " -2.2395\n",
      " -3.3885\n",
      " -5.4710\n",
      " -4.1000\n",
      " -6.8901\n",
      " -5.1268\n",
      " -4.4349\n",
      " -6.2448\n",
      "-10.0871\n",
      " -7.7496\n",
      " -6.2156\n",
      " -5.6223\n",
      " -7.3910\n",
      " -6.4690\n",
      " -6.0614\n",
      " -7.4649\n",
      " -6.9022\n",
      " -6.4852\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  159\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.4255\n",
      " -3.0915\n",
      " -3.1419\n",
      " -3.4617\n",
      " -4.5489\n",
      " -3.8085\n",
      " -5.2784\n",
      " -8.4178\n",
      "-12.7982\n",
      "-10.3401\n",
      " -8.3228\n",
      " -6.4390\n",
      " -5.3919\n",
      " -4.9236\n",
      " -4.9459\n",
      " -5.1414\n",
      " -5.5007\n",
      " -5.6471\n",
      " -6.0462\n",
      " -6.9557\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  189\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.9667\n",
      "-2.6961\n",
      "-4.1247\n",
      "-3.1310\n",
      "-5.0991\n",
      "-3.6779\n",
      "-3.5216\n",
      "-4.3238\n",
      "-3.9192\n",
      "-4.1412\n",
      "-4.4565\n",
      "-4.9469\n",
      "-4.8365\n",
      "-5.3189\n",
      "-5.2142\n",
      "-5.7238\n",
      "-5.5583\n",
      "-6.1465\n",
      "-5.9141\n",
      "-5.7979\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training. Score was  144\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.3414\n",
      "-6.2190\n",
      "-2.5288\n",
      "-0.0325\n",
      " 0.1540\n",
      "-1.1766\n",
      "-0.0157\n",
      " 0.1634\n",
      "-0.3875\n",
      " 0.1241\n",
      "-0.0410\n",
      " 0.0224\n",
      "-1.7121\n",
      "-5.7629\n",
      "-3.4572\n",
      "-1.6739\n",
      "-5.7034\n",
      "-3.7142\n",
      "-1.8346\n",
      "-6.2594\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  174\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.5210\n",
      "-2.4514\n",
      "-2.5608\n",
      "-2.9459\n",
      "-3.0565\n",
      "-3.4273\n",
      "-4.3221\n",
      "-3.8795\n",
      "-5.1495\n",
      "-8.4552\n",
      "-6.4186\n",
      "-5.2583\n",
      "-4.8760\n",
      "-4.9385\n",
      "-5.4822\n",
      "-5.4420\n",
      "-5.6186\n",
      "-5.9418\n",
      "-6.2278\n",
      "-6.5380\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  145\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-2.8121\n",
      "-0.0492\n",
      " 0.2167\n",
      " 0.1761\n",
      " 0.1986\n",
      "-1.6600\n",
      " 0.0657\n",
      " 0.1966\n",
      "-1.0056\n",
      " 0.1402\n",
      " 0.2018\n",
      " 0.1598\n",
      " 0.1740\n",
      "-1.4467\n",
      " 0.0822\n",
      "-3.6195\n",
      "-9.2693\n",
      "-6.7375\n",
      "-4.0385\n",
      "-1.4441\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  152\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.9017\n",
      "  0.2006\n",
      " -0.7194\n",
      "  0.2034\n",
      " -0.3142\n",
      "  0.2035\n",
      " -1.0037\n",
      "  0.1014\n",
      " -2.0944\n",
      " -0.4529\n",
      "  0.1524\n",
      " -1.3817\n",
      " -5.9222\n",
      " -3.4918\n",
      " -1.5073\n",
      " -0.2264\n",
      "  0.0986\n",
      " -1.3014\n",
      " -5.8367\n",
      "-12.1600\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  156\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.5108\n",
      " -4.5326\n",
      " -4.7219\n",
      " -5.2814\n",
      " -5.0730\n",
      " -5.5437\n",
      " -6.1828\n",
      " -5.9829\n",
      " -6.5308\n",
      " -6.3797\n",
      " -6.8960\n",
      " -7.5778\n",
      " -7.3980\n",
      " -8.0448\n",
      " -8.7325\n",
      " -8.5648\n",
      " -9.3054\n",
      "-10.4316\n",
      " -9.9704\n",
      " -9.7467\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  126\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.7863\n",
      "  0.1394\n",
      " -3.8204\n",
      " -0.9586\n",
      " -6.3088\n",
      " -3.4756\n",
      " -9.2494\n",
      " -6.5796\n",
      " -3.6230\n",
      " -0.7964\n",
      " -6.5220\n",
      " -3.5876\n",
      " -0.8046\n",
      "  0.1689\n",
      " -3.2435\n",
      " -0.2107\n",
      "  0.1942\n",
      " -2.3125\n",
      " -8.1835\n",
      "-14.3223\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  170\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -6.1138\n",
      " -5.7627\n",
      " -6.4924\n",
      " -6.1960\n",
      " -6.6483\n",
      " -6.6459\n",
      " -7.6038\n",
      " -7.2527\n",
      " -7.6996\n",
      " -8.4162\n",
      " -9.3119\n",
      " -8.9500\n",
      " -8.7101\n",
      " -9.4846\n",
      " -9.2242\n",
      "-10.0123\n",
      " -9.7996\n",
      "-10.5086\n",
      "-11.4625\n",
      "-12.4643\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  193\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.2786\n",
      " -6.1923\n",
      " -7.2848\n",
      " -6.5658\n",
      " -6.0057\n",
      " -6.9055\n",
      " -8.0932\n",
      " -9.3128\n",
      " -8.5770\n",
      " -7.7861\n",
      " -9.0245\n",
      " -8.2275\n",
      " -9.4871\n",
      " -8.6584\n",
      " -8.1563\n",
      " -9.0345\n",
      "-10.3502\n",
      " -9.4292\n",
      "-10.7822\n",
      " -9.8242\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  180\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -5.3758\n",
      " -6.3202\n",
      " -5.6514\n",
      " -6.5734\n",
      " -7.5324\n",
      " -8.4760\n",
      " -9.9795\n",
      " -9.1392\n",
      " -8.5732\n",
      " -7.8636\n",
      " -7.4226\n",
      " -8.2727\n",
      " -9.5188\n",
      " -8.7362\n",
      " -8.3782\n",
      " -9.1559\n",
      " -8.9002\n",
      " -9.5637\n",
      "-10.8024\n",
      "-12.0098\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  143\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " 0.1995\n",
      " 0.1979\n",
      "-0.8419\n",
      " 0.2038\n",
      "-0.1733\n",
      " 0.2059\n",
      "-0.7364\n",
      "-5.5276\n",
      "-2.6908\n",
      "-0.3686\n",
      " 0.1832\n",
      "-1.8693\n",
      "-7.5010\n",
      "-4.6443\n",
      "-1.9924\n",
      "-0.0054\n",
      "-4.5515\n",
      "-1.8384\n",
      "-7.4592\n",
      "-4.8472\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Training. Score was  136\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -0.3451\n",
      " -4.6614\n",
      " -1.3357\n",
      "  0.1495\n",
      " -2.6283\n",
      " -0.0765\n",
      " -4.3507\n",
      " -1.3258\n",
      "  0.1378\n",
      "  0.1977\n",
      " -0.0595\n",
      "  0.1791\n",
      " -0.9961\n",
      " -6.0430\n",
      "-11.9948\n",
      " -9.0537\n",
      " -6.2821\n",
      "-12.1536\n",
      " -9.5158\n",
      " -6.7903\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  193\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-6.0133\n",
      "-4.5854\n",
      "-4.0184\n",
      "-4.8287\n",
      "-6.3897\n",
      "-8.3200\n",
      "-6.7358\n",
      "-5.3967\n",
      "-5.2778\n",
      "-5.6294\n",
      "-7.0070\n",
      "-8.8930\n",
      "-7.2706\n",
      "-9.1909\n",
      "-7.5511\n",
      "-6.6314\n",
      "-7.7923\n",
      "-9.5994\n",
      "-8.0815\n",
      "-9.8366\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  174\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -3.0860\n",
      " -0.2438\n",
      " -2.8032\n",
      " -0.1509\n",
      " -0.1029\n",
      " -0.0173\n",
      " -1.2662\n",
      "  0.0523\n",
      " -0.4483\n",
      " -3.1763\n",
      " -0.0841\n",
      " -0.1208\n",
      "  0.1107\n",
      " -0.7680\n",
      "  0.0774\n",
      " -2.2738\n",
      " -7.9649\n",
      "-14.4415\n",
      "-12.4799\n",
      "-10.5309\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Training. Score was  197\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "-8.3596\n",
      "-6.5523\n",
      "-5.2687\n",
      "-4.0688\n",
      "-6.2569\n",
      "-4.9750\n",
      "-7.2769\n",
      "-5.8838\n",
      "-4.5794\n",
      "-6.7189\n",
      "-5.3249\n",
      "-7.5108\n",
      "-6.0331\n",
      "-4.8792\n",
      "-6.5738\n",
      "-8.8208\n",
      "-7.2088\n",
      "-9.5720\n",
      "-7.8364\n",
      "-6.3872\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  80\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "  0.0599\n",
      "  0.1985\n",
      " -0.1582\n",
      " -3.2783\n",
      " -9.0947\n",
      " -6.4508\n",
      "-12.9148\n",
      "-10.5773\n",
      " -8.1596\n",
      " -5.1189\n",
      " -2.0847\n",
      " -0.0574\n",
      " -4.6861\n",
      " -1.5724\n",
      " -7.7733\n",
      " -4.3397\n",
      "-11.2522\n",
      "-19.0420\n",
      "-16.0411\n",
      "-12.4658\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  137\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " 0.2976\n",
      " 0.2365\n",
      " 0.2853\n",
      " 0.1495\n",
      "-0.8339\n",
      "-0.1081\n",
      "-2.2132\n",
      "-7.0194\n",
      "-5.2117\n",
      "-3.9925\n",
      "-2.7509\n",
      "-1.3963\n",
      "-5.7755\n",
      "-4.3085\n",
      "-2.5497\n",
      "-0.8548\n",
      "-5.6387\n",
      "-3.6554\n",
      "-1.5024\n",
      "-6.9990\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  193\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " -1.5540\n",
      " -0.1967\n",
      "  0.1642\n",
      "  0.1845\n",
      " -1.2139\n",
      "  0.1873\n",
      "  0.1106\n",
      " -1.1044\n",
      " -5.5030\n",
      " -2.8622\n",
      " -0.9845\n",
      " -4.9623\n",
      " -2.5014\n",
      " -7.7433\n",
      "-13.8880\n",
      "-11.7616\n",
      "-18.3207\n",
      "-16.6424\n",
      "-14.9108\n",
      "-12.6316\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  135\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      "  0.2286\n",
      "  0.0039\n",
      " -4.9553\n",
      " -0.3866\n",
      " -6.0990\n",
      " -1.1720\n",
      "  0.2036\n",
      "  0.2589\n",
      "  0.3028\n",
      " -0.0837\n",
      " -3.1377\n",
      " -8.3314\n",
      "-14.5908\n",
      "-12.8393\n",
      "-11.1455\n",
      " -9.5105\n",
      " -7.9047\n",
      " -6.3103\n",
      " -4.9140\n",
      " -2.9970\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Training. Score was  191\n",
      "\n",
      "Rewards [5.136933816377228, 4.596593129308031, 3.996214588120034, 3.329127320133371, 2.5879192445926344, 1.7643547162140383, 0.8492830180155982, -0.16746331331600195, -1.2971814592400022, -2.5524238436000024, -3.9471376040000026, -5.496819560000003, -7.218688400000003, -9.131876000000004, -11.257640000000004, -13.619600000000004, -16.244000000000003, -19.160000000000004, -22.400000000000002, -26.0] \n",
      "State values Variable containing:\n",
      " 0.2280\n",
      " 0.0724\n",
      " 0.2268\n",
      " 0.2683\n",
      "-0.1662\n",
      "-3.2758\n",
      "-8.5726\n",
      "-6.6397\n",
      "-4.7231\n",
      "-2.9191\n",
      "-1.5026\n",
      "-0.6953\n",
      "-4.1058\n",
      "-2.5047\n",
      "-7.9404\n",
      "-6.2303\n",
      "-4.3306\n",
      "-2.1199\n",
      "-8.1175\n",
      "-5.2845\n",
      "[torch.FloatTensor of size 20x1]\n",
      "\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n",
      "Not training, score of  200\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a17e21710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0K+/Ga6jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a14332fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a14281e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "num_games = []\n",
    "value_losses = []\n",
    "action_gains = []\n",
    "\n",
    "for i in range(N_GAMES):\n",
    "    \n",
    "    del states[:]\n",
    "    del actions[:]\n",
    "    del rewards[:]\n",
    "    \n",
    "    state = env.reset() \n",
    "    done = False\n",
    "    \n",
    "    # act phase\n",
    "    while not done:\n",
    "        s = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        \n",
    "        action_probs = model.get_action_probs(Variable(s))\n",
    "        action = action_probs.multinomial().data[0][0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "    if len(rewards) < 200: # only reflecting/training on episodes where a failure occured. No training\n",
    "        # signal in perfect games. \n",
    "        # Reflect phase\n",
    "        print(\"Training. Score was \", len(rewards))\n",
    "\n",
    "        R = []\n",
    "        rr = rewards\n",
    "        rr.reverse()\n",
    "\n",
    "        next_return = -30 #if len(rewards) < 200 else 1 # unnecessary now, should just be 0\n",
    "        # punish failure hard\n",
    "\n",
    "        for r in range(len(rr)):\n",
    "            this_return = rr[r] + next_return * .9\n",
    "            R.append(this_return)\n",
    "            next_return = this_return\n",
    "        R.reverse()\n",
    "\n",
    "        global rewards\n",
    "        rewards = R\n",
    "        \n",
    "        # taking only the last 20 states before failure\n",
    "        rewards = rewards[-20:]\n",
    "        states = states[-20:]\n",
    "        actions = actions[-20:]\n",
    "        \n",
    "        s = Variable(torch.FloatTensor(states))\n",
    "\n",
    "        global state_values\n",
    "        action_probs, state_values = model.evaluate_actions(s)\n",
    "\n",
    "        action_log_probs = action_probs.log() \n",
    "\n",
    "        advantages = Variable(torch.FloatTensor(rewards)).unsqueeze(1) - state_values\n",
    "\n",
    "        entropy = (action_probs * action_log_probs).sum(1).mean()\n",
    "\n",
    "        a = Variable(torch.LongTensor(actions).view(-1,1))\n",
    "\n",
    "        chosen_action_log_probs = action_log_probs.gather(1, a)\n",
    "\n",
    "        action_gain = (chosen_action_log_probs * advantages).mean()\n",
    "\n",
    "        value_loss = advantages.pow(2).mean()\n",
    "\n",
    "        total_loss = value_loss - action_gain - 0.0001*entropy\n",
    "\n",
    "        #total_loss /= len(rewards) # wow this allowed to reach high score faster. Wait. this shouldn't matter\n",
    "        # bc we're using mean values. undoing now.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(\"\\nRewards\", rewards, \"\\nState values\",  state_values)\n",
    "        \n",
    "    else: print(\"Not training, score of \", len(rewards))\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        s = test_model(model)\n",
    "        scores.append(s)\n",
    "        num_games.append(i)\n",
    "\n",
    "        action_gains.append(action_gain.data.numpy()[0])\n",
    "        value_losses.append(value_loss.data.numpy()[0])\n",
    "\n",
    "        \n",
    "plt.plot(num_games, scores)\n",
    "plt.xlabel(\"N_GAMES\")\n",
    "plt.ylabel(\"Score\")\n",
    "#plt.title(EXP)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_games, value_losses)\n",
    "plt.xlabel(\"N_GAMES\")\n",
    "plt.ylabel(\"Value loss\")\n",
    "#plt.savefig(\"experiments/\"+EXP_NAME+'/'+EXP)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_games, action_gains)\n",
    "plt.xlabel(\"N_GAMES\")\n",
    "plt.ylabel(\"action gains\")\n",
    "#plt.savefig(\"experiments/\"+EXP_NAME+'/'+EXP)\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.linear1 = nn.Linear(N_INPUTS, 64)\n",
    "        self.linear2 = nn.Linear(64, 128)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "        \n",
    "        self.actor = nn.Linear(64, N_ACTIONS)\n",
    "        self.critic = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_action_probs(self, x):\n",
    "        x = self(x)\n",
    "        action_probs = F.softmax(self.actor(x))\n",
    "        return action_probs\n",
    "    \n",
    "    def evaluate_actions(self, x):\n",
    "        x = self(x)\n",
    "        action_probs = F.softmax(self.actor(x))\n",
    "        state_values = self.critic(x)\n",
    "        return action_probs, state_values\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    score = 0\n",
    "    done = False\n",
    "    env = gym.make('CartPole-v0')\n",
    "    state = env.reset()\n",
    "    global action_probs\n",
    "    while not done:\n",
    "        score += 1\n",
    "        s = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        \n",
    "        action_probs = model.get_action_probs(Variable(s))\n",
    "        \n",
    "        _, action_index = action_probs.max(1)\n",
    "        action = action_index.data[0] \n",
    "        next_state, reward, done, thing = env.step(action)\n",
    "        state = next_state\n",
    "        \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.7.17 experiment. set up model from scratch. was having problems initially because\n",
    "wasn't passing discounted returns into the past. There was no signal for model to grab \n",
    "on to, seeing as how it was just all ones. Model improved immediately after discounting \n",
    "future returns. consistently beat game during training after 7-12k games\n",
    "\n",
    "12.15.17 WTF now it errors out with nans in the parameters?? looks like exploding/vanishing gradients. Trying gradient clipping. Gradient clipping solves it. Weird scores shoot up fast then back down. Hit 200 after 600 games. Scores really all over the place.\n",
    "\n",
    "12.17 Dividing loss be length of rewards speeds training. Dividing inputs by their max value breaks it, probably bc max values are too big.\n",
    "\n",
    "Rewards vs state values is relatively accurate. Much better than nstep version. At least they're in the ballpark and trend in the correct direction. state_values pretty much just converge on rewards values (which evens out due to discounting). So in essence model just learns rewards values and assigns that value to all states, regardless of state. Even states in which the game loses are marked as same value. Safest bet from model's perspective is to just predict the long term reward value every time. \n",
    "\n",
    "Why does nstep version blow up state_value predictions? They just keep getting bigger and bigger\n",
    "\n",
    "epsilon makes sense when thinking how far back we want responsability to go. It cartpole, probably not very far so a low epsilon is probably better. All stable states look relatively the same--it would be hard to differentiate btwn a stable state that will end in 20 steps or a stable state that will end in 200 steps. Both stable states should be valued the same.\n",
    "\n",
    "by epsilon, I mean gamma. bc i'm an amateur. \n",
    "\n",
    "Note: We were assigning value of 0 to last state indisciminantly, even if termination was due to max score of 200. Fixed now.\n",
    "\n",
    "\n",
    "12.18\n",
    "Problem: V(s) is not learning well. It's just predicting the steady state (based on gamma) for all states--even those right before failure. This is ok in non-nstep version bc we're not using v(s) to bootstrap, but it's a big problem with nstep models. Hypothesis: It's bc our steady-state samples, where no real signal is being providing, are overwhelming the frames directly before failure--frames with strong signal. ALso, those steady state frames have no variation, no signal. Approach: Oversample important frames. Take only the 15 frames prior to failure for training.\n",
    "\n",
    "Result: wow after score of 200 remained 200 thereafter. makes sense bc we're not training it anymore. v(s) looks better, descending from 8 to 5, ideal would be 8 to 1. not enough spread in the v(s) estimates. Trying with window of 20 before failure, decreasing reward for ending state to -30. Success in terms of not training on no-signal data, failure in terms of capturing variability of v(s). \n",
    "\n",
    "Result: first run didn't catch at all. second run caught early and right to 200. v(s) now flattened out as before. \n",
    "\n",
    "Why can't we capture variability of v(s)? \n",
    "\n",
    "hypothesis: neural network isn't deep enough. \n",
    "\n",
    "Approach: change architecture to 64-128-64 instead of single 128.\n",
    "\n",
    "Result: Didn't catch on first run of 500, but wow v(s) estimates look much better. Was that the case in other failed runs? Often blowing up gradients though.\n",
    "\n",
    "Try reducing LR to 3e-3 from 3e-4. Result: This allows it to train. We're capturing range of about 0 to -12 or -20, which is good although ideal range would be 5 to -26.\n",
    "\n",
    "Let's go back and try shallower net to see if also captures this range. Changing ONLY the model architecture back to 128. Keeping lr 3e-3 and failure reward of -30. Result: very little variation (about 3)! Probably reason: deeper network better captures variation. Although v(s) estimate less good with simpler model, simpler model appears to perform better (?)\n",
    "\n",
    "Question: why does deeper model require smaller LR to not blow up gradients? Is it just bc there are more parameters so more opportunity for blowup?\n",
    "\n",
    "Hypothesis: if deeper models better capture variation, an even deeper model will do even better. Instead of a three layer 64-128-64, let's try a 64-128-256-128-64. Again, changing ONLY model architecture.\n",
    "\n",
    "Result: Hmm, sometimes capturing lots of variation. sometimes too much even. Takes much longer to reach 200. v(s) sometimes very good, sometimes very bad. \n",
    "\n",
    "I wonder how a two hidden layer model would do? Not capturing as much variation. about 8. Let's go back to 64-128-64 model and try with n-steps. First, verify model again: Verified. Notes: early on in training we're seeing some really nice progressions of v(s). Later on not so good, is that just selection bias bc we're only seeing failed episodes, and the episodes model fails on get harder and harder? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
