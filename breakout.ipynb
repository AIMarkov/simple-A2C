{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (8, 8), padding='same',\n",
    "                 input_shape=(105,80,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(4)) # number of actions\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_old = env.reset()\n",
    "frame_new, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.16893387,   9.68431473,  14.90043354,  -3.45087957]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(state.reshape(1,105, 80, 2), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BreakoutDeterministic-v4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85ead9fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#frame_diff = preprocess(frame_1) - preprocess(frame_2)\n",
    "#frame_1=frame_2\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(preprocess(frame_old), cmap=\"gray\") \n",
    "\n",
    "gamma = 0.9\n",
    "buffer = 80\n",
    "batchSize = 40\n",
    "\n",
    "rewards = []\n",
    "\n",
    "replay = []\n",
    "h = 0\n",
    "\n",
    "def prep_frames(f1, f2):\n",
    "    return np.array([preprocess(f1), preprocess(f2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #: 0\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 156s - loss: -1970.8500 - acc: 0.3000\n",
      "Game #: 0\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 50s - loss: -1093.0066 - acc: 0.5250\n",
      "Game #: 0\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 19s - loss: -787.1974 - acc: 0.4500\n",
      "Game #: 0\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    \n",
    "    # doing first two steps here to get enough for initial state\n",
    "    frame_old = env.reset()\n",
    "\n",
    "    frame_new, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "    while not is_done:\n",
    "        # STATE\n",
    "        orig_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "        # ACTION\n",
    "        Qvals = model.predict(orig_state.reshape(1,105,80,2), batch_size=1)\n",
    "        maxQ_ix = np.argmax(Qvals)\n",
    "        \n",
    "        frame_old = frame_new\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "        #action = maxQ_ix\n",
    "\n",
    "        # NEW STATE, REWARD\n",
    "        frame_new, reward, is_done, _ = env.step(action) # totally exploratory\n",
    "\n",
    "        # new state \n",
    "        new_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "        reward = np.sign(reward)\n",
    "        \n",
    "        #Experience replay storage\n",
    "        if (len(replay) < buffer): #if buffer not filled, add to it\n",
    "            replay.append((orig_state, action, reward, new_state))\n",
    "        else: \n",
    "            if (h < (buffer-1)):\n",
    "                h += 1\n",
    "            else:\n",
    "                h = 0\n",
    "                \n",
    "            replay[h] = (orig_state, action, reward, new_state)\n",
    "            \n",
    "            #randomly sample our experience replay memory\n",
    "            minibatch = random.sample(replay, batchSize)\n",
    "            \n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            for memory in minibatch:\n",
    "                #Get max_Q(S',a)\n",
    "                old_state, action, reward, new_state = memory\n",
    "                old_qval = model.predict(old_state.reshape(1,105,80,2), batch_size=1)\n",
    "                \n",
    "                newQ = model.predict(new_state.reshape(1,105,80,2), batch_size=1)\n",
    "                maxQ = np.max(newQ)\n",
    "                y = np.zeros((1,4))\n",
    "                y[:] = old_qval[:]\n",
    "                update = (reward + (gamma * maxQ))\n",
    "\n",
    "                y[0][action] = update\n",
    "                X_train.append(old_state)\n",
    "                y_train.append(y)\n",
    "            \n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train).reshape(batchSize, 4)\n",
    "            \n",
    "            print(\"Game #: %s\" % (i,))\n",
    "            model.fit(X_train, y_train, batch_size=batchSize, epochs=1, verbose=1)\n",
    "            \n",
    "        env.render()\n",
    "        \n",
    "        \"\"\"\n",
    "        if i % 50 == 0:\n",
    "            print(\"qvals\", Qvals)\n",
    "            print(\"action\", action)\n",
    "            print(\"reward: \", reward)\n",
    "            print(\"frame diff max\", np.max(preprocess(frame_new)-preprocess(frame_old)))\n",
    "            print(\"new maxQ\", new_maxQ)\n",
    "            print(\"update\", update)\n",
    "            print(\"fitting with the following y:\", y, \"\\n\\n\")\"\"\"\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "im = ax.imshow(preprocess(frame_old), cmap=\"gray\") \n",
    "env.close()\n",
    "\n",
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 105, 80, 2)"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-649-db013e4a4793>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-649-db013e4a4793>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \"\"\"new_Qvals = model.predict(new_state, batch_size=1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " ######### No replay\n",
    "        \n",
    "        \"\"\"new_Qvals = model.predict(new_state, batch_size=1)\n",
    "        new_maxQ = np.max(new_Qvals)\n",
    "    \n",
    "        update = reward + (gamma * new_maxQ)\n",
    "        y = np.zeros((1,4))\n",
    "        y[:] = Qvals[:]\n",
    "        y[0][action] = update #target output\n",
    "        \n",
    "        model.fit(orig_state, y, batch_size=1, epochs=1, verbose=1)\"\"\"\n",
    "        ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_to_gray(frame_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_greyscale(img): # later on, let's turn these binary\n",
    "    return np.mean(img, axis=2).astype(np.uint8)\n",
    "\n",
    "def rgb_to_gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray.astype(np.uint8)\n",
    "\n",
    "def downsample(img):\n",
    "    return img[::2, ::2]\n",
    "\n",
    "def preprocess(img):\n",
    "    return rgb_to_gray(downsample(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predPic1 = preprocess(frame_1)#.reshape(1,105,80,1)\n",
    "predPic2 = preprocess(frame_2)#.reshape(1,105,80,1)\n",
    "X = np.array([predPic1, predPic2]).reshape(1,105,80,2) # last number is number of pics\n",
    "np.max(predPic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_reward(reward):\n",
    "    return np.sign(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def atari_model(n_actions):\n",
    "    # We assume a theano backend here, so the \"channels\" are first.\n",
    "    #ATARI_SHAPE = (4, 105, 80)\n",
    "    \n",
    "    # tf backend\n",
    "    ATARI_SHAPE = (105, 80, 2)\n",
    "\n",
    "    # With the functional API we need to define the inputs.\n",
    "    frames_input = keras.layers.Input(ATARI_SHAPE, name='frames')\n",
    "    #actions_input = keras.layers.Input((n_actions,), name='mask')\n",
    "\n",
    "    # Assuming that the input frames are still encoded from 0 to 255. Transforming to [0, 1].\n",
    "    normalized = keras.layers.Lambda(lambda x: x / 255.0)(frames_input)\n",
    "    \n",
    "    #still want to normalize these, although greyscaled already\n",
    "    \n",
    "    # \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "    conv_1 = keras.layers.convolutional.Convolution2D(\n",
    "        16, 8, 8, subsample=(4, 4), activation='relu'\n",
    "    )(normalized)\n",
    "    # \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "    conv_2 = keras.layers.convolutional.Convolution2D(\n",
    "        32, 4, 4, subsample=(2, 2), activation='relu'\n",
    "    )(conv_1)\n",
    "    # Flattening the second convolutional layer.\n",
    "    conv_flattened = keras.layers.core.Flatten()(conv_2)\n",
    "    # \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "    hidden = keras.layers.Dense(256, activation='relu')(conv_flattened)\n",
    "    # \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "    output = keras.layers.Dense(n_actions)(hidden)\n",
    "    # Finally, we multiply the output by the mask!\n",
    "    # filtered_output = keras.layers.merge([output, actions_input], mode='mul')\n",
    "\n",
    "    #model = keras.models.Model(input=[frames_input, actions_input], output=filtered_output)\n",
    "    model = keras.models.Model(input=frames_input, output=output)\n",
    "    optimizer = optimizer=keras.optimizers.RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "    model.compile(optimizer, loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (8, 8), activation=\"relu\", strides=(4, 4))`\n",
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (4, 4), activation=\"relu\", strides=(2, 2))`\n",
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"fr...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01656071, -0.01670225]], dtype=float32)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "atari_model(2).predict(X, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
