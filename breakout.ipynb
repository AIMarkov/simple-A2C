{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_greyscale(img): # later on, let's turn these binary\n",
    "    return np.mean(img, axis=2).astype(np.uint8)\n",
    "\n",
    "def rgb_to_gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray.astype(np.uint8)\n",
    "\n",
    "def downsample(img):\n",
    "    return img[::2, ::2]\n",
    "\n",
    "def preprocess(img):\n",
    "    return rgb_to_gray(downsample(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (8, 8), strides=(4, 4), activation=\"relu\")`\n",
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (4, 4), strides=(2, 2), activation=\"relu\")`\n",
      "/home/beans/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"fr...)`\n"
     ]
    }
   ],
   "source": [
    "# We assume a theano backend here, so the \"channels\" are first.\n",
    "#ATARI_SHAPE = (4, 105, 80)\n",
    "\n",
    "# tf backend\n",
    "#ATARI_SHAPE = (105, 80, 2)\n",
    "ATARI_SHAPE = (105, 80, 1) # using diff images\n",
    "\n",
    "# With the functional API we need to define the inputs.\n",
    "frames_input = keras.layers.Input(ATARI_SHAPE, name='frames')\n",
    "#actions_input = keras.layers.Input((n_actions,), name='mask')\n",
    "\n",
    "# Assuming that the input frames are still encoded from 0 to 255. Transforming to [0, 1].\n",
    "normalized = keras.layers.Lambda(lambda x: x / 255.0)(frames_input)\n",
    "\n",
    "#still want to normalize these, although greyscaled already\n",
    "\n",
    "# \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "conv_1 = keras.layers.convolutional.Convolution2D(\n",
    "    16, 8, 8, subsample=(4, 4), activation='relu'\n",
    ")(normalized)\n",
    "# \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "conv_2 = keras.layers.convolutional.Convolution2D(\n",
    "    32, 4, 4, subsample=(2, 2), activation='relu'\n",
    ")(conv_1)\n",
    "# Flattening the second convolutional layer.\n",
    "conv_flattened = keras.layers.core.Flatten()(conv_2)\n",
    "\n",
    "# \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "hidden = keras.layers.Dense(256, activation='relu')(conv_flattened)\n",
    "\n",
    "# \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "#output = keras.layers.Dense(4)(hidden) # number of actions\n",
    "output = keras.layers.Dense(2)(hidden) # number of actions--only allowing useful moves\n",
    "\n",
    "#model = keras.models.Model(input=[frames_input, actions_input], output=filtered_output)\n",
    "atari_model = keras.models.Model(input=frames_input, output=output)\n",
    "optimizer = optimizer=keras.optimizers.RMSprop(lr=0.00025, rho=0.95, epsilon=0.01)\n",
    "atari_model.compile(optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = gym.make(\"BreakoutDeterministic-v4\")\n",
    "env = gym.make(\"Pong-v0\")\n",
    "\n",
    "gamma = 0.9\n",
    "buffer = 10000\n",
    "batchSize = 32\n",
    "epsilon = 1\n",
    "\n",
    "rewards = []\n",
    "\n",
    "replay = []\n",
    "h = 0\n",
    "\n",
    "model = atari_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_old = env.reset()\n",
    "frame_new, reward, is_done, _ = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgdL+pYLqqf+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b9ad22630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_new, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "print(reward)\n",
    "env.render()\n",
    "plt.imshow(preprocess(frame_new)-preprocess(frame_old), cmap=\"gray\")\n",
    "frame_old = frame_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00204902  0.00154707]]\n",
      "AxesImage(54,36;334.8x217.44)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRiQ1GZHUZERSkxFJTf8D5sscgCV5hNcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b6ce6a940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# STATE\n",
    "orig_state = preprocess(frame_old) - preprocess(frame_new)\n",
    "\n",
    "# ACTION\n",
    "Qvals = model.predict(orig_state.reshape(1,105,80,1), batch_size=1)\n",
    "maxQ_ix = np.argmax(Qvals)\n",
    "\n",
    "print(Qvals)\n",
    "frame_old = frame_new\n",
    "\n",
    "# take optimal choice\n",
    "action = maxQ_ix \n",
    "\n",
    "# NEW STATE, REWARD\n",
    "frame_new, reward, is_done, _ = env.step(action)\n",
    "\n",
    "print(plt.imshow(preprocess(frame_new), cmap=\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(\"game #\", i)\n",
    "    # doing first two steps here to get enough for initial state\n",
    "    \n",
    "    frame_old = env.reset()\n",
    "\n",
    "    frame_new, reward, is_done, _ = env.step(2 if random.random()<.5 else 3) #random\n",
    "\n",
    "\n",
    "    while not is_done:\n",
    "        # STATE\n",
    "        orig_state = preprocess(frame_old) - preprocess(frame_new)\n",
    "\n",
    "        # ACTION\n",
    "        Qvals = model.predict(orig_state.reshape(1,105,80,1), batch_size=1)\n",
    "        maxQ_ix = np.argmax(Qvals)\n",
    "\n",
    "        frame_old = frame_new\n",
    "\n",
    "        if random.random()>epsilon:\n",
    "            action = maxQ_ix\n",
    "            # take optimal choice\n",
    "        else:\n",
    "            action = 2 if random.random()<.5 else 3\n",
    "            # take random choice\n",
    "        if epsilon > .1: epsilon -= .9e-06\n",
    "\n",
    "        # NEW STATE, REWARD\n",
    "        frame_new, reward, is_done, _ = env.step(action)\n",
    "\n",
    "        # new state \n",
    "        new_state = preprocess(frame_new) - preprocess(frame_old)\n",
    "\n",
    "        reward = np.sign(reward)\n",
    "\n",
    "        #Experience replay storage\n",
    "        if (len(replay) < buffer): #if buffer not filled, add to it\n",
    "            replay.append((orig_state, action, reward, new_state))\n",
    "        else: \n",
    "            if (h < (buffer-1)):\n",
    "                h += 1\n",
    "            else:\n",
    "                h = 0\n",
    "\n",
    "            replay[h] = (orig_state, action, reward, new_state)\n",
    "\n",
    "            #randomly sample our experience replay memory\n",
    "            minibatch = random.sample(replay, batchSize)\n",
    "\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            for memory in minibatch:\n",
    "                #Get max_Q(S',a)\n",
    "                old_state, action, reward, new_state = memory\n",
    "                old_qval = model.predict(old_state.reshape(1,105,80,1), batch_size=1)\n",
    "\n",
    "                newQ = model.predict(new_state.reshape(1,105,80,1), batch_size=1)\n",
    "                maxQ = np.max(newQ)\n",
    "                y = np.zeros((1,2))\n",
    "                y[:] = old_qval[:]\n",
    "                update = (reward + (gamma * maxQ))\n",
    "\n",
    "                y[0][0 if action == 2 else 1] = update\n",
    "                X_train.append(old_state)\n",
    "                y_train.append(y)\n",
    "\n",
    "                \"\"\"\n",
    "                print(\"old qvals\", old_qval)\n",
    "                print(\"action\", action)\n",
    "                print(\"reward: \", reward)\n",
    "                print(\"new q vals \", newQ)\n",
    "                print(\"update\", update)\n",
    "                print(\"fitting with the following y:\", y, \"\\n\\n\")\n",
    "                \"\"\"\n",
    "\n",
    "            X_train = np.array(X_train).reshape(batchSize, 105, 80, 1)\n",
    "            y_train = np.array(y_train).reshape(batchSize, 2)\n",
    "\n",
    "            #print(\"Game #: %s\" % (i,))\n",
    "            model.fit(X_train, y_train, batch_size=batchSize, epochs=1, verbose=0)\n",
    "\n",
    "    #env.render()\n",
    "\n",
    "    print(plt.imshow(new_state, cmap=\"gray\"))\n",
    "    #env.close()\n",
    "    print(\"saving model...\")\n",
    "    model.save(\"pong.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 105, 80)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "frame_old = env.reset()\n",
    "\n",
    "frame_new, reward, is_done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "while not is_done:\n",
    "    # STATE\n",
    "    orig_state = np.array([preprocess(frame_old), preprocess(frame_new)]).reshape(105, 80, 2)\n",
    "\n",
    "    # ACTION\n",
    "    Qvals = model.predict(orig_state.reshape(1,105,80,2), batch_size=1)\n",
    "    maxQ_ix = np.argmax(Qvals)\n",
    "\n",
    "    frame_old = frame_new\n",
    "\n",
    "    # take optimal choice\n",
    "    action = maxQ_ix \n",
    "\n",
    "    # NEW STATE, REWARD\n",
    "    frame_new, reward, is_done, _ = env.step(action)\n",
    "    \n",
    "\n",
    "    env.render(mode='rgb_array')    \n",
    "#ax.imshow(preprocess(frame_old), cmap=\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
